{"meta":{"title":"仙人一张","subtitle":"","description":"","author":"yiqing","url":"http://yiiiqing.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2023-07-29T05:20:38.926Z","updated":"2020-11-04T10:39:32.000Z","comments":false,"path":"/404.html","permalink":"http://yiiiqing.github.io/404.html","excerpt":"","text":""},{"title":"categories","date":"2020-11-05T03:46:09.000Z","updated":"2020-11-05T03:46:53.000Z","comments":true,"path":"categories/index.html","permalink":"http://yiiiqing.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2023-07-29T05:20:38.921Z","updated":"2020-11-04T10:39:32.000Z","comments":false,"path":"about/index.html","permalink":"http://yiiiqing.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"友情链接","date":"2023-07-29T05:20:38.924Z","updated":"2020-11-04T10:39:32.000Z","comments":true,"path":"links/index.html","permalink":"http://yiiiqing.github.io/links/index.html","excerpt":"","text":""},{"title":"书单","date":"2023-07-29T05:20:38.922Z","updated":"2020-11-04T10:39:32.000Z","comments":false,"path":"books/index.html","permalink":"http://yiiiqing.github.io/books/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-11-05T03:41:08.000Z","updated":"2020-11-05T03:44:10.000Z","comments":true,"path":"tags/index.html","permalink":"http://yiiiqing.github.io/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-07-29T05:20:38.663Z","updated":"2020-11-04T10:39:32.000Z","comments":false,"path":"repository/index.html","permalink":"http://yiiiqing.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"Spring-BeanFactory和FactoryBean的区别","slug":"Spring-BeanFactory和FactoryBean的区别","date":"2023-04-13T09:35:43.000Z","updated":"2023-05-25T08:00:34.000Z","comments":true,"path":"2023/04/13/Spring-BeanFactory和FactoryBean的区别/","link":"","permalink":"http://yiiiqing.github.io/2023/04/13/Spring-BeanFactory%E5%92%8CFactoryBean%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"BeanFactory 和 FactoryBean共同点: 都是用来创建对象的 不同点: FactoryBean类 实现接口FactoryBean 实现getObject() 在这里可以自定义自己的返回对象的方法, 可以反射也可以 new 等于是一个定制化的 Factory 实现getObjectType() 实现isSingleton() FactoryBean 的调用地点: 获取 beanDefinition 的时候判断isFactoryBean(beanName) 就通过自己的方法来获取 bean BeanFactory 相当于流水线","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"}]},{"title":"Spring-Bean的生命周期","slug":"Spring-Bean的生命周期","date":"2023-04-13T09:22:34.000Z","updated":"2023-04-13T09:35:49.000Z","comments":true,"path":"2023/04/13/Spring-Bean的生命周期/","link":"","permalink":"http://yiiiqing.github.io/2023/04/13/Spring-Bean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","excerpt":"","text":"Spring中 Bean 的生命周期 实例化 Bean 对象 设置对象属性 检查 Aware 相关接口并设置相关依赖 BeanPostProcessor 前置处理 检查是否implement 了 InitializingBean 以决定是否调用 afterPropertiesSet 方法 检查是否配置有自定义的 init-method BeanPostProcessor 后置处理 注册必要的 Destruction 相关毁掉接口 使用 Bean 是否实现 DisposableBean 接口 是否配有自定义的 destroy 方法","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"}]},{"title":"Spring容器的refresh方法","slug":"Spring容器的refresh方法","date":"2023-03-21T08:40:55.000Z","updated":"2023-03-23T08:07:12.000Z","comments":true,"path":"2023/03/21/Spring容器的refresh方法/","link":"","permalink":"http://yiiiqing.github.io/2023/03/21/Spring%E5%AE%B9%E5%99%A8%E7%9A%84refresh%E6%96%B9%E6%B3%95/","excerpt":"","text":"Spring容器的refresh方法BeanFactory的创建以及准备 prepareRefresh 刷新前的预处理 initPropertySources() 初始化一些设置; 子类自定义个性化的属性设置方法; getEnvironment().validateRequiredProperties(); 校验属性的合法等 this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners);保存容器中一些早期的事件; obtainFreshBeanFactory(); 获取BeanFactory refreshBeanFactory(); 创建了一个 this.beanFactory = new DefaultListableBeanFactory(); 设置id getBeanFactory() 返回上一步的beanFactory 将创建的BeanFactory返回 prepareBeanFactory(beanFactory); BeanFactory的准备工作(BeanFactory进行一些设置) 设置BeanFactory的类加载器, 支持表达式解析器 添加部分BeanPostProcessor [ApplicationContextAwareProcessor] 设置忽略的自动装配的接口 [EnvironmentAware,EmbeddedValueResolverAware…] 注册可以解析的自动装配 ,我们可以在任何组件中自动注入[BeanFactory,ResourceLoader,ApplicationEventPublisher,ApplicationContext] 添加BeanPostProcessor 添加编译时的AspectJ支持 给BeanFactory中注册一些能用的组件: environment systemProperties systemEnvironment postProcessBeanFactory(beanFactory); BeanFactory准备工作完成后进行的后置处理工作 子类通过重写这个方法在BeanFactory创建并准备完成后进一步的设置 BeanFactoryPostProcessor接着往下说 invokeBeanFactoryPostProcessors(beanFactory);执行BeanFactoryPostProcessors; BeanFactoryPostProcessors: BeanFactory的后置处理器, 在BeanFactory标准初始化之后进行的 两个相关接口: BeanFactoryPostProcessor和BeanDefinitionRegistryPostProcessor 执行BeanFactoryPostProcessor的方法 先执行BeanDefinitionRegistryPostProcessor 获取所有的BeanDefinitionRegistryPostProcessor 按照优先级排序: PriorityOrdered -&gt; Ordered指定顺序的 -&gt; 没有实行任何优先级或者顺序接口的 再执行BeanFactoryPostProcessor registerBeanPostProcessors(beanFactory);` 注册bean的后置处理器 不同接口类型的BeanPostProcessor, 在Bean创建前后执行时机是不一样的 DestructionAwareBeanPostProcessor InstantiationAwareBeanPostProcessor SmartInstantiationAwareBeanPostProcessor MergedBeanDefinitionPostProcessor 获取所有的BeanPostProcessor beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); 后置处理器都默认可以通过PriorityOrdered,Ordered接口来指定优先级 先注册PritorityOrdered优先级接口的BeanPostProcessor beanFactory.addBeanPostProcessor(postProcessor) 再注册Ordered接口的 最后注册没有实现优先级接口的 最终注册MergedBeanDefinitionPostProcessor 这测一个ApplicationListenerDetector: 在Bean创建完成后检查是否是ApplicationListener, 如果是,this.applicationContext.addApplicationListener 国际化 initMessageSource() 初始化MessageSource组件(做国际化,消息绑定,消息解析) 获取BeanFactory 看容器中是否有id为messageSource的, 类型是MessageSource的组件 如果有赋值给MessageSource, 如果没有, 自己创建一个DelegatingMessageSource 把创建好的MessageSource注册在容器中; 以后获取国际化配置文件值的时候,可以自动注入MessageSource 时间派发器 initApplicationEventMulticaster 初始化事件派发器 获取BeanFactory 从BeanFactory中获取 applicationEventMulticaster (可以自行配置) 如果没有配置, 创建一个SimpleApplicationEventMulticaster 将创建的 applicationEventMulticaster 注入到容器 registerSingleton onRefresh 留给子类 子类可以重写这个方法, 在容器刷新时自定义逻辑 registerListeners 给容器中将所有项目里面的ApplicationListener注册进来 从容器中拿到所有的ApplicationListener 将每个监听器添加到事件派发器中 派发之前步骤产生的事件 初始化Bean finishBeanFactoryInitialization(beanFactory); 初始化所有剩下的单实例bean beanFactory.preInstantiateSingletons(); 初始化 获取容器中的所有Bean, 依次创建和初始化对象 获取Bean的定义信息 RootBeanDefinition Bean不是抽象的, 是单实例的, 不是LazyInit的. 进行创建 判断是否是FactoryBean, 也就是是否实现了此接口-&gt;使用工厂方法创建 不是工厂Bean, 使用getBean(beanName)创建 (这里的方法跟直接调用ioc.getBean一样) getBean(beanName) doGetBean(name, null, null, false); 先获取缓存中保存的单实例Bean, 如果能获取到, 说明这个Bean之前被创建过(所有创建过的Bean都会被缓存起来) private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); 是从这里获取 缓存中获取不到, 开始Bean的创建流程 标记当前bean被创建markBeanAsCreated 获取Bean的定义信息 getMergedLocalBeanDefinition 获取当前Bean依赖的其他Bean getDependsOn;(这个也是配置在Beandepends-on属性上的) 如果有, 按照getBean()把依赖的Bean先创建出来 启动单实例Bean的创建流程 createBean(beanName, mbd, args) Object bean = resolveBeforeInstantiation(beanName, mbdToUse); 让BeanPostProcessor先拦截返回代理对象 先触发applyBeanPostProcessorsBeforeInstantiation 如果有返回值applyBeanPostProcessorsAfterInitialization 如果前面的resolveBeforeInstantiation没有返回代理对象, 向下执行, 如果返回了代理对象, 结束创建. 调用 Object beanInstance = doCreateBean(beanName, mbdToUse, args); 创建Bean实例 obtainFromSupplier 利用Supplier instantiateUsingFactoryMethod 利用工厂方法或构造器 applyMergedBeanDefinitionPostProcessors 调用MergedBeanDefinitionPostProcessor 为属性赋值populateBean 拿到InstantiationAwareBeanPostProcessor后置处理器; 执行postProcessAfterInstantiation方法 拿到InstantiationAwareBeanPostProcessor; 执行postProcessProperties 赋值 应用Bean属性的值; 为属性利用setter方法进行赋值: applyPropertyValues(beanName, mbd, bw, pvs); 初始化 initializeBean 执行Aware接口的方法invokeAwareMethods[如BeanNameAware\\BeanClassLoaderAware\\BeanFactoryAware] 执行后置处理器初始化之前的方法 applyBeanPostProcessorsBeforeInitialization 执行初始化方法 invokeInitMethods(beanName, wrappedBean, mbd); 是否是InitializingBean接口实现, 执行接口规定的初始化 是否是自定义初始化方法, 有则执行invokeCustomInitMethod 执行后置处理器初始化之后的方法applyBeanPostProcessorsAfterInitialization 注册销毁方法 将创建的Bean添加到缓存中singletonObjects 说白了IOC容器就是这种各样的Map; 很多的Map保存了单实例Bean, 各种环境信息; 所有的Bean都利用getBean创建完成后, 检查所有的Bean是否是SmartInitializingSingleton接口的; 如果是, 就执行afterSingletonsInstantiated finishRefresh() 完成BeanFactory的初始化创建工作 -&gt; IOC容器创建完成 initLifycycleProcessor() 获取生命周期有关的后置处理器 LifecycleProcessor 加入到容器中 默认从容器中找, 如果没有 new 一个DefaultLifecycleProcessor 可以写一个 拿到处理器, 调用onRefresh方法 发布容器刷新完成时间publishEvent 至此, 粗略的刷新过程就是这样 总结 Spring容器启动时会保存所有注册进来的Bean的定义信息 xml annotation: @Service @Component @Bean Spring容器会在合适的实际创建Bean 用到这个bean的时候使用getBean方法创建, 创建好后保存在容器中 统一创建所有bean的时候``finishBeanFactoryInitialization` 后置处理器 每一个bean创建, 都会使用各种后置处理器进行处理, 来增强bean的功能 AnnotationAwareAspectJAutoProxyCreator AOP AutowiredAnnotationBeanPostProcessor 处理自动注入 事件驱动器 ApplicationListener 监听 ApplicationEventMulticaster 事件派发器","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"}]},{"title":"JavaWeb知识点","slug":"JavaWeb知识点","date":"2023-01-12T07:05:09.000Z","updated":"2023-01-12T07:31:51.000Z","comments":true,"path":"2023/01/12/JavaWeb知识点/","link":"","permalink":"http://yiiiqing.github.io/2023/01/12/JavaWeb%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"JavaWeb知识点JavaWeb三大组件 Servlet: 处理请求 Filter: 过滤/拦截请求 Listener: 监听器 除了listener的活化钝化和绑定解绑监听器需要javaBean实现,三大组件都需要注册 Filter过滤器使用步骤 实现Filter接口 web.xml中配置 12345678&lt;filter&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.yiqing.MyFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;MyFilter&lt;/filter-name&gt; &lt;url-pattern&gt;&lt;/url-pattern&gt;&lt;/filter-mapping&gt; url-parttern三种写法: 精确匹配: /pics/hello.jsp 路径匹配: /pics/* 拦截pics路径下所有请求 后缀匹配: *.jsp 拦截所有.jsp结尾的请求 原理1234doFilter()&#123; // 放行请求 chain.doFilter(request,response);&#125; Listener8个 ServletRequest(2) HttpSession(4) ServletContext(2) 2个的为生命周期监听器 HttpSession除了这两个还有额外的2个(活化钝化监听器, 绑定解绑监听器) 掌握的监听器ServletContextListener 生命周期监听器 监听ServletContext的创建和销毁(也就是监听服务器的启动和停止). 服务器启动为当前项目创建ServletContext对象, 服务器停止销毁创建的ServletContext对象; ServletContext 一个web项目对应一个ServletContext, 它代表当前项目的信息 可以作为最大的域对象在整个项目运行期间共享数据 监听器使用步骤 实现对应的监听器接口 去web.xml中配置 除了listener的活化钝化和绑定解绑监听器需要javaBean实现(HttpSessionActivationListener, HttpSessionBindingListener)","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"WEB","slug":"WEB","permalink":"http://yiiiqing.github.io/tags/WEB/"}]},{"title":"kafka消息转本地队列多线程消费下发现的问题","slug":"kafka消息转本地队列多线程消费下发现的问题","date":"2022-07-15T05:00:05.000Z","updated":"2022-07-15T09:52:43.000Z","comments":true,"path":"2022/07/15/kafka消息转本地队列多线程消费下发现的问题/","link":"","permalink":"http://yiiiqing.github.io/2022/07/15/kafka%E6%B6%88%E6%81%AF%E8%BD%AC%E6%9C%AC%E5%9C%B0%E9%98%9F%E5%88%97%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%B6%88%E8%B4%B9%E4%B8%8B%E5%8F%91%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"kafka消息转本地队列多线程消费下发现的问题这个问题来源于对于trace系统的改造。 之前的trace消费其实是没有问题的，但是整个trade结构被改造成了本地消息队列的形式，所以trace迁移新库的同时决定统一采用消息队列的形式来进行消费。 trace本地队列主要由两部分组成： 核心线程池master：负责开两个线程池，一个是dispatch，一个是monitor。是一个ScheduledThreadPool，时延由apollo配置控制。 dispatch线程池：负责从kafka拉取信息放入本地队列中，循环拉取，在执行完一批后将会拉去新的一批，跳出条件为running为false。 monitor线程池：负责监控本地队列的占用情况 worker：负责本地队列信息的消费，是一个ThreadPoolExecutor 本地队列：是一个blocking queue 1234567891011121314this.consumer.subscribe(this.getTopic());this.master.scheduleWithFixedDelay(dispatch, KafkaConfig.getKafkaInitDelay(), KafkaConfig.getKafkaThreadFixedDelay(), MILLISECONDS);this.master.scheduleWithFixedDelay(monitor, KafkaConfig.getKafkaMonitorInitDelay(), KafkaConfig.getKafkaMonitorThreadFixedDelay(), MILLISECONDS);this.running = true;for (int i = 0; i &lt; threadNumber; i++) &#123; ConsumeThread consumeThread = getConsumeThread(i); // 会返回一个Runnable this.worker.submit(consumeThread); // 提交worker线程池&#125; 一（消费线程退出版）第一版的构成是不太一样的，思想是队列进来一个Runnable任务，就开启一个消费者线程进行消费，worker会创建一个新的Runnable匿名类消费这一条信息。上线后发现功能无异常，但是会有巨大的创建销毁线程的开销，导致本地消费能力很低 二（消费线程不退出版）因为第一版的问题，为了加大本地消费能力，修改：1修改消费线程为一个while循环，唯一出口为running参数为false2在初始化的时候创建消费线程，交给worker去执行这样的好处是：在队列中有无消息的情况下，这些消费线程都不会退出。节省了线程创建销毁的开销。上线后发现消费能力从3k上涨到5k左右 三第二版上线后发现有服务停止运行的情况。刚开始排查的问题以为是服务问题，以为服务down掉了，检查之后发现状况为：dispatch停止运行，但是monitor却正常运行，日志发现本地队列为空，kafka topic lag持续增长。这么说只有两个原因： kafka将consumer踢出去 dispatch线程池ScheduledThreadPool没有定时执行 加了日志排除了2. 所以只能是1。再进行细化。kafka为什么要踢出我这个消费者？ 稍微查了一下资料，发现==kafka在消费者长期未commit的情况下，将该消费者认为无法消费==，将进行rebalance。在之前代码的逻辑，为了满足业务需求，关闭了kafka自动提交。在trace放入本地队列失败的情况下(采用BlockingQueue的offer方法)，将会重新拉取同一个offset这一批数据，重新消费。但是由于仍然无法消费，所以在这个地方卡住了，kafka就将该消费者踢出去了。 发现问题原因后有以下几个方法能解决（事后总结）： 开启监控本地队列占用情况的线程，在本地队列将满的情况下，sleep dispatch线程。等待consumer消费本地队列。 原有的offer方法更改为put阻塞方法的执行。（本地队列是一个blockingQueue） 增加offer方法的等待时间 每次不再拉取一批数据放入队列, 而是一个逐一手动提交 四没有采用上述2的原因是，put会严重降低效率，也测试了1方法，发现在业务上能实现，但是没有必要尝试更改加长了offer时间，从50ms升高到500ms，发现报错基本消失目前为止应用运行一段时间被kafka踢出消费者组的情况已经解决了。但是又发现了新的问题。 消息有重复消费，因为每次拉取的数目是500条，如果有一条无法消费报错（如400），整段都无法commit。下次将会消费之前的offset。这样第1-399条将会重复消费。如果解决这个问题。需要大改。将消费者改为每次拉取一条的情况，手动指定offset提交，可以完全避免。但是由于成本太大，放弃这个方案。 123// 放入队列的那段代码added = partition.get(index) .offer(record.value(), KafkaConfig.getFastConsumerPartitionTimeout(), MILLISECONDS); 五 最终版吸取了之前的经验。最终版做了以下优化： 合理调节offer时间，使本地引用的消费能力与kafka本地队列的存放能力达到平衡。 在dispatch方法中加入错误跳出机制。 之前dispatch是一直循环拉kafka数据，就算error，也会立即重新拉，这样在本地线程阻塞的时候，会在瞬间频繁出现error。导致kafka踢出consumer。(也就是在拥塞的时候还会放东西进去) 修改为: 一旦发现不能添加，直接跳出整个dispatch方法(之前是只要拉取的数据不为空一直在dispatch,没有起到定时的作用)。这样可以在ScheduledThreadPool下次开启dispatch之间(dispatch前文说过是定时的)不再拉取新的kafka数据。给与本地队列喘息时间被消费。 结合2通过设置dispatch线程池重启时间进行合理调节 12345678910111213141516171819202122while (!records.isEmpty()) &#123; if (!running) &#123; return; &#125; boolean added = true; for (ConsumerRecord&lt;String, T&gt; record : records) &#123; int hashCode = record.key().hashCode(); final int index = Math.abs(hashCode % threadNumber); added = partition.get(index) .offer(record.value(), KafkaConfig.getFastConsumerPartitionTimeout(), MILLISECONDS); if (!added) &#123; break; &#125; &#125; if (added) &#123; consumer.commitAsync(); records = consumer.poll(KafkaConfig.getConsumerPollTimeout()); &#125; else &#123; // 无法加入本地队列, 消费能力不足, 等待消费. break; &#125; &#125; 六 最终版plus没想到还是运行了一段时间就down掉了。检查了jvm和容器状态推测，在down掉的时间cpu很高，基本在200左右。所以是因为cpu使用率太高导致容器重启。cpu和线程直接挂钩，于是降低了数据库连接池个数(之前错误开了很大的连接池)，将cpu使用率由200降到了150。但是核心原因是：为什么重启后consumer就不能消费了呢？**分析: **容器在重启前会调用shutdown方法。之前的shutdown方法只关闭了master线程池，并没有关闭consumer线程池。这导致容器关闭前consumer拉取的那一批数据无法被消费。kafka将流量压力又只给了一个容器（容器重启前的最后一个，基于重启前的rebalance结果） 查阅kafka官方文档: 如果你没有在程序退出前很好关闭consumer，最明显的行为主是在下次启动程序消费数据时会发现consumer分配分区的过程可能非常慢，还有一个问题是Kafka不能立即知道consumer已经退出，如果同组在其他地方有其他消费者，rebalance要在心跳超时后才分触发 在shutdown方法中增加了consumer.close() 再结合上述的最终版, 最终这个服务达到了稳定.","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://yiiiqing.github.io/categories/Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yiiiqing.github.io/tags/Kafka/"}]},{"title":"设计模式-工厂模式","slug":"设计模式-工厂模式","date":"2021-11-10T03:12:22.000Z","updated":"2021-11-10T03:13:40.000Z","comments":true,"path":"2021/11/10/设计模式-工厂模式/","link":"","permalink":"http://yiiiqing.github.io/2021/11/10/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"设计模式-单例模式","slug":"设计模式-单例模式","date":"2021-11-09T11:32:10.000Z","updated":"2021-11-09T13:23:54.000Z","comments":true,"path":"2021/11/09/设计模式-单例模式/","link":"","permalink":"http://yiiiqing.github.io/2021/11/09/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"设计模式-单例模式单例模式, 就是采取一定方法保证在整个软件系统中, 对某个类只能存在一个对象实例, 并且该类只提供一个取得其对象实例的方法(静态方法) 使用场景 需要频繁进行创建和销毁的对象 创建对象耗时过多或耗费资源过多(重量级对象), 但又常用到的对象 工具类对象 频繁访问数据库或文件的对象(DataSource, session工厂) 八种方式饿汉式(静态常量) 构造器私有化 类的内部创建对象 对外暴露一个静态的公共方法 1234567891011121314class Singleton &#123; // 私有化, 外部不能new private Singleton() &#123; &#125; // 内部创建对象 private final static Singleton instance = new Singleton(); public static Singleton getInstance() &#123; return instance; &#125;&#125; 优缺点: 优点: 写法比较简单, 类装载时候就完成实例化. 避免了线程同步问题 缺点: 在类装载的时候就完成实例化,没有达到Lazy Loading的效果. 但是, 导致类装载的原因有很多种. 如果从始至终没有用到这个实例, 将会造成==内存浪费== 饿汉式(静态代码块) 与上面相似, 只不过将类实例化放在了静态代码块. 123456789101112131415161718class Singleton &#123; // 私有化, 外部不能new private Singleton() &#123; &#125; // 在静态代码块中创建 static &#123; instance = new Singleton(); &#125; // 内部创建对象 private final static Singleton instance; public static Singleton getInstance() &#123; return instance; &#125;&#125; 优缺点: 与上面类似, 通过jvm加载机制可以知道, static代码块和static常量的初始化在jvm编译器优化后, 其实是合并在一起的(等价), 执行先后顺序由代码的先后顺序评定 注意: 因为clinit方法是线程安全, 所以加载类的时候如果static加载的东西太多也会很慢 ==内存浪费== final的作用: 加final修饰的对象, 在连接-准备阶段就已经赋值, 没有final的在初始化阶段赋值 懒汉式(线程不安全)12345678910111213141516class Singleton &#123; private static Singleton instance; private Singleton() &#123; &#125; // 提供一个静态的共有方法, 只有使用到这个方法的时候,才会创建单例对象 // 懒汉式 public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 优缺点: 起到了Lazy Loading的效果, 但是只能在单线程下使用 多线程下, 一个线程进入了if (instance == null)语句块后, 还没执行后, 另一个线程也进入了这个语句块. 就会产生多个实例. ==实际开发不要使用这种方式== 懒汉式(线程安全, 同步方法)12345678910111213141516class Singleton &#123; private static Singleton instance; private Singleton() &#123; &#125; // 提供一个静态的共有方法, 加入同步处理的代码, 解决线程安全问题 // 懒汉式 public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 优缺点: 解决了上述的线程不安全的问题 效率低. 因为只有在第一次才会初始化instance, 其他的时间getInstance方法只是为了获取而已, 这样加入synchronized将会降低很多效率 ==实际开发中不推荐== 懒汉式(线程不安全,同步代码块)123456789101112131415161718class Singleton &#123; private static Singleton instance; private Singleton() &#123; &#125; // 提供一个静态的共有方法, 加入同步处理的代码, 解决线程安全问题 // 懒汉式 public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class)&#123; instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 优缺点: 不能起到线程同步的作用: 这样写也没有用! 和上面是一样的, 因为只要if判断结束进入if块中, 线程排队执行同步代码块, 第一个执行完了后, 第二个仍旧要执行! 连线程安全都做不到 ==实际开发中不能使用== 双重检查1234567891011121314151617181920class Singleton &#123; private static volatile Singleton instance; private Singleton() &#123; &#125; // 提供一个静态的共有方法, 加入双重检查锁 // 懒汉式 public static Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 优缺点: Double-Check概念其实是在多线程开发中经常用到的. 实例化代码只执行了一次 线程安全; 延迟加载; 效率较高 ==开发中推荐使用== 静态内部类静态内部类的特点就是: 当外部类装载的时候, 内部类是不会装载的. 当getInstance的时候只会装载一次, 还能保证线程安全 jvm在装载类的时候是线程安全的 1234567891011121314151617class Singleton &#123; private static volatile Singleton instance; private Singleton() &#123; &#125; // 写一个静态内部类, 该类中有一个静态属性 Singleton private static class SingletonInstance &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonInstance.INSTANCE; &#125;&#125; 优缺点: 采用了类装载的机制来保证初始化实例时只有一个线程. jvm帮助我们保证了线程的安全性, 在类初始化时, 别的线程无法进入 ==推荐使用== 枚举123456enum Singleton&#123; INSTANCE; public void sayOK()&#123; System.out.println(&quot;ok&quot;); &#125;&#125; 优缺点: jdk1.5+后实现的枚举 避免多线程同步问题 防止反序列化重新创建新的对象 其他方法都可以通过反射破坏, 只有枚举不可以 ==强烈推荐== 总结推荐使用: 饿汉式(静态常量) 饿汉式(静态代码块) 懒汉式(线程不安全) 懒汉式(线程安全,同步方法) 懒汉式(线程不安全,同步代码块) 双重检查 静态内部类 枚举 所以懒汉式团灭 = = jdk中单例模式的应用: Runtime类, 使用了饿汉式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://yiiiqing.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://yiiiqing.github.io/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"http协议","slug":"http协议","date":"2021-11-05T07:23:45.000Z","updated":"2021-11-08T07:56:09.000Z","comments":true,"path":"2021/11/05/http协议/","link":"","permalink":"http://yiiiqing.github.io/2021/11/05/http%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"http协议前一阵子跟着宋红康老师学了一遍 jvm, 收获颇深. 因为追求看视频的速度问题所以没有去做笔记. 后期回忆起来可能记忆犹如无根浮萍一般. 所以以后还是打算能记笔记就记笔记. http tcp udp 什么的, 其实学过很多了遍. 就计算机网络来说, 本科学了一遍, 选修课刷 GPA 又选修了一遍, 研究生又学了一遍. 可以说是学了三遍了. 但是现在回想起来, 框架还在, 但是具体的细节比如 tcp 滑动窗口之类的还是忘记了, 还是要经常回忆复习的好. 网络分层复杂的网络由于网络环境来说, 会有数据丢包, 数据重复, 完整性校验, 信号衰减等等问题. 为了处理这种问题, 国际标准组织对于整个网络体系进行了分层, 同时也规定了每一层的交互规则. 为了解耦与可拓展性(这里其实类似于 Java 中的接口的作用) 分层方法两种分层方法: OSI 和 TCP/IP 一个 http 请求的分层解析流程 在浏览器输入域名回车 域名解析 为什么解析? 网络中两端进行交互只认 ip 地址 首先查浏览器有没有这个 DNS 的缓存 如果没有去计算机本地 host 文件查看 如果没有, 发起 DNS 请求 DNS 也是服务器, 也有自己的 IP 地址, 是配在操作系统的 DNS 是使用 UDP 协议的, 传输层会加一个 UDP 请求头 DNS 有时候会用 TCP, 如果相应的内容超过 512 字节, 或者使用区域传送 加一个网络层 IP 请求头 传送到数据链路层, 数据链路层加上自己的头, 并且加入下个机器的 MAC 地址(从网络层的 ARP 协议而来https://blog.csdn.net/ever_peng/article/details/80008638) 传送到路由器上面 路由器是三层的(网络,数据链路,物理层), 不同于交换机(物理,数据链路) 路由器解析刚才收到的消息 从物理层开始 数据链路层会查看 MAC 地址是否给与, 是的话交给网络层 网络层查看数据应该传送的下一个路由器是多少, 这里一般是传送到服务商的路由器 运营商解析地址并返回 DNS 信息 返回到路由器, 从网络层解析到物理层 返回到计算机 从物理层开始 检查 IP 头(网络层) 检查UDP协议头(传输层) DNS 拿到信息(应用层) 根据 DNS 获取的信息, 发送 http 协议 开始类似上面逐层加协议头 发送到路由器 路由器发送到运营商ISP找到目标服务器 到达目标服务器 物理层 数据链路层解析 网络层解析 传输层解析, 这一层会解析端口, 比如 80 应用层解析, 交给对应端口的应用程序 应用程序构造一个 http 的响应报文回传 收到目标服务器的回传报文 这里依然是逐层的 ==上面写的有点长, 其实脑海里在思考 http 协议交流过程的时候, 只需要建立两个塔状的模型, 一个是源计算机, 一个是目标计算机, 所有的交流都是从一方最高到对方最高. 牢记这一点即可== HTTP协议HyperText Transfer Protocol 五大特点 支持 c/s 模式 简单快速 灵活 无连接: 限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 因为HTTP诞生之初，主要是为了应付容易很小的文本传输，所以即使这样也没多大的问题 为了解决TCP连接问题, HTTP1.1提出了持久连接 所以说这个无连接其实算是过去式 无状态: HTTP协议无法根据之前的状态进行本次的请求处理 为了解决无状态, 引入cookie技术 说白了五大特点简直是人硬凑的, 不过也是有时代因素吧, 现在看来只需要记住后面两个就可以了: ==无连接, 无状态== 注意: 无连接是应用层面上的无连接! 要从应用层去理解 HTTP报文格式 起始行(请求行) 请求: GET /index.html HTTP/1.1 构成: METHOD+空格+URI+空格+VERSION+换行 返回: HTTP/1.1 200 OK 构成: VERSION+空格+STATUS CODE+空格+REASON+换行 头部字段集合 Connection: keep-alive … 空行 消息正文 http协议还有很多, 暂时先跳过 TCP协议Transmission Control Protocol 面向连接的, 可靠的, 基于字节流的传输层通信协议 特点 基于连接的: 数据传输之前都要建立连接 全双工: 双向传输 字节流: 不限制数据大小, 打包成报文段, 保证有序接收, 重复报文自动丢弃 因为网络,数据到达很可能乱序, 接收端需要重排序 给到应用层肯定是排序后的 流量缓冲: 解决双方处理能力的不匹配 可靠的传输服务: 保证可达, 丢包时通过数据重发机制实现可靠性 拥塞控制: 防止网络出现恶心拥塞 TCP连接四元组: 源地址, 源端口, 目的地址, 目的端口 三次握手 一个小的知识点: 为什么ack是x+1呢? 官方的回答是: The server responds to the client with a sequence number of zero, as this is its first packet in this TCP session, and a relative acknowledgement number of 1. The acknowledgement number is set to 1 to indicate the receipt of the client’s SYN flag in packet #1. Notice that the acknowledgement number has been increased by 1 although no payload data has yet been sent by the client. This is because the presence of the SYN or FIN flag in a received packet triggers an increase of 1 in the sequence. (This does not interfere with the accounting of payload data, because packets with the SYN or FIN flag set do not carry a payload.) 也就是由于SYN或者FIN标志位的存在,造成了sequence的增加. +1是针对SYN和FYN的，主要是在没有数据传输的情况下，告诉发送端我收到了你之前发的这俩标示（的其中一个） 这个+1是基于对方的seq来加的 感谢这篇文章的参考:https://blog.csdn.net/oldfish_C/article/details/105150516 linux可以通过`netstat -来查看tcp连接的状态 可以通过telnet [ip] [port] 建立tcp连接 四次挥手两端都可以关闭连接, 在此将主动关闭的称为client 图中的M和N和上面图中x和y是一样的含义, 只是因为分开画的表示不一样. server在close_wait阶段仍然可以发数据, 发送结束后发送FIN client time_wait阶段等待一个来回的时间(2MSL)==面试高频== 防止滞留在网络中的报文, 对新建立的连接造成数据扰乱(确保close_wait阶段的内容被收到) 防止报文丢失(也就是图中最后一个ACK), 导致server重复发送FIN 字节流的协议 TCP把应用层的数据看成一连串的无结构的字节流; 数据将会被切割成小报文; TCP根据报文的序列号进行排序 TCP并不知道字节流的含义 TCP并不关心应用程序一次将多大的报文发送到TCP的缓存中, 而是根据对方给出的窗口和当前网络的拥堵程度来决定一个报文段应该包含多少字节 MSS: Max Segment Size. 默认 536byte 实际数据 报文没有收到ack消息的话将会重传 数据可靠性传输停止等待协议即发送一个分组就停止发送, 等待对方确认, 确认后再发送下一个分组 重传机制 ack报文丢失: 请求报文收到但是回复的ack报文丢失, 也会导致重传 请求报文丢失: 直接是请求报文丢失, 那么自然不会ack, 所以会超时重传 滑动窗口协议与累计确认(延时ack) 因为停止等待和重传机制非常的效率低下, tcp通过这个协议解决信道效率低,增加吞吐量. 上面提到 ack 其实非常浪费时间, 那么如何破除停止等待协议? 使用滑动窗口协议. 允许发送方在停止并等待确认前发送多个数据分组. 由按序到达的最后一个分组发送确认. 发送确认即表明这个窗口全部收到, 那么窗口将会滑动到后面. 12345全部收到, 窗口将会滑动到6; 如果12345只收到了1245, 发送的确认信息告诉对方3没有收到, 那么窗口将会滑动到3 滑动窗口大小通过tcp三次握手和对端协商, 且受网络状况影响. HTTPS协议HTTP天生”明文”, 整个传输过程透明. HTTPS就是为了安全而诞生的 HTTPS其实就是HTTP的基础上增加了一个安全层. 在HTTP和TCP之间使用SSL/TLS构成安全层. 原本HTTP直接与TCP交互 使用安全层后, HTTP层与安全层交互, 安全层再与TCP交互 SSL/TLSSSL: 安全套接层(Secure Sockets Layer) TLS: 传输层安全(Transport Layer Security). 1999年IETF将SSL改名为TLS. 现已发展到1.3. 版本紧跟密码学研究. 摘要算法md5, sha1, sha2, sha256 摘要算法能把任意长度的数据”压缩”成固定长度, 并且独一无二. 所以通过将明文的信息的摘要和明文一起加密进行传输, 数据接收方解密, 重新对数据进行摘要, 再比对就可以发现数据有没有被篡改. 保障了数据的完整性. 加密算法 对称密钥加密算法 编解码使用相同密钥 AES, RC4, ChaCha20 经典实现: xor异或 将原文与密钥异或得到密文 非对称密钥加密算法 一个叫公钥, 一个叫私钥. 公钥公开, 私钥保密. 发送方用公钥加密数据传输, 密文只能由私钥持有者(接收方)才可能解密. 需要大量数学运算, 比较慢. TLS里使用的混合加密方式, 即把对称加密和非对称加密结合起来, 两者互相取长补短. 通信开始使用非对称算法解决密钥交换的问题. 对方服务器发送公钥(公钥数字证书). 在连接之初client发送有一个加密套件列表进行 服务器在client支持的加密套件中选择一个加密套件返回公钥数字证书 密钥交换之后, 使用对称加密来传输数据 这里有一个重点, 就是, 我是通过这种方式来保证传输安全了, 那万一对面根里其实就烂了(server就是fake)呢? 这样我们需要一个方法来确保公钥是正确的server发送的. 这里就出现了一个机构也就是CA机构. 所以其实上面发送的公钥是一个公钥数字证书, 是由CA机构颁发的. 证书包含CA信息, 公钥用户信息, 公钥, 权威机构的签名, 有效期等等. 那肯定我就又有疑问了. 那CA也烂了咋办? 所以其实CA证书是一个证书链, 逐层向上验证, 一直到最后有一个根证书来提供最后的保障. 这个不是走互联网的, 这个是操作系统写入的. 所以也就是说我们确保了最最根部的CA证书是正确的, 剩下的逐层验证即可. 到此为止也算是把http和tcp还有https过了一遍了, 深度肯定还不够, 譬如tcp的拥塞控制还没有写. 这个我觉得需要另开一个篇章去写, 就不放到http协议这里了. 拥塞控制可以参考这篇文章: https://zhuanlan.zhihu.com/p/37379780 OK! 努力年薪百万.","categories":[{"name":"网络","slug":"网络","permalink":"http://yiiiqing.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"http","slug":"http","permalink":"http://yiiiqing.github.io/tags/http/"},{"name":"tcp","slug":"tcp","permalink":"http://yiiiqing.github.io/tags/tcp/"}]},{"title":"Docker启动常用工具大全","slug":"Docker启动常用工具大全","date":"2021-10-18T10:43:45.000Z","updated":"2021-10-18T11:29:22.000Z","comments":true,"path":"2021/10/18/Docker启动常用工具大全/","link":"","permalink":"http://yiiiqing.github.io/2021/10/18/Docker%E5%90%AF%E5%8A%A8%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%A4%A7%E5%85%A8/","excerpt":"","text":"Docker 启动常用工具大全平时经常使用 docker 启动一些服务, 比如数据库, redis, es 什么的, 每一个启动命令都不一样. 在这里统一做一个总结. docker hub 镜像仓库地址: https://hub.docker.com/ MongoDB12docker pull mongo:latestdocker run -itd --name mongo -p 27017:27017 mongo --auth –auth: 需要密码才能访问容器服务 12345$ docker exec -it mongo mongo admin# 创建一个名为 admin，密码为 123456 的用户。&gt; db.createUser(&#123; user:&#x27;admin&#x27;,pwd:&#x27;123456&#x27;,roles:[ &#123; role:&#x27;userAdminAnyDatabase&#x27;, db: &#x27;admin&#x27;&#125;,&quot;readWriteAnyDatabase&quot;]&#125;);# 尝试使用上面创建的用户信息进行连接。&gt; db.auth(&#x27;admin&#x27;, &#x27;123456&#x27;) RabbitMQ注意选择 management 的版本才有网页端 12docker pull rabbitmq:3.7.14-managementdocker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:3.7.14-management 然后打开http://localhost:15672/可以看到管理界面 默认账号: guest 默认密码: guest","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/tags/Docker/"}]},{"title":"Java-单例模式实现","slug":"Java-单例模式实现","date":"2021-10-08T12:52:50.000Z","updated":"2021-10-09T01:58:58.000Z","comments":true,"path":"2021/10/08/Java-单例模式实现/","link":"","permalink":"http://yiiiqing.github.io/2021/10/08/Java-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"Java单例模式实现学习枚举类的时候看到了一篇文章, 其中大致总结了几种单例模式的写法, 正好我也抽空自己整理一下 简介什么是单例模式? 其实是一种最常使用的设计模式, 也就是确保某个类只有一个实例, 而且这个类能自行实例化并向整个系统提供这个实例. 应用在: 线程池, 缓存, 日志对象, 对话框对象等. 实现饿汉式12345678910111213public class SingletonHungry &#123; private static SingletonHungry instance = new SingletonHungry(); private SingletonHungry() &#123; &#125; public static SingletonHungry getInstance() &#123; return instance; &#125; &#125; 比较简单的一种写法 在类加载的时候就会创建对象, 但是有一个问题就是如果这个类依赖于很多资源, 那么创建必定比较耗时. 所以我们希望他能够延迟加载, 减少初始化负载, 从而就有了懒汉式单例实现 懒汉式123456789101112131415public class SingletonLazy &#123; private static volatile SingletonLazy singletonLazy; private SingletonLazy() &#123; &#125; public static synchronized SingletonLazy getInstance() &#123; if (singletonLazy == null) &#123; singletonLazy = new SingletonLazy(); &#125; return singletonLazy; &#125;&#125; 这样写, 就具备了懒加载的特点. 并且为了能够在多线程中更好的工作, 加入了 synchronized 关键字. 优点自然是可以更好的同步, 缺点就是因为 synchronized, 效率会变低. volatile 关键字打算再另一篇里面写, 简单描述一下就是: 第一层语义是可见性，可见性是指在一个线程中对该变量的修改会马上由工作内存（Work Memory）写回主内存（Main Memory），所以其它线程会马上读取到已修改的值，关于工作内存和主内存可简单理解为高速缓存（直接与CPU打交道）和主存（日常所说的内存条），注意工作内存是线程独享的，主存是线程共享的。volatile的第二层语义是禁止指令重排序优化，我们写的代码（特别是多线程代码），由于编译器优化，在实际执行的时候可能与我们编写的顺序不同。编译器只保证程序执行结果与源代码相同，却不保证实际指令的顺序与源代码相同，这在单线程并没什么问题，然而一旦引入多线程环境，这种乱序就可能导致严重问题。volatile关键字就可以从语义上解决这个问题，值得关注的是volatile的禁止指令重排序优化功能在Java 1.5后才得以实现，因此1.5前的版本仍然是不安全的，即使使用了volatile关键字。 为了优化这个缺点, 在单线程的情况下, 去掉 synchronized 关键字. 双重检查锁123456789101112131415161718public class Singleton &#123; private static volatile Singleton singleton = null; private Singleton() &#123; &#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 双重检查锁进行了两次 null 检查. 因为在 getSinleton 调用的时候并没有进入同步代码, 外面的检查是并发的, 并且过滤了绝大多数的 null 检查. 当出现 null 的时候进入同步代码再进行一次检查. 这样极大提升了并发度, 也提升了性能. 但是有一个问题, 就是 volatile 关键字是 1.5 才实现的禁止指令重排, 所以可以使用静态内部类 静态内部类123456789101112public class SingletonInner &#123; private static class Holder&#123; private static SingletonInner singleton = new SingletonInner(); &#125; private SingletonInner()&#123;&#125; public static SingletonInner getInstance()&#123; return Holder.singleton; &#125;&#125; 我们把Singleton实例放到一个静态内部类中，这样可以避免了静态实例在Singleton类的加载阶段（类加载过程的其中一个阶段的，此时只创建了Class对象）就创建对象，毕竟静态变量初始化是在SingletonInner类初始化时触发的，并且由于静态内部类只会被加载一次，所以这种写法也是线程安全的 共同缺点 序列化可能会破坏单例模式. 因为每次反序列化一个序列化的对象会创建一个新的实例, 解决方案: 1234567891011public class Singleton implements java.io.Serializable &#123; public static Singleton INSTANCE = new Singleton(); protected Singleton() &#123; &#125; //反序列时直接返回当前INSTANCE private Object readResolve() &#123; return INSTANCE; &#125; &#125; 使用反射强行调用私有构造器. 解决方案: 修改构造器, 让他在创建第二个实例的时候抛异常 12345678910public static Singleton INSTANCE = new Singleton(); private static volatile boolean flag = true;private Singleton()&#123; if(flag)&#123; flag = false; &#125;else&#123; throw new RuntimeException(&quot;The instance already exists ！&quot;); &#125;&#125; 优化上面的四类模式有了, 共同的缺点也能解决了, 但是代码复杂度也上去了, 更高效的方法就是枚举单例. 12345678910public enum SingletonEnum &#123; INSTANCE; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 无比简洁! 使用枚举单例我们还不需要考虑序列化和反射的问题, 因为枚举序列化是由jvm保证的，每一个枚举类型和定义的枚举变量在JVM中都是唯一的，在枚举类型的序列化和反序列化上，Java做了特殊的规定：在序列化时Java仅仅是将枚举对象的name属性输出到结果中，反序列化的时候则是通过java.lang.Enum的valueOf方法来根据名字查找枚举对象。同时，编译器是不允许任何对这种序列化机制的定制的并禁用了writeObject、readObject、readObjectNoData、writeReplace和readResolve等方法，从而保证了枚举实例的唯一性 这里要深入了解可以查看 Enum 类的 valueOf 方法. 总结就是: 创建枚举实例只有编译器能做到 单例模式的几个重点需要我们一直注意: 线程安全 延迟加载 序列化与反序列化安全 反射安全","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://yiiiqing.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/tags/Java/"},{"name":"单例模式","slug":"单例模式","permalink":"http://yiiiqing.github.io/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"make命令","slug":"make命令","date":"2021-09-26T14:06:14.000Z","updated":"2021-09-26T14:09:10.000Z","comments":true,"path":"2021/09/26/make命令/","link":"","permalink":"http://yiiiqing.github.io/2021/09/26/make%E5%91%BD%E4%BB%A4/","excerpt":"","text":"make 命令最近工作中看到了 make 命令 直接看这个教程简单学了一下https://www.ruanyifeng.com/blog/2015/02/make.html 有空自己再补","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/tags/Linux/"}]},{"title":"tmux使用","slug":"tmux使用","date":"2021-09-26T13:39:23.000Z","updated":"2021-09-26T13:48:45.000Z","comments":true,"path":"2021/09/26/tmux使用/","link":"","permalink":"http://yiiiqing.github.io/2021/09/26/tmux%E4%BD%BF%E7%94%A8/","excerpt":"","text":"tmux 使用最近项目中需要 ssh 到堡垒机上运行一个脚本, 但是由于SRE那边的设置, 连接一段时间后就会断开连接. 导致长时间脚本立刻停止运行 然后发现使用 tmux 可以解决这个问题 简介tmux 的英文名是 terminal multiplexer, 荣用户可以在一个终端内管理多个分离的会话 优点: 不受断网影响, 可以保存工作进度 原理正常情况下, ssh 到 server, 当 ssh 断掉之后, server 会 kill 掉程序 如果使用 tmuxtmux 这边采用 c/s 结构, 键入 tmux, tmux 服务器会启动, 并创建一个 session. 也就是一个 bash 环境. 重点是这个环境是与当前 ssh 连接独立. 这样 ssh 断开不会影响这个 session. 使用1234567891011# 进入Linux机器ssh &lt;your host name&gt;# 安装tmuxsudo apt install tmux # 对每一个需要持续运行的程序$ cd &lt;your working directory&gt; # go to the corresponding working drectory$ tmux new -s &lt;your session name&gt; # create new tmux session$ &lt;command to start your server&gt;$ control + b d # to detach 常用 tmux 命令在 shell 主进程下， 可以用以下命令操作 tmux session Function（作用） Command （命令） 新建有命名的 tmux session tmux new -s session-name 列出所有 tmux session tmux ls 进入上一次的 tmux session tmux a (a 指 attach ) 进入名称为 test 的 tmux session tmux a -t test （-t 指 target） 删除名称为 test 的 tmux session tmux kill-session -t test 删除所有的 tmux session tmux kill-server 在 tmux session下， 可以用以下命令操作 tmux session先按前缀快捷键 control+b $ 重命名当前session s 弹出列表，可以选择进入不同 session d detach sessio，返回至 shell 主进程 tmux 其他用处可以屏幕共享, 如果 A 创建一个 session, B ssh 到此机器 tmux attach session, 这样 A 和 B 就可以看到互相的 session 的操作. 参考资料 https://www.cxyzjd.com/article/u014261408/89931729 https://www.jianshu.com/p/8be9e77f4284","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/tags/Linux/"}]},{"title":"计算机组成原理学习笔记","slug":"计算机组成原理学习笔记","date":"2021-09-26T02:19:52.000Z","updated":"2021-10-18T03:44:18.000Z","comments":true,"path":"2021/09/26/计算机组成原理学习笔记/","link":"","permalink":"http://yiiiqing.github.io/2021/09/26/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"计算机组成原理学习笔记最近发现自己离科班出身差了”挂科四大件” 计算机组成原理 操作系统 数据结构(已完成) 计算机网络 其中数据结构学习了”大话数据结构”这本书,基本算是没问题. 正在通过刷算法题强化算法. 未来会啃一遍算法第四版 现在开始学习计算机组成! ==学习是跟着 b 站的视频学习的, 所以其实也包含了很多视频的截图.== 视频地址:https://www.bilibili.com/video/BV1BE411D7ii?p=1 1. 基本概念1.1 计算机分类与发展方向1.2 结构1.2.1 系统结构指令和数据流 单指令&amp;单数据流 SISD: 冯诺依曼体系结构 冯诺依曼体系结构见博客: https://blog.csdn.net/fayfayfaydyt/article/details/81603250 单指令流&amp;多数据流 SIMD: 阵列处理器, 向量处理器 多指令流&amp;单数据流 MISD: 实际不存在 多指令流&amp;多数据流 MIMD: 多处理器, 多计算机. 类似分布式 左上角为冯诺依曼结构计算机 右上角为现代结构计算机 注意理解图中各个箭头的意义 个人理解: 计算机是输入到输出, 所以要有输入设备和输出设备 输入到输出需要计算,所以左上角图中,中间由运算器连接 整个流程需要控制, 所以输入输出运算器均由控制器控制(虚线) 我们需要让输入连续一串,而不是一个一个,所以需要地方存储输入的数据和指令, 所以有了存储器,存储器与运算器直接数据交互 又因为控制器需要控制逻辑运算流程,所以存储器和控制器也直接数据交互(左上角图完成) 如果将运算器独立出来作为运算职能, 将存储器与运算器位置交换, 可以得到右上角图. 右上角图的优势是总线变宽 上面两张图进行分类得到左下角的图, 可以知道 CPU 和 IO 设备的由来, 这也就组成了右下角的计算机 1.2.2 CPU 及工作过程==cpu 的任务: 到内存中取指令; 按指令的指示进行下一步工作== 运算器和控制器 计算机工作过程-取数指令 1.2.3 I/O 设备1.2.4 软件系统机器语言: 二进制代码10000,0000,000000010000 如果 0000 代表 LOAD 操作, 0001 代表 STORE 操作. 可以使用汇编语言使人类能看懂 汇编语言 Assembly language : 助记符所以, 汇编语言也就是一种助记符. 1LOAD A,16 16 号单元数据与 17 号单元数据相加存回 17 号单元: 1234LOAD A,16LOAD B,17ADD C,A,BSTORE C,17 汇编语言通过汇编器转换为机器语言 汇编语言其实也不是我们平时在生活中使用的符号, 所以就有了高级语言 高级语言: C/C++, Java123c = a + bd = a + be = b + c 高级语言通过编译器编译为汇编语言 1.2.5 计算机系统的层次结构 微指令是为了复用机器指令 冯诺依曼计算机“存储程序”: 将指令以代码的形式实现输入到计算机主存储器中, 然后按其在存储器中的首地址执行程序的第一条指令, 以后就按照程序的规定顺序执行其他指令, 直至程序执行结束. 计算机硬件由运算器,存储器,控制器,输入设备,输出设备 5 大部件 指令和数据以同等地位存于存储器内,并可按地址寻访 指令和数据军用二进制码表示 指令由操作码和地址码组成, 操作码用来表示操作的性质, 地址码用来表示操作数在存储器中的位置 指令在存储器内按顺序存放. 通常指令是顺序执行的, 特定条件可以根据设定的条件改变 早期的冯诺依曼机以运算器为中心, 输入/输出设备通过运算器与存储器传送数据 1.2.6 存储器 注意存储元的存储原理 我们将诸多的存储元放在一行构成了存储单元. 许多存储单元构成了存储体 图中绿色线表示连通的, 所以我们需要图中的红色线来表明我们取的是哪一行存储单元. 红色线的数值用 0 和 1 表示,1 表示选取该行. 于是有了另一个设备: 译码器. 用来指定输入/输出的存储单元. 因为用二进制表示, 所以 3 根输入线可以表示 8 排存储单元. 图中的设备名为 3-8 译码器 尽管设计上 MDR 和 MAR 是属于内存, 但是实现上是放在了 CPU 中的, 目的是为了加快速度 1.3 性能指标1.3.1 容量首先得了解一下存储器的容量 ![image-20210928113143786](/Users/yiqing/Library/Application Support/typora-user-images/image-20210928113143786.png) 一个存储元只能存储二进制的一位, 也就是一个 bit. 一个存储单元是八个存储元,也就是 1Byte 所以可以计算出总容量 译码器依赖于地址寄存器. 如果译码器加一根线, 可以支持的存储单元就多一倍. 所以系统所能支持的最大容量取决于地址寄存器. 已经达到上限的话,添加右侧的存储单元也是无意义的. 1.3.2 速度几个方面可以衡量计算机的速度 CPU 执行速度时钟周期的倒数就是主频 ![image-20210928144404954](/Users/yiqing/Library/Application Support/typora-user-images/image-20210928144404954.png) MIPS (Million Instructions Per Second): 每秒执行多少百万条指令 数据通路带宽数据总线一次所能并行传送信息的位数 吞吐量系统在单位时间内处理请求的数量 响应时间指从用户向计算机发送一个请求,到系统对该请求做出相应并获得它所需要的结果的等待时间. 通常包括 CPU 时间,与等待时间(磁盘,存储器,IO,系统开销) 2 数制与编码2.1 计数法和编码2.1.1 进数计数法基数: 每个数位所用到的不同符号的个数 基数大(十进制) 基数小(二进制) 位数 少 多 运算(乘法为例) 100 种情况(10*10) 4 种情况(2*2) 计算机选择二进制的原因: 方便对应到物理器件的状态, 如高电平, 低电平 2.1.2 进制转换 (重点)进制说白了只是因为每一位的权值不同, 比如 75 = 7 * 10 + 5 这个权重叫做位权 十进制和任意进制的转换根据位权的推算, 我们可以通过一种除基取余法来转换. 二进制和其他进制的转换n 位一组法 真值和机器数 2.1.3 BCD 码BCD 即 Binary Coded Decimal 注意如果超出 9, 则不在映射表中, 这种情况需要加 6 叫做加6修正 我感觉就是模拟十进制的进位, 使二进制表示方法下进位 除了 8421 码还有: 余 3 码, 其实也就是将 8421 平移了 2421 码, 也就是将最高位权重变为 2 2.1.4 字符ASCII 码: 大写字母: 65-90 小写字母: 97-122 需要记住的是 A 是 65 而且实际存放的是 ASCII 码对应的二进制形式 2.1.5 奇偶校验码距: 两个合法码字对应位上数字的不同位的个数 奇偶校验其实就是增加了一个校验位, 用来使整个奇偶校验码”1”的个数为奇数或偶数 示例: 给出两个编码 1001101 和 1010111 的奇校验码和偶校验码 假设最高位为校验位, 剩下 7 位为信息位, 则对应的奇偶校验码为: 奇校验: 11001101 01010111 (第一个本身 1 不是奇数个,加一个 1 变成奇数个, 第二个本身就是奇数个,所以补一个 0) 偶校验: 01001101 11010111 2.1.6 汉明码汉明码的设计思路: 分组校验 -&gt; 多个校验位 -&gt; 校验位标注出错位置 汉明码的实际过程和校验方法略 2.1.7 循环冗余校验码略 2.2 定点数的表示和运算2.2.1 无符号数和及原码无符号数: 整个机器字长的全部二进制位均为数值位, 没有符号位, 相当于数的绝对值 原码: 就是符号位加上了绝对值, 把正号变为 0,把符号变为 1. 2.2.2 补码反码移码补码对于正数, 补码与原码的表示相同 对于负数, 原码符号位不变, 数值部分按位取反, 末位加一 (即所谓”取反加一”) 补码的作用: 使用补码可以将减法操作转变为等价的加法, ALU 中无须集成减法器. 执行加法操作后, 符号位一起参与运算 计算机在执行有符号数的减法很麻烦, 想办法将其转换为加法, 利用的就是取模的原理, 因为计算机会天然的取 $2^8$ 的模. 所以我们想办法让两个数相加溢出一位, 将结果等于取 $2^8$ 的模的结果即可将减法等价于加法. 这时候就将八位的二进制取反+1,使得运算结果超出$2^8$, 计算机自动取模得到等价的减法操作. (重点理解) 取反加一的加一操作原因: 因为如果不加一, 某一个数取反之后何其原本相加为八个一, 11111111. 加一之后为 100000000. 即 $2^8$ .为我们所需要的模 反码对于正数, 反码与原码的表示相同 对于负数,原码符号位不变,数值部分按位取反(也就是求补码的中间状态) 核心就是这张图 2.2.3 移位运算我们日常使用的十进制, 可以通过小数点左移或者右移, 实现 /10 或者 *10操作. 原码的算数移位符号位保持不变, 仅对数值位进行移位. 右移: 高位补零,低位舍弃. 若舍弃的位等于 0, 则相当于除以 2; 若舍弃的位不等于 0, 则相当于丢失精度. 右移一位: $\\div 2^1$; 右移两位: $\\div 2^2$; 右移三位: $\\div 2^3$ 左移: 低位补零, 高位舍弃. 若舍弃的位等于 0, 则相当于乘以 2; 若舍弃的位不等于 0, 则会出现严重误差. (原因左移表示至少乘以二,但是因为最高位为 1 的话, 乘以二绝对会超出 7 位 bit 表示的范围) 反码的算数移位正数的反码与原码相同. 因此对正数的反码移位和原码相同. 负数的反码数值为与原码想反. 因此负数反码的移位运算规则如下: 右移: 高位补1,低位舍弃. 左移:低位补 1,高位舍弃.(其实就是从补0变成了补1) 补码的算数移位正数的补码与原码相同. 因此对正数的补码移位和原码相同. 负数: 因为负数的补码是反码+1.导致反码最右边几个连续的1 都将会边为 0, 知道进位变成第一个 0 为止. 规律: 负数补码时,最右边的 1 及其右边同原码, 最右边的 1 的左边同反码. 所以负数补码的移位运算规则如下: 右移(同反码): 高位补 1, 低位舍弃; 左移(同原码): 低位补 1,高位舍弃. 2.2.4 加减运算和溢出运算2.2.5 乘法运算2.2.6 除法运算2.2.7 强制类型转换以上小节略过 2.2.8 数据的存储和排列大小端模式对于 4 字节的 int 类型, 将最高一个字节称为最高有效字节(MSB), 将最低一个字节称为最低有效字节(LSB). 而且一个 int 几个字节都是连续的. 大端方式: 将最高有效字节存放在低地址. (便于人类阅读) 小端方式: 将最低有效字节存放在低地址. (便于机器处理, 如果 cpu 只能处理 8 位, 显然应该从最低的八位开始相加) 2.3 浮点数2.3.4 浮点数的表示定点数可表示的数字范围悠闲, 但我们不要无限制地增加数据的长度. 所以, 如何在位数不变的情况下增加数据的表示范围? 浮点数将数分成阶码和尾数两个部分. 规格化浮点数: 规定尾数的最高位必须是一个有效值 左规: 当浮点数运算结果为非规格化时要进行规格化处理, 将尾数算数左移一位, 阶码减一. 右规: 当浮点数运算结果尾数出现溢出(双符号位为 01 或 10), 将尾数算数右移一位, 阶码加一. 之所以采用双符号位就是为了当溢出发生时进行挽救. 更高的符号位是正确的符号位 2.3.2 IEEE754 标准2.4.3 浮点数的运算运算略 强制类型转换char -&gt; int -&gt; long -&gt; double 不会损失精度(前提是32 位机器,因为在 32 位机器 long 占用 32 位, 64 位中long 占用 64 位,但是 double 的尾数位只有 53 位, 所以一定会损失精度) float -&gt; double 不会损失精度 int -&gt; float 可能丢失精度 float -&gt; int 可能溢出(表示了超出 int 的小数)及损失精度(表示整数) 2.4 算数逻辑单元 ALU2.4.1 电路的基本原理, 加法器设计逻辑表达式其实就是电路的数学化表示. 根据逻辑电路的规则对逻辑表达式进行优化, 其实就是在优化电路 算术运算: 加减乘除等 逻辑运算: 与, 或, 非, 异或等 辅助功能: 移位, 求补 此处需要复习门电路 一位全加器 注意去理解如何将二进制加法 -&gt; 逻辑表达式 -&gt; 逻辑门电路 -&gt; 一位加法器 但是注意, 这个是一位的加法, 如何计算多位? 串行加法器 只能一位一位的加 并行加法器 典型的空间换时间 并行加法器的速度取决于每一个加法器的速度 2.4.2 ALU 的改进串行加法器 -&gt; 串行进位的并行加法器 -&gt; 组内并行, 组间串行进位的加法器 -&gt; 组内并行, 组间并行的加法器 3 存储系统3.1 存储系统3.1.1 主存简单模型主存储器包括存储体, MAR(地址寄存器)和 MDR(数据寄存器)三个部分. 联想到之前学的存储元的知识, 直接联系起来了. 3.2 寻址概念3.3 存储器3.3.1 半导体存储器 RAM (Random-Access Memory)分为 SRAM (静态随机存储器) 和 DRAM (动态随机存储器) 两种 SRAM: 触发器存储信息, 速度快, 成本高, 集成度低, 常用作高速缓存 Cache DRAM: 电容存储信息, 需刷新, 速度慢, 成本低, 集成度高, 常用作主存(SDRAM) 为什么要用行列地址? 减少选通线的数量 3.3.2 半导体存储器 ROM (Read-Only Memory)CPU 包含了运算器, 控制器和主存储器. 因为 RAM 为易失性存储器. 如果采用 RAM 用来做主存, 一旦掉电将会丢失! 哪种不会丢失? 辅存. 但是由于辅存是通过 IO 接口连入主机, 所以就有了 ROM ROM: 将辅存里的 OS 调到 RAM ROM 经历了各种发展后, 目前使用固态硬盘为多. 但是固态硬盘依然无法替代 RAM, 但是正在逐步靠近. 没有保存的文件断电就会消失原理就是因为这些文件其实保存在 RAM 里. 保存其实就是将 RAM 中的数据保存到辅存. ROM 就是在开机时候告诉主机, 应该往 RAM 中放辅存的哪些内容 总结 重点理解存储周期的概念 3.3.3 存储器概念存储器的功能: 存放二进制信息 不同的材料, 不同的特性: 磁表面存储器: 磁盘 (特点:直接存取, 先定位到一个小区域), 磁带(特点:顺序存取) 磁芯存储器 半导体存储器 (特点是随机存取, 存取时间与存储单元位置无关,仅与电流有关. eg: ROM,RAM(易失性)) 光存储器 存储器的性能指标 存储容量: 存储字数 * 字长 单位成本: 每位价格=总成本/总容量 存储速度: 数据传输率=数据的宽度/存储周期 存储器的层次化结构 3.4 主存与 CPU 的连接片选线: 0 和 1 决定存储器工作与否 读写控制线: 0 和 1 决定读 or 写 cpu 想要处理 8 位的数据,则需要八个 8k1 位的存储器, 则有了下图, 这种扩展称为位扩展 位扩展 字扩展通过利用 cpu 上的 A13A14 操控使用哪一个存储器的数据, 本例只有 01 或 10, 也就是 n 条线 n 个片选信号 这种叫做线选法 电路简单地址空间不连续 但是可见容量收到了输入线的数量的限制, 如何突破这种限制呢? 主存容量扩展使用译码器, 将三位转换成 2 的三次方位 图下这种方法称为译码片选法, 电路复杂,但是地址空间可连续, 可以增加逻辑设计 字位同时扩展略 3.5 双口 RAM 和多模块存储器CPU 和主存之间存在着科技进步速度的差距 所以双口 RAM 和多模块存储器就是为了提高存储器的工作速度 存取周期 多体并行存储器 高位交叉编址的多体存储器 连续存取 n 个存储器耗时为 nT, n 个存取周期 低位交叉编址的多体存储器 这种方式省却了恢复时间, 所以在时间上会更快 一个存储周期内, 交叉存储器可以提供的数据量为单个模块的 m 倍 (m 为模块数). 可以并行工作, 如总线宽度为 mW 时, 可以同时取出长度为 mW 的数据. 3.6 高速缓冲存储器3.6.1 局部性原理性能分析通过多体并行存储器优化后, 速度与 CPU 差距仍然很大. 考虑更告诉的存储单元设计, 但是这样存储器价格会提升,容量会下降. 而且根据程序访问的局部性原理. 就有了高速缓存. 局部性原理 空间局部性: 在最近的未来要用到的信息(指令和数据), 很可能与现在正在使用的信息在存储空间上是临近的 时间局限性: 在最近的未来要用到的信息, 很可能是正在使用到的信息 命中率 HCPU 欲访问的信息已在 Cache 中的比率 3.6.2 Cache-地址映射主存中的块放到 Cache 中的哪个位置? 空位随意放: 全相联映射 对号入座: 直接映射 按号分组, 组内随意放: 组相联映射 对于 1, Cache 满了如何处理? 对于 2,3, 对应位置被占用如何处理? 随机算法, 先进先出算法, 近期最少使用(LRU)算法, 最不经常使用(LFU)算法. 修改 Cache 中的内容后, 如何保持主存中相应内容的一致性? 命中: 全写法(write-through) 回写法(write-back) 不命中: 写分配法(write-allocate) 非写分配法(not-write-allocate) 3.6.3 替换算法和写策略替换算法 随机算法(RAND): 随机地确定替换的 Cache 块. 实现简单, 没有依据程序访问的局部性原理, 命中率较低. 先进先出算法(FIFO): 选择最早调入的行进行替换. 比较容易实现, 但也没有依据程序访问的局部性原理, 可能会把一些经常要使用的程序块(如循环程序)也作为最早进入 Cache 的块替换掉. 近期最少使用算法(LRU): 依据访问的局部性原理选择近期内长久未访问过的存储行作为替换的行, 平均命中率要比 FIFO 要高, 是堆栈类算法. LRU 算法对每行设置一个计数器, Cache 命中一次, 命中行计数器清0,其他各行计数器加 1, 需要替换时比较各特定行的计数值, 将计数值最大的行换出. 最不经常使用算法(LFU): 将一段时间内访问次数最少的存储行换出. 每行也设置一个计数器, 新行建立后从 0 开始计数, 每访问一次, 被访问的计数器加 1,需要替换时比较计数值, 将计数值最小的行换出. 写策略见上面的问题 主要搭配有两种: 写回法搭配写分配法 全写法搭配非写分配法 3.7 虚拟存储器结构: ==CPU - Cache - 主存 - 辅助存储器== 这样层次是硬件直接实现的, 对操作系统透明(看不见) 虚拟存储器是一个逻辑模型. 功能: 用户给出一个地址, 叫做虚地址或逻辑地址, 虚拟存储器要给出该地址对应的数据 类型页式虚拟存储器(重点)虚拟空间与主存空间都被划分成同样大小的页, 主存的页称为实页, 虚存的页称为虚页. 段式虚拟存储器按程序的逻辑结构划分的, 各个段的长度因程序而异. 虚拟地址分为两部分: 段号和段内地址. 虚实地址转换 快表 TLB 慢表 Page 4 指令系统4.1 指令格式指令: 是指计算机执行某种操作的命令, 是计算机运行的最小功能单位. 一台计算机的所有指令的集合构成该机的指令系统, 也称为指令集. 一台计算机只能执行自己指令系统中的指令, 不能执行其他系统的指令. 一条指令通常包括操作码字段和地址字段两部分 地址码设指令字长及存储字长均为 32 位, 操作码占 8 位, 地址码占 24 位. 操作码有定长和扩展两种. 扩展操作码就是预留 全 1 作为标识, 使用地址字段作为操作码. 变换三地址指令二地址指令一地址指令等. 如果操作码字段读到 1110, 就将之后的作为地址码. 操作类型 数据传送(LOAD,STORE) 算术逻辑操作 移位操作 转移操作 输入输出操作 4.2 寻址 寻址方式 指令寻址: 下一条与执行指令的指令地址: 始终由程序计数器 PC 给出 数据寻址: 确定本条指令的操作数地址 4.2.1 指令寻址 顺序寻址: (PC) + 1 -&gt; PC 跳跃寻址: 由转移指令指出 4.2.2 数据寻址操作数类型 地址: 无符号数 数字: 定点数, 浮点数, 十进制树(BCD 码) 字符: ASCII 码 逻辑树: 逻辑运算 寻址特征有很多种, 例如直接寻址.不需要记 直接寻址: 指令字中的形式地址 A 就是操作数的真实地址 EA, 即 EA=A. 优点: 简单 间接寻址: 指令的地址字段给出的地址不是操作数的真实地址, 而是操作数有效地址存在的存储单元的地址. 也就是操作数地址的地址. 即 EA=(A). 优点: 可扩大寻址范围(EA 位数大于 A) 寄存器寻址: 在指令字中直接给出操作数所在的寄存器编号. 优点: 执行阶段不访问主存, 执行速度快. 缺点: 昂贵. 寄存器间接寻址: 寄存器中给出的不是一个操作数, 而是操作数所在主存 单元的地址. 特点: 与一般间接寻址快, 但指令执行阶段需要访问主存. 隐含寻址: 不是明显给出操作数的地址,而是在指令中隐含着操作数的地址. 也就是直接指出操作数在 ACC 中. 偏移寻址 基址寻址: 将 CPU 中基址寄存器(BR) 的内容加上指令格式中的形式地址 A, 而形成操作数的有效地址, 即 EA=(BR)+A 变址寻址: 有效地址 EA 等于指令字中的形式地址 A 与变址寄存器 IX 的内容相加之和, 即 EA=(IX)+A, 其中 IX 为变址寄存器(专用, 可以由用户改变), 也可使用通用寄存器作为变址寄存器. 相对寻址: 把程序计数器 PC 的内容加上指令格式中的形式地址 A 而形成操作数的有效地址, 即 EA=(PC) + A, 其中 A 是相对于当前指令地址的位移量, 可正可负, 补码表示. 优点: 操作数的地址不是固定的, 随着 PC 变化而变化. 相对寻址广泛应用于转移指令. 堆栈寻址操作数存放在对战中, 隐含使用堆栈指针(SP)作为操作数地址. 4.3 CISC 和 RISC 替换版 CISC Complex Instruction Set Computer 设计思路: 一条指令完成一个复杂的基本功能 代表: x86, 主要用于笔记本,台式机 80-20 规律: 典型程序中 80%的语句仅仅用处理机中 20%的指令 RISC Reduced Instruction Set Computer 设计思路: 一条指令完成一个基本”动作”; 多条指令组合完成一个复杂的基本功能. 代表: ARM 架构, 主要用于手机,平板, 苹果刚换了 M1芯片 5 中央处理器5.1 CPU 的功能和基本结构CPU 的功能 运算器的基本结构 控制器的基本结构 CPU 的基本结构将运算器和控制器两者结合就是 CPU 的基本结构. 主要分为四部分: ALU 寄存器 中断系统 CU 简单了解就好! 5.2 指令执行过程指令周期的概念: 一条指令执行分为不同的阶段 数据流: 不同阶段要求依次访问的数据序列 指令执行方案: 如何安排多条指令的执行? 指令周期指令周期: CPU 从主存中每取出并执行一条指令所需的全部时间 指令周期 = 若干机器周期(CPU 周期) 机器周期 = 若干时钟周期(这是 CPU 操作的最基本单位) 每个指令周期内机器周期数可以不等, 每个机器周期内的节拍数也可以不等. (每个指令任务是不一样的) 指令周期流程 取指周期: 取指令 间址周期: 取有效地址 执行周期: 取操作数 中断周期: 保存程序断点 指令执行方案 单指令周期 多指令周期 流水线方案 5.3 数据通路5.3.1 数据通路—CPU 内部单总线模式![image-20211015192300654](/Users/yiqing/Library/Application Support/typora-user-images/image-20211015192300654.png) 5.3.2 数据链路—专用数据通路方式 总结: 数据通路都是魔法世界, 看不懂, 学不会 5.4 控制器的功能和工作原理5.4.1 硬布线太难了, 略. CPU 的控制方式指: 产生不同微操作命令序列所用的时序控制方式. 同步控制方式 整个系统所有的控制信号均来自一个统一的时钟信号. 控制电路简单, 运行速度慢 异步控制方式 异步控制方式不存在基准时标信号. 各部件按自身固有的速度工作, 通过应答方式进行联络. 运行速度快, 控制电路比较复杂 联合控制方式 对各种不同的指令的微操作实行大部分采用同步控制, 小部分采用异步控制的方法 5.4.2 微程序事先把微操作控制信号存储在一个专门的存储器(控制存储器)中, 将每一条机器指令编写成一个微程序, 用寻址用户程序机器指令的办法来寻址每个微程序中的微指令 太难了,详细略 5.5 指令流水线5.5.1 概念和性能指标指令流水线: 一条指令的执行过程可以分成多个阶段, 占用不同的资源, 就能使多条指令同时进行 取址: 根据 PC 内容访问主存, 取出一条指令送到 IR 中 分析: 对指令操作码进行译码, 按照给定的寻址方式和地址字段中的内容形成操作数的有效地址 EA, 并从有效地址 EA 中取出操作数. 执行: 根据操作码字段, 完成指令规定的功能, 即把运算结果写到通用寄存器或主存中. 流水线的性能指标 吞吐率: 单位时间内流水线所完成的任务数量. 加速比: 完成同样一批任务, 不使用流水线和使用流水线的时间之比 效率: 设备使用率 5.5.2 影响因素分类 结构相关(资源冲突) 由于多条指令在同一时刻征用同一资源所引起的冲突 数据相关(数据冲突) 数据相关指在一个程序中, 存在必须等前一条指令执行完之后才能执行后一条指令的情况 控制相关 当流水线遇到转移指令和其他改变 PC 值的指令而造成断流时, 会引起控制相关 6 总线 计组的记忆就像是一场梦 6.1 概念与分类定义总线是一组能为多个部件==分时共享==的公共信息传送线路. 分类 按数据传输格式 串行总线 并行总线 按总线的功能(连接的部件) 片内总线 芯片内部的总线 系统总线 数据总线 地址总线 控制总线 通信总线 按时序控制 同步总线 异步总线 性能指标传输周期, 时钟周期, 工作频率, 时钟频率, 总线宽度, 总线带宽, 总线复用, 信号线数 6.2 总线仲裁如何解决多个设备争用总线的问题? (不是重点) 6.3 总线操作和定时占用总线的一对设备如何进行数据传输? 同步定时方式(同步通信) 异步定时方式(异步通信) 半同步通信 分离式通信 6.4 总线标准易于实现系统的模块化设计 7 I/O7.1 I/O 系统基本概念 7.2 外部设备7.2.1 输入输出设备7.2.2 外存储器都不重要 7.3 I/O 接口接口可以看作两个部件之间的交接部分 I/O 接口是主机和外设之间的交接界面, 通过接口可以实现主机和外设之间的信息交换. 接口的功能 设备选址 传送命令 传送数据 反应 I/O 设备的工作状态 7.4 I/O 方式7.4.1 程序查询方式 主要特点是: 踏步; 串行. 7.4.2 中断机制程序中断是指计算机执行现行程序的过程中, 出现某些急需处理的异常情况或特殊请求, CPU 暂时中止线性程序, 而转去对这些异常情况或特殊请求进行处理, 在处理完毕后 CPU 又自动返回到现行程序的断点处, 继续执行原程序. 内容略 7.4.3 程序中断方式 7.4.4 DMA 方式略 至此, 大概全部跟着走了一遍了, 有很多内容因为工作使用不到或者太难了就略过了. 毕竟我也不考研嘛. 继续努力! 年薪百万! 一清于 21 年 10 月 18 日","categories":[{"name":"笔记","slug":"笔记","permalink":"http://yiiiqing.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"计算机组成原理","slug":"计算机组成原理","permalink":"http://yiiiqing.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"}]},{"title":"MySQL-主从复制","slug":"MySQL-主从复制","date":"2021-09-10T05:48:51.000Z","updated":"2021-09-10T06:42:42.000Z","comments":true,"path":"2021/09/10/MySQL-主从复制/","link":"","permalink":"http://yiiiqing.github.io/2021/09/10/MySQL-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","excerpt":"","text":"MySQL 主从复制以下是 linux 版本的搭建 简介以下来自另一篇 blog 基本原理slave 会从 master 读取 binlog 来进行数据同步 三步骤 master 将该表记录到二进制日志 (binary log). 这些记录过程叫做二进制日志事件, binary log events; slave 将 master 的 binary log events 拷贝到它的中继日志 (relay log); slava 重做中继日志中的事件, 将改变应用到自己的数据库中. MySQL 复制是异步的且串行化的 基本规则 每个 slave 只有一个 master 每个 slave 只能有一个唯一的服务器 ID 每个 master 可以有多个 slave 最大问题延时 搭建步骤启动服务首先在 docker 中启动两个 MySQL 服务, 这里使用的是 5.7 版本 1234yiqings-laptop:~ yiqing$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES747fe7f90035 2c9028880e58 &quot;docker-entrypoint.s…&quot; 3 hours ago Up 3 hours 3306/tcp, 33060/tcp, 0.0.0.0:3307-&gt;3307/tcp, :::3307-&gt;3307/tcp mysql-slave7df9dd80af21 2c9028880e58 &quot;docker-entrypoint.s…&quot; 2 months ago Up 6 minutes 0.0.0.0:3306-&gt;3306/tcp, :::3306-&gt;3306/tcp, 33060/tcp mysql 修改主库 首先进入主库, 修改 my.cnf 文件 1vim /etc/mysql/my.cnf 如果没有 vim 命令, 需要安装 12apt-get update # 更新软件源列表apt-get -y install vim # 安装 vim 在 my.cnf 文件中添加 123456789[mysqld]#开启log-bin二进制日志log-bin=/var/log/mysql/mysql-bin#配置唯一的服务器IDserver-id=1#下面这两个不是必须要配置#主要是为了使用带事务的InnoDB进行复制设置时尽可能提高持久性和一致性innodb_flush_log_at_trx_commit = 1sync_binlog = 1 创建日志目录 12mkdir /var/log/mysqlchown myslq:mysql /var/log/mysql 重启数据库查看配置,这里是直接重启 docker 1docker restart 7df9dd80af21 如果是centos,直接重启服务systemctl start mysql 1234567891011121314151617181920212223mysql&gt; show variables like &#x27;server_id&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| server_id | 1 |+---------------+-------+1 row in set (0.00 sec)mysql&gt; show variables like &#x27;log_bin&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | ON |+---------------+-------+1 row in set (0.00 sec)mysql&gt; show variables like &#x27;%skip_networking%&#x27;; #skip_networking默认是OFF关闭状态，启用后主从将无法通信+-----------------+-------+| Variable_name | Value |+-----------------+-------+| skip_networking | OFF |+-----------------+-------+1 row in set (0.00 sec) 在主库上建立用于主从复制的账号 123mysql&gt; CREATE USER &#x27;replication&#x27;@&#x27;%&#x27;;mysql&gt; GRANT REPLICATION SLAVE ON *.* TO &#x27;replication&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27;;mysql&gt; flush privileges; 查看主库的二进制日志的名字 1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 801 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 记住这里的 file 和 position 关闭防火墙 由于 docker 不是 centos, 所以我跳过这一步 如果有: service iptables stop 修改从库 关闭防火墙(同上) 设置配置文件 my.cnf 12[mysqld]server-id=2 配置主从复制参数 12345mysql&gt; CHANGE MASTER TO MASTER_HOST=&#x27;172.17.0.2&#x27;,MASTER_USER=&#x27;replication&#x27;,MASTER_PASSWORD=&#x27;123456&#x27;,MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;,MASTER_LOG_POS=801; 这里的 ip 写的是 docker 的容器的 ip docker 容器的 ip 查看方法: docker inspect &lt;container id&gt; 启动 1mysql&gt; start slave; 查看 slave 状态 1234567891011121314mysql&gt; show slave status\\G; # \\G 表示用 kv 键值对输出*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.17.0.2 Master_User: replication Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 801 Relay_Log_File: 747fe7f90035-relay-bin.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes # 这个一定要为 yes Slave_SQL_Running: Yes # 这个一定要为 yes 如果有问题, 清理配置 12stop slave;reset slave all; 测试 在主库新增一个 test_rep 数据库 12mysql&gt; create database test_rep;Query OK, 1 row affected (0.01 sec) 查看从库 1234567891011mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || test_rep |+--------------------+5 rows in set (0.00 sec) 可以看到从库也新增了一个 test_rep 数据库","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/tags/MySQL/"}]},{"title":"MySQL-关闭ONLY_FULL_GROUP_BY","slug":"MySQL-关闭ONLY-FULL-GROUP-BY","date":"2021-09-06T02:21:34.000Z","updated":"2021-09-06T02:27:52.000Z","comments":true,"path":"2021/09/06/MySQL-关闭ONLY-FULL-GROUP-BY/","link":"","permalink":"http://yiiiqing.github.io/2021/09/06/MySQL-%E5%85%B3%E9%97%ADONLY-FULL-GROUP-BY/","excerpt":"","text":"MySQL关闭 ONLY_FULL_GROUP_BY问题如果在 group by 的时候出现如下问题,可以通过关闭 MySQL 的参数来解决 1Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#x27;db0629.tbl_emp.id&#x27; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by 原因MySQL 5.7.5及以上功能依赖检测功能。默认情况下启用ONLY_FULL_GROUP_BY SQL模式，MySQL将拒绝选择列表，HAVING条件或ORDER BY列表的查询引用在GROUP BY子句中既未命名的非集合列，也不在功能上依赖于它们。（5.7.5之前，MySQL没有检测到功能依赖关系，默认情况下不启用ONLY_FULL_GROUP_BY。 解决方法临时解决直接修改变量参数, 可以通过下面这个简单的脚本直接修改 1SET SESSION sql_mode=(SELECT REPLACE(@@sql_mode,&#x27;ONLY_FULL_GROUP_BY,&#x27;,&#x27;&#x27;)); 永久解决直接修改 MySQL 的配置文件 123[mysqld]-sql_mode=ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION+sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 然后重启 MySQL 1service mysqld restart 注意因为 ONLY_FULL_GROUP_BY 更加符合 SQL 标准，所以不建议关掉","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/tags/MySQL/"}]},{"title":"冒泡排序","slug":"冒泡排序","date":"2021-08-16T02:50:31.000Z","updated":"2021-08-16T05:40:19.000Z","comments":true,"path":"2021/08/16/冒泡排序/","link":"","permalink":"http://yiiiqing.github.io/2021/08/16/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/","excerpt":"","text":"冒泡排序最近重新学习算法, 发现这东西真的得时常复习, 或者一次彻底整会, 我选择后者 定义冒泡排序(Bubble Sort) 是一种交换排序, 它的基本思想是: 两两比较相邻记录的关键字, 如果反序则交换, 知道没有反序的记录为止. 原理冒泡法其实原理核心就是两两比较, 每一轮比较就得到一个极值. 两个数比较需要一次 三个数比较需要两次 得出: N 个数比较需要 N-1 次(这是外循环) 又因为每次比较都会增长有序序列, 所以吧, 每次比较次数会变少一次, 每次比较次数取决于有序序列的长度. 第 i 趟的排序次数为$(N-i)$次. (这是内循环) 所以可以用嵌套循环, 外层控制循环次数, 内层控制每一次循环的比较次数 123456for(int i = 0; i&lt;arr.length; i++)&#123; for(int j = 1; j&lt;arr.length-i; j++)&#123; if(arr[j-1] &gt; arr[j]) // 交换 &#125;&#125; 时间复杂度最好的情况, 只用走一次, 所以为$O(n)$ 最坏的情况, 需要$n-1$次排序,每次$n-i$次比较, 每次比较移动三次, 不算移动开销的话 需要比较$1+2+3+…+(n-1)=\\frac{n(n-1)}{2}$ 次. 计算移动开销就是$\\frac{3n(n-1)}{2}$ 次 所以总的时间复杂度就是$O(n^2)$ 代码 基本实现 12345678910111213141516171819/** * 冒泡排序的第一种实现, 没有任何优化 * @param a */public static void bubbleSort1(int [] a)&#123; int i, j; for(i=0; i&lt;n; i++)&#123;//表示n次排序过程。 for(j=1; j&lt;n-i; j++)&#123; if(a[j-1] &gt; a[j])&#123;//前面的数字大于后面的数字就交换 //交换a[j-1]和a[j] int temp; temp = a[j-1]; a[j-1] = a[j]; a[j]=temp; &#125; &#125; &#125;&#125; 进一步优化 因为如果数组部分有序, 其实每次比较都不需要再排序了. 所以设置一个 flag, 如果这一趟发生交换, 则为 true, 否则为 false. 如果有一趟没有发生交换,则排序已经完成. 12345678910111213141516171819202122232425262728public class BubbleSort implements IArraySort &#123; @Override public int[] sort(int[] sourceArray) throws Exception &#123; // 对 arr 进行拷贝，不改变参数内容 int[] arr = Arrays.copyOf(sourceArray, sourceArray.length); for (int i = 1; i &lt; arr.length; i++) &#123; // 设定一个标记，若为true，则表示此次循环没有进行交换，也就是待排序列已经有序，排序已经完成。 boolean flag = true; for (int j = 0; j &lt; arr.length - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; int tmp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = tmp; flag = false; &#125; &#125; if (flag) &#123; break; &#125; &#125; return arr; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://yiiiqing.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"排序","slug":"排序","permalink":"http://yiiiqing.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"Java-Thread.join方法","slug":"Java-Thread-join方法","date":"2021-08-06T03:19:33.000Z","updated":"2021-08-06T03:34:37.000Z","comments":true,"path":"2021/08/06/Java-Thread-join方法/","link":"","permalink":"http://yiiiqing.github.io/2021/08/06/Java-Thread-join%E6%96%B9%E6%B3%95/","excerpt":"","text":"Thread 类的 join 方法今天看到一个问题 如何确保 main 方法所在的线程是 Java 程序最后结束的线程 答案是使用 join 方法 于是去了解了一下这个方法 join 的作用引言跟刚才我看到的问题类似, 一个面试题: Java 中如何让多线程按照自己指定的顺序执行? 最简单的回答就是通过 Thread.join 来实现 直接上代码 1234567891011121314151617181920212223242526272829303132333435public class JoinDemo extends Thread &#123; int i; Thread previousThread; //上一个线程 public JoinDemo(Thread previousThread, int i) &#123; this.previousThread = previousThread; this.i = i; &#125; @Override public void run() &#123; try &#123; //调用上一个线程的join方法 previousThread.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; Thread.sleep((long) Math.random() * 10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;num:&quot; + i); &#125; public static void main(String[] args) &#123; Thread previousThread = Thread.currentThread(); for (int i = 0; i &lt; 10; i++) &#123; JoinDemo joinDemo = new JoinDemo(previousThread, i); joinDemo.start(); previousThread = joinDemo; &#125; &#125;&#125; 代码中,每个线程会随机 sleep 一段时间, 如果将previousThread.join()注释掉,结束顺序将会随机 如果不注释,可以看到结果为 0 到 9 依次排列 所以 join 对于线程的作用就是阻塞,等待线程中止后返回. 注意阻塞这一点,如果线程一直不结束,将会一直阻塞 注意: 必须在 start 之后调用 join 才有意义 join 原理看一下源码来理解一下 123456789101112131415161718192021222324public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 可以看到, 核心是调用 wait 方法(Object 类的) 由于 wait 方法必须要获取锁, 所以 join 方法被 synchronized 修饰, 在方法层面, 相当于 synchroinzed(this), 是本身的实例 线程执行完毕唤醒主线程的原因对于线程来说, wait 方法阻塞之后需要 notify/notifyall 来唤醒.那么这个 join 最后是怎么唤醒主线程的? 是因为底层的源码在线程执行完毕后有一个唤醒操作 join 的使用场景适用于我们需要等待线程执行结果来进行后续处理的场合 参考资料: https://zhuanlan.zhihu.com/p/53078651 https://www.cnblogs.com/duanxz/p/5038471.html https://www.journaldev.com/1024/java-thread-join-example","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"http://yiiiqing.github.io/tags/Thread/"}]},{"title":".bash_profile更改不起效","slug":"bash-profile更改不起效","date":"2021-07-22T08:48:50.000Z","updated":"2021-07-22T08:51:41.000Z","comments":true,"path":"2021/07/22/bash-profile更改不起效/","link":"","permalink":"http://yiiiqing.github.io/2021/07/22/bash-profile%E6%9B%B4%E6%94%B9%E4%B8%8D%E8%B5%B7%E6%95%88/","excerpt":"","text":".bash_profile更改不起效问题 最近项目中需要修改环境变量,配置了之后发现即使 1source ~/.bash_profile java 项目中System.getenv()都拿不到, 思前想后不知道什么原因 解决方法重启 …","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"bash","slug":"bash","permalink":"http://yiiiqing.github.io/tags/bash/"}]},{"title":"Java8新特性-Stream","slug":"Java8新特性-Stream","date":"2021-07-19T02:54:58.000Z","updated":"2021-07-19T10:07:46.000Z","comments":true,"path":"2021/07/19/Java8新特性-Stream/","link":"","permalink":"http://yiiiqing.github.io/2021/07/19/Java8%E6%96%B0%E7%89%B9%E6%80%A7-Stream/","excerpt":"","text":"Stream最近疯狂补习 Java8 的特性, 今天学习了一下 Stream. 基本上是跟着廖雪峰官网的教程来学习的, 自己边看别写,将 Stream 整理了一下 原文链接: https://www.liaoxuefeng.com/wiki/1252599548343744/1322402873081889 介绍Java8 引入了 Lambda 表达式,还引入了流式 API: Stream API 位于 java.util.stream 包 特点: 提供了一套新的流式处理的抽象序列 支持函数式变成和链式操作 可以表示无限序列,并且大多数情况下是惰性求值的 元素可能全部存储在内存,也有可能需要实时计算 惰性计算: 真正的计算通常发生在最后的结果的获取 创建 Stream多种方法 Stream.of()是一个静态方法, 传入可变参数 12Stream&lt;String&gt; stream = Stream.of(&quot;A&quot;,&quot;B&quot;);stream.forEach(System.out.println); 方便测试 基于数组或 Collection1234Stream&lt;String&gt; stream1 = Arrays.stream(new String[] &#123;&quot;A&quot;,&quot;B&quot;,&quot;C&quot;&#125;);Stream&lt;String&gt; stream2 = List.of(&quot;X&quot;,&quot;Y&quot;,&quot;Z&quot;).stream();stream1.forEach(System.out.println);stream2.forEach(System.out.println); 对于 Collection(List, Set, Queue...), 直接调用 stream()方法就可以获得 Stream 基于 Supplier还可以通过Stream.generate()方法, 需要传入一个Supplier对象 Stream&lt;String&gt; s = Stream.generate(Supplier&lt;String&gt;sp); 基于Supplier创建的Stream会不断调用Supplier.get()方法来不断产生下一个元素, 这种Stream保存的不是元素, 而是算法, 可以用来表示无限序列 1234567891011121314151617public class StreamTest &#123; public static void main(String[] args) &#123; Stream&lt;Integer&gt; natural = Stream.generate(new NatualSupplier()); natural.limit(20).forEach(System.out::println); &#125;&#125;class NatualSupplier implements Supplier&lt;Integer&gt;&#123; int n = 0; @Override public Integer get() &#123; n++; return n; &#125;&#125; 用 Supplier&lt;Integer&gt; 模拟了一个无限序列, 如果用 List 表示,即便在 int 范围内,也会占用很大内存, 而Stream几乎不占用空间,因为每个元素都是实时计算出来的,用的时候再算 其他方法通过一些 API 提供的接口 基本类型因为 Java 的泛型不支持基本类型 为了避免繁复的装箱拆箱,Java 提供了 IntStream, LongStream, DoubleStream 这三种使用基本类型的 Stream 12IntStream is = Arrays.stream(new int[]&#123;1,2,3&#125;);LongStream ls = List.of(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;).stream().mapToLong(Long::parseLong); 示例利用 Stream 实现输出斐波那契序列: 12345678910111213141516171819202122232425262728293031// 方法一Stream.iterate(new long[]&#123;0, 1&#125;, a -&gt; new long[]&#123;a[1], a[0] + a[1]&#125;) .limit(100) .map(a -&gt; a[0] + &quot;,&quot;) .forEach(System.err::print);// 方法二public static void fi2()&#123; IntSupplier is = new IntSupplier() &#123; int pre = 0; int current = 1; @Override public int getAsInt() &#123; int p = pre; int next = pre+current; pre = current; current = next; return p; &#125; &#125;; IntStream.generate(is).limit(10).forEach(System.out::println);&#125;// 方法三public static void fibonacci1() &#123; // 生成 整形数组，在通过flatmap 转换成一个集合输出 Stream.iterate(new Integer[]&#123;0, 1&#125;, t -&gt; new Integer[]&#123;t[0] + t[1], t[0] + t[1] + t[1]&#125;) // 1 .flatMap(Arrays::stream) // flatMap 数据， 将数组元素转化成stream //2 .limit(10) // 默认是无线长度，所以要给出限制 .forEach(System.out::println);&#125; 常见操作操作分为两类: 转换操作: 把一个 Stream 转换为另一个 Stream; 不会触发任何计算 聚合操作: 对 Stream 的每个元素进行计算,得到一个确定的结果; 立刻计算 mapStream.map()是Stream最常用的一个转换方法，它把一个Stream转换为另一个Stream。 所谓map操作，就是把一种操作运算，映射到一个序列的每一个元素上。 map()方法接收一个Function接口对象, 其定义了一个apply()方法, 将 T 类型转换为 R 类型 123456789public class Main &#123; public static void main(String[] args) &#123; List.of(&quot; Apple &quot;, &quot; pear &quot;, &quot; ORANGE&quot;, &quot; BaNaNa &quot;) .stream() .map(String::trim) // 去空格 .map(String::toLowerCase) // 变小写 .forEach(System.out::println); // 打印 &#125;&#125; filter所谓filter()操作，就是对一个Stream的所有元素一一进行测试，不满足条件的就被“滤掉”了，剩下的满足条件的元素就构成了一个新的Stream。 123IntStream.of(1, 2, 3, 4, 5, 6, 7, 8, 9) .filter(n -&gt; n % 2 != 0) .forEach(System.out::println); reducemap()和filter()都是Stream的转换方法，而Stream.reduce()则是Stream的一个聚合方法，它可以把一个Stream的所有元素按照聚合函数聚合成一个结果。 123// 累加int sum = Stream.of(1, 2, 3, 4, 5, 6, 7, 8, 9).reduce(0, (acc, n) -&gt; acc + n);System.out.println(sum); // 47 reduce 是聚合方法,聚合方法会立刻对 Stream 进行计算 输出为 List把 Stream 转换为 List 也是一个聚合操作,它会强制 Stream 输出每个元素 方法是调用collect()并传入Collectors.toList()对象 它实际上是一个Collector实例，通过类似reduce()的操作，把每个元素添加到一个收集器中（实际上是ArrayList）。 1234Stream&lt;String&gt; stream = Stream.of(&quot;Apple&quot;, &quot;&quot;, null, &quot;Pear&quot;, &quot;Orange&quot;);List&lt;String&gt; collect = stream.filter(s -&gt; s != null &amp;&amp; !s.isEmpty()) .collect(Collectors.toList());System.out.println(collect); 类似的，collect(Collectors.toSet())可以把Stream的每个元素收集到Set中。 输出为数组把Stream的元素输出为数组和输出为List类似，我们只需要调用toArray()方法，并传入数组的“构造方法”： 12List&lt;String&gt; list = List.of(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Orange&quot;);String[] array = list.stream().toArray(String[]::new); 注意到传入的“构造方法”是String[]::new，它的签名实际上是IntFunction&lt;String[]&gt;定义的String[] apply(int)，即传入int参数，获得String[]数组的返回值。 输出为Map如果我们要把Stream的元素收集到Map中，就稍微麻烦一点。因为对于每个元素，添加到Map时需要key和value，因此，我们要指定两个映射函数，分别把元素映射为key和value： 12345678Stream&lt;String&gt; stream = Stream.of(&quot;APPL:Apple&quot;, &quot;MSFT:Microsoft&quot;); Map&lt;String, String&gt; map = stream .collect(Collectors.toMap( // 把元素s映射为key: s -&gt; s.substring(0, s.indexOf(&#x27;:&#x27;)), // 把元素s映射为value: s -&gt; s.substring(s.indexOf(&#x27;:&#x27;) + 1))); System.out.println(map); 分组输出使用Collectors.groupingBy() 提供两个函数,一个是分组的key，这里使用s -&gt; s.substring(0, 1)，表示只要首字母相同的String分到一组，第二个是分组的value，这里直接使用Collectors.toList()，表示输出为List 1234567List&lt;String&gt; list = List.of(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Blackberry&quot;, &quot;Coconut&quot;, &quot;Avocado&quot;, &quot;Cherry&quot;, &quot;Apricots&quot;);Map&lt;String, java.util.List&lt;String&gt;&gt; groups = list.stream() .collect(Collectors.groupingBy( s -&gt; s.substring(0, 1), Collectors.toList() ));System.out.println(groups); 运行结果为: 12345&#123; A=[Apple, Avocado, Apricots], B=[Banana, Blackberry], C=[Coconut, Cherry]&#125; 示例按照对象的某一个字段分组 现有对象 Student 为: 12345678@Data@AllArgsConstructorpublic class Student &#123; int gradeId; // 年级 int classId; // 班级 String name; // 名字 int score; // 分数&#125; 按照 gradeId 分组: 12345678910111213141516Stream&lt;Student&gt; studentStream = Stream.of(new Student(1, 1, &quot;A&quot;, 80), new Student(1, 2, &quot;B&quot;, 90), new Student(1, 3, &quot;C&quot;, 100), new Student(2, 1, &quot;D&quot;, 90), new Student(2, 2, &quot;E&quot;, 100), new Student(2, 3, &quot;F&quot;, 80), new Student(3, 1, &quot;G&quot;, 100), new Student(3, 2, &quot;H&quot;, 80), new Student(3, 3, &quot;I&quot;, 90));Map&lt;Integer, List&lt;Student&gt;&gt; map = studentStream.collect( Collectors.groupingBy( s -&gt; s.gradeId, Collectors.toList() ));System.out.println(map); 输出结果为: 1&#123;1=[Student(gradeId=1, classId=1, name=A, score=80), Student(gradeId=1, classId=2, name=B, score=90), Student(gradeId=1, classId=3, name=C, score=100)], 2=[Student(gradeId=2, classId=1, name=D, score=90), Student(gradeId=2, classId=2, name=E, score=100), Student(gradeId=2, classId=3, name=F, score=80)], 3=[Student(gradeId=3, classId=1, name=G, score=100), Student(gradeId=3, classId=2, name=H, score=80), Student(gradeId=3, classId=3, name=I, score=90)]&#125; 其他操作排序1234List&lt;String&gt; list = List.of(&quot;Orange&quot;, &quot;apple&quot;, &quot;Banana&quot;) .stream() .sorted() .collect(Collectors.toList()); 去重1234List.of(&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;, &quot;B&quot;, &quot;D&quot;) .stream() .distinct() .collect(Collectors.toList()); // [A, B, C, D] 截取12345List.of(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;) .stream() .skip(2) // 跳过A, B .limit(3) // 截取C, D, E .collect(Collectors.toList()); // [C, D, E] 合并12345Stream&lt;String&gt; s1 = List.of(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;).stream();Stream&lt;String&gt; s2 = List.of(&quot;D&quot;, &quot;E&quot;).stream();// 合并:Stream&lt;String&gt; s = Stream.concat(s1, s2);System.out.println(s.collect(Collectors.toList())); // [A, B, C, D, E] flatMap是把 Stream 的每个元素映射为 Stream,然后合并成一个新的 Stream 如果Stream的元素是集合： 1234Stream&lt;List&lt;Integer&gt;&gt; s = Stream.of( Arrays.asList(1, 2, 3), Arrays.asList(4, 5, 6), Arrays.asList(7, 8, 9)); 而我们希望把上述Stream转换为Stream&lt;Integer&gt;，就可以使用flatMap()： 1Stream&lt;Integer&gt; i = s.flatMap(list -&gt; list.stream()); 并行通常情况下，对Stream的元素进行处理是单线程的，即一个一个元素进行处理。但是很多时候，我们希望可以并行处理Stream的元素，因为在元素数量非常大的情况，并行处理可以大大加快处理速度。 把一个普通Stream转换为可以并行处理的Stream非常简单，只需要用parallel()进行转换： 1234Stream&lt;String&gt; s = ...String[] result = s.parallel() // 变成一个可以并行处理的Stream .sorted() // 可以进行并行排序 .toArray(String[]::new); 经过parallel()转换后的Stream只要可能，就会对后续操作进行并行处理。我们不需要编写任何多线程代码就可以享受到并行处理带来的执行效率的提升。 其他聚合方法除了reduce()和collect()外，Stream还有一些常用的聚合方法： count()：用于返回元素个数； max(Comparator&lt;? super T&gt; cp)：找出最大元素； min(Comparator&lt;? super T&gt; cp)：找出最小元素。 针对IntStream、LongStream和DoubleStream，还额外提供了以下聚合方法： sum()：对所有元素求和； average()：对所有元素求平均数。 还有一些方法，用来测试Stream的元素是否满足以下条件： boolean allMatch(Predicate&lt;? super T&gt;)：测试是否所有元素均满足测试条件； boolean anyMatch(Predicate&lt;? super T&gt;)：测试是否至少有一个元素满足测试条件。 最后一个常用的方法是forEach()，它可以循环处理Stream的每个元素，我们经常传入System.out::println来打印Stream的元素： 1234Stream&lt;String&gt; s = ...s.forEach(str -&gt; &#123; System.out.println(&quot;Hello, &quot; + str);&#125;); 小结Stream提供的常用操作有： 转换操作：map()，filter()，sorted()，distinct()； 合并操作：concat()，flatMap()； 并行处理：parallel()； 聚合操作：reduce()，collect()，count()，max()，min()，sum()，average()； 其他操作：allMatch(), anyMatch(), forEach()。","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://yiiiqing.github.io/tags/Java8/"}]},{"title":"Maven依赖冲突解决方法","slug":"Maven依赖冲突解决方法","date":"2021-07-09T09:10:35.000Z","updated":"2021-07-09T09:11:39.000Z","comments":true,"path":"2021/07/09/Maven依赖冲突解决方法/","link":"","permalink":"http://yiiiqing.github.io/2021/07/09/Maven%E4%BE%9D%E8%B5%96%E5%86%B2%E7%AA%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"Maven依赖冲突解决方法案例修改项目依赖后,程序出现NoSuchMethodError 或者 ClassNotFoundException 或者类似的异常,大概率是因为依赖冲突 原因对于一个 Project 的依赖: 直接依赖","categories":[],"tags":[]},{"title":"jOOQ入门","slug":"jOOQ入门","date":"2021-06-28T09:30:37.000Z","updated":"2021-06-29T08:37:58.000Z","comments":true,"path":"2021/06/28/jOOQ入门/","link":"","permalink":"http://yiiiqing.github.io/2021/06/28/jOOQ%E5%85%A5%E9%97%A8/","excerpt":"","text":"jOOQ入门公司的 ORM 框架用的是 jOOQ 之前为了学 spring 全家桶学习的 mybatis 和 mybatis plus 都白学了 好吧我又继续学习了 概述官网: https://www.jooq.org/ 官网对于为什么使用 jOOQ 的描述如下 So why not just use SQL? SQL can be written as plain text and passed through the JDBC API. Over the years, people have become wary of this approach for many reasons: - No typesafety 无类型安全 - No syntax safety 无语法安全 - No bind value index safety 无绑定值索引安全性 - Verbose SQL String concatenation 冗长的SQL字符串拼接 - Boring bind value indexing techniques 乏味的绑定值索引技术 - Verbose resource and exception handling in JDBC JDBC中的详细资源和异常处理 - A very “stateful”, not very object-oriented JDBC API, which is hard to use 一个非常“有状态”的、不是非常面向对象的JDBC API，很难使用 因为以上这些原因,在过去,很多框架尝试以各种方式去抽象 JDBC. 但是不幸的是,很多框架把 SQL 也抽象掉了. jOOQ 可以将这一空白填充. 这样看起来,感觉口气很狂的样子,然后继续看一下官网的介绍 jOOQ is different SQL was never meant to be abstracted. To be confined in the narrow boundaries of heavy mappers, hiding the beauty and simplicity of relational data. SQL was never meant to be object-oriented. SQL was never meant to be anything other than… SQL! 翻译过来就是说: SQL 从来就不是抽象的.被限制在mappers 的狭窄的区域中,被隐藏了数据关联的美丽和简单 SQL 从来就不是面向对象的. SQL 从来就不是任何东西, 除了 SQL! 好吧这么一看,喷了很多框架啊,哈哈哈开发者个性我喜欢 jOOQ 的不同 jOOQ has originally been created as a library for complete abstraction of JDBC and all database interaction. Various best practices that are frequently encountered in pre-existing software products are applied to this library. This includes: - Typesafe database object referencing through generated schema, table, column, record, procedure, type, dao, pojo artefacts (see the chapter about code generation) 通过生成的模式、表、列、记录、过程、类型、dao和pojo构件引用类型安全数据库对象 - Typesafe SQL construction / SQL building through a complete querying DSL API modelling SQL as a domain specific language in Java (see the chapter about the query DSL API) 类型安全SQL构建/ SQL构建通过一个完整的查询DSL API建模的SQL - Convenient query execution through an improved API for result fetching (see the chapters about the various types of data fetching) 通过改进的用于结果获取的API方便地执行查询 - SQL dialect abstraction and SQL clause emulation to improve cross-database compatibility and to enable missing features in simpler databases (see the chapter about SQL dialects) SQL方言抽象和SQL子句模拟，以提高跨数据库兼容性，并在更简单的数据库中启用缺少的特性 - SQL logging and debugging using jOOQ as an integral part of your development process (see the chapters about logging) SQL日志记录和调试 Effectively, jOOQ was originally designed to replace any other database abstraction framework short of the ones handling connection pooling (and more sophisticated transaction management) 实际上，jOOQ最初的设计是为了取代除处理连接池之外的任何其他数据库抽象框架 好,很棒 使用 jOOQ 的几种方式 - Using Hibernate for 70% of the queries (i.e. CRUD) and jOOQ for the remaining 30% where SQL is really needed - Using jOOQ for SQL building and JDBC for SQL execution - Using jOOQ for SQL building and Spring Data for SQL execution - Using jOOQ without the source code generator to build the basis of a framework for dynamic SQL execution. 教程好记性不如烂笔头,跟着官网的 7 步成 jOOQ 教程走一波 准备下载jOOQ 或者通过 maven 引入官网的话https://www.jooq.org/download/ 我使用的是 maven 方式 首先建了一个空白的 maven 项目,在 pom 中引入: 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-meta&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-codegen&lt;/artifactId&gt;&lt;/dependency&gt; 数据库数据准备123456CREATE DATABASE `library`;USE `library`;CREATE TABLE `author` (`id` int NOT NULL,`first_name` varchar(255) DEFAULT NULL, `last_name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)); 代码生成在 resources 中创建一个 xml 文件, 使用官网给出的模板 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;&lt;configuration xmlns=&quot;http://www.jooq.org/xsd/jooq-codegen-3.9.2.xsd&quot;&gt; &lt;!-- Configure the database connection here --&gt; &lt;jdbc&gt; &lt;driver&gt;com.mysql.jdbc.Driver&lt;/driver&gt; &lt;!-- 数据库url --&gt; &lt;url&gt;jdbc:mysql://localhost:3306/library?useUnicode=true&amp;amp;characterEncoding=UTF-8&lt;/url&gt; &lt;!-- 数据库账号 --&gt; &lt;user&gt;root&lt;/user&gt; &lt;!-- 数据库账号密码 --&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/jdbc&gt; &lt;generator&gt; &lt;!-- The default code generator. You can override this one, to generate your own code style. Supported generators: - org.jooq.util.JavaGenerator - org.jooq.util.ScalaGenerator Defaults to org.jooq.util.JavaGenerator --&gt; &lt;name&gt;org.jooq.util.JavaGenerator&lt;/name&gt; &lt;database&gt; &lt;!-- The database type. The format here is: org.util.[database].[database]Database --&gt; &lt;name&gt;org.jooq.util.mysql.MySQLDatabase&lt;/name&gt; &lt;!-- The database schema (or in the absence of schema support, in your RDBMS this can be the owner, user, database name) to be generated --&gt; &lt;inputSchema&gt;library&lt;/inputSchema&gt; &lt;!-- All elements that are generated from your schema (A Java regular expression. Use the pipe to separate several expressions) Watch out for case-sensitivity. Depending on your database, this might be important! --&gt; &lt;includes&gt;.*&lt;/includes&gt; &lt;!-- All elements that are excluded from your schema (A Java regular expression. Use the pipe to separate several expressions). Excludes match before includes, i.e. excludes have a higher priority --&gt; &lt;excludes&gt;&lt;/excludes&gt; &lt;/database&gt; &lt;target&gt; &lt;!-- The destination package of your generated classes (within the destination directory) --&gt; &lt;!-- 生成的包名，生成的类在此包下 --&gt; &lt;packageName&gt;zone.yiqing.learnjooq.generated&lt;/packageName&gt; &lt;!-- The destination directory of your generated classes. Using Maven directory layout here --&gt; &lt;!-- 输出的目录 --&gt; &lt;directory&gt;/Users/yiqing/Documents/programming/projects/learn-jooq/src/main/java&lt;/directory&gt; &lt;/target&gt; &lt;/generator&gt;&lt;/configuration&gt; 其中: 替换 sql 连接的账号密码 packageName: 设置为用于生成代码的 classes 的 parent package directory: 输出生成 classes 的目录 生成代码使用 maven 插件https://www.jooq.org/doc/3.0/manual/code-generation/codegen-configuration/ 这个方法应该是最简单的方法 但是我在这个方法一直报错,最终尝试了其他方法 之后又尝试了此方法,发现和注 1 是一样的原因导致的报错,所以,切记版本选择!!! maven 插件:1234567891011121314151617181920212223242526&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.jooq&lt;/groupId&gt; &lt;artifactId&gt;jooq-codegen-maven&lt;/artifactId&gt; &lt;version&gt;$&#123;jooq.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.connector.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;configurationFile&gt;src/main/resources/library.xml&lt;/configurationFile&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 然后直接使用 maven 的 compile 即可产生代码,非常方便 使用生成器生成将 jOOQ 的三个文件和 mysql connector的 jar 包复制到一个目录,在本例中是 generated.将之前创建的 library.xml 也复制进来 cd 到这个目录 执行: 1java -classpath jooq-3.9.5.jar:jooq-meta-3.9.5.jar:jooq-codegen-3.9.5.jar:mysql-connector-java-5.1.30.jar: org.jooq.util.GenerationTool library.xml 注1: jar 包都要和本地的版本对应,mysql-connector 也要和 mysql 对应,我数据库是 5.7.24,使用 5.1.48 版本的 connector 报 ClassNotFound 错误,使用 5.1.30 就可以 运行命令看到输出 123456789101112131415161718192021222324252627282930...信息: Synthetic primary keys : 0 (0 included, 0 excluded)六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Overriding primary keys : 1 (0 included, 1 excluded)六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Generating table : Author.java [input=author, output=author, pk=KEY_author_PRIMARY]六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Tables generated : Total: 712.006ms六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Generating table references六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Table refs generated : Total: 724.683ms, +12.676ms六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Generating Keys六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Keys generated : Total: 728.338ms, +3.654ms六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Generating table records六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Generating record : AuthorRecord.java六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Table records generated : Total: 742.384ms, +14.046ms六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Domains fetched : 0 (0 included, 0 excluded)六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Generation finished: library: Total: 743.337ms, +0.953ms六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息:六月 29, 2021 11:16:00 上午 org.jooq.tools.JooqLogger info信息: Removing excess files 连接数据库创建一个测试类,一个标准的 JDBC MySQL 连接代码 1234567891011121314151617181920212223242526272829package zone.yiqing.learnjooq;import java.sql.Connection;import java.sql.DriverManager;/** * @author yiqing.zhang * @date 2021-06-29. */public class Main &#123; public static void main(String[] args) &#123; String userName = &quot;root&quot;; String password = &quot;123456&quot;; String url = &quot;jdbc:mysql://localhost:3306/library&quot;; // Connection is the only JDBC resource that we need // PreparedStatement and ResultSet are handled by jOOQ, internally try (Connection conn = DriverManager.getConnection(url, userName, password)) &#123; // ... &#125; // For the sake of this tutorial, let&#x27;s keep exception handling simple catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 查询使用 jOOQ 的 DSL 构建一个简单查询 12DSLContext create = DSL.using(conn, SQLDialect.MYSQL);Result&lt;Record&gt; result = create.select().from(AUTHOR).fetch(); 传入Connection连接对象、数据方言得到一个DSLContext的实例，然后使用DSL对象查询得到一个Result对象。 注意：DSLContext不会主动关闭连接，需要我们手动关闭。 输出得到结果后,使用迭代器打印结果 123456for (Record r : result) &#123; Integer id = r.getValue(AUTHOR.ID); String firstName = r.getValue(AUTHOR.FIRST_NAME); String lastName = r.getValue(AUTHOR.LAST_NAME); System.out.println(&quot;ID: &quot; + id + &quot; first name: &quot; + firstName + &quot; last name: &quot; + lastName);&#125; 结果我一看咋啥都没有,原来是没有插入数据 1INSERT INTO author(id,first_name,last_name) VALUES(1,&#x27;yiqing&#x27;,&#x27;zhang&#x27;); 重新运行 12345678910111213141516171819202122六月 29, 2021 11:41:22 上午 org.jooq.tools.JooqLogger info信息: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@ @@ @@ @@@@@@@@@@@@@@@@@@@@ @@@@ @@ @@ @@@@@@@@@@@@@@@@@@@@ @@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@ @@@@@@@@@@@@@@@@@@@@ @@ @@ @@@@ @@@@@@@@@@@@@@@@@@@@ @@ @@ @@@@ @@@@@@@@@@@@@@@@@@@@ @@ @ @ @@@@@@@@@@@@@@@@@@@@ @@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Thank you for using jOOQ 3.9.5 ID: 1 first name: yiqing last name: zhang 成功! 探索好吧这就是第七步,强行加的一步,附上第七步原文 jOOQ has grown to be a comprehensive SQL library. For more information, please consider the documentation: https://www.jooq.org/learn … explore the Javadoc: https://www.jooq.org/javadoc/latest/ … or join the news group: https://groups.google.com/forum/#!forum/jooq-user This tutorial is the courtesy of Ikai Lan. See the original source here: http://ikaisays.com/2011/11/01/getting-started-with-jooq-a-tutorial/ 进阶配置生成 dao,pojo,interface修改 library.xml 文件中的 generate 标签 123456&lt;!-- 配置生成 dao,interface,pojo--&gt;&lt;generate&gt; &lt;daos&gt;true&lt;/daos&gt; &lt;interfaces&gt;true&lt;/interfaces&gt; &lt;pojos&gt;true&lt;/pojos&gt;&lt;/generate&gt; 重新使用 maven compile 一下即可 生成目录介绍 DefaultCatalog: 一些常量,平时用不到 Library(名称不定,根据自己的库名): 数据库常量,包含库中表的描述 Keys: 表中的主键,唯一索引等 Tables:表的常量 tables: 文件夹,包含了我们应该使用的操作 interface:定义了各种字段的 get,set 等等 可以提高pojo 和 records 之间的转换性能 pojos: 一些表对象,实现了定义的接口 records: 表操作对象,包含字段 get,set 方法 CRUDR1234567891011121314151617181920212223242526272829303132public class SelectDemo &#123; public static void main(String[] args) &#123; selectDemo(); &#125; public static void selectDemo() &#123; DSLContext dslContext = DslContextConfig.getDslContext(); Result&lt;Record&gt; result = dslContext.select().from(AUTHOR) .where(AUTHOR.FIRST_NAME.eq(&quot;yiqing&quot;)).fetch(); System.out.println(result); Result&lt;Record1&lt;Integer&gt;&gt; result1 = dslContext.selectCount().from(AUTHOR).fetch(); System.out.println(result1); Result&lt;Record1&lt;String&gt;&gt; result2 = dslContext.selectDistinct(AUTHOR.FIRST_NAME).from(AUTHOR) .fetch(); System.out.println(result2); Result&lt;Record&gt; result3 = dslContext.select().from(AUTHOR).where(AUTHOR.FIRST_NAME.like(&quot;%y%&quot;)) .fetch(); System.out.println(result3); dslContext.select(AUTHOR.ID,AUTHOR.FIRST_NAME) .from(AUTHOR) .orderBy(AUTHOR.ID.asc()) .limit(2) .offset(2) .fetch() .forEach(System.out::println); &#125;&#125; C12345678910111213141516171819202122232425public class InsertDemo &#123; public static void main(String[] args) &#123; insert(); &#125; public static void insert()&#123; DSLContext dslContext = DslContextConfig.getDslContext(); // 方法 1 try&#123; dslContext.insertInto(AUTHOR,AUTHOR.ID,AUTHOR.FIRST_NAME,AUTHOR.LAST_NAME) .values(4,&quot;mazi&quot;,&quot;wang&quot;) .execute(); &#125;catch (Exception e)&#123;&#125; // 方法 2 dslContext.insertInto(AUTHOR) .set(AUTHOR.ID, 5) .set(AUTHOR.FIRST_NAME, &quot;si&quot;) .set(AUTHOR.LAST_NAME, &quot;wang&quot;) .execute(); &#125;&#125; U12345678910111213141516171819public class UpdateDemo &#123; public static void main(String[] args) &#123; update(); &#125; public static void update()&#123; DSLContext dslContext = DslContextConfig.getDslContext(); dslContext.update(AUTHOR).set(AUTHOR.FIRST_NAME,&quot;san2&quot;) .where(AUTHOR.FIRST_NAME.eq(&quot;san&quot;)) .execute(); dslContext.update(AUTHOR) .set(AUTHOR.FIRST_NAME, select(AUTHOR.FIRST_NAME).from(AUTHOR).where(AUTHOR.LAST_NAME.eq(&quot;li&quot;))) .where(AUTHOR.LAST_NAME.eq(&quot;wang&quot;)) .execute(); &#125;&#125; D1234567891011121314public class DelectDemo &#123; public static void main(String[] args) &#123; delete(); &#125; public static void delete() &#123; DSLContext dslContext = DslContextConfig.getDslContext(); dslContext.delete(AUTHOR) .where(AUTHOR.LAST_NAME.eq(&quot;li&quot;)) .execute(); &#125;&#125; 将结果封装成对应的类123456789101112131415161718192021public class ResultHandleDemo &#123; public static void main(String[] args) &#123; resultHandle(); &#125; public static void resultHandle()&#123; DSLContext dslContext = DslContextConfig.getDslContext(); List&lt;Author&gt; authors = dslContext.select() .from(AUTHOR) .where(AUTHOR.LAST_NAME.eq(&quot;zhang&quot;)) .fetch(r -&gt; r.into(Author.class)); System.out.println(authors); List&lt;Author&gt; into = dslContext.select() .from(AUTHOR) .where(AUTHOR.LAST_NAME.eq(&quot;zhang&quot;)) .fetchInto(Author.class); System.out.println(into); &#125;&#125; Transaction123456789101112131415161718public class TransactionDemo &#123; public static void main(String[] args) &#123; transaction(); &#125; private static void transaction() &#123; DSLContext dslContext = DslContextConfig.getDslContext(); dslContext.transaction(configuration -&gt; &#123; AuthorRecord peng = dslContext.insertInto(AUTHOR) .set(AUTHOR.ID, 6) .set(AUTHOR.FIRST_NAME, &quot;6&quot;) .set(AUTHOR.LAST_NAME, &quot;peng&quot;) .returning() .fetchOne(); &#125;); &#125;&#125; 执行可见正常插入 插入一个错误运算int i=1/0; 可见报错并且没有插入 注 2:一般来说,平时很少用 jOOQ 的事务,平时常结合第三方如 spring 进行事务管理","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"jOOQ","slug":"jOOQ","permalink":"http://yiiiqing.github.io/tags/jOOQ/"}]},{"title":"gRPC入门java示例","slug":"gRPC入门java示例","date":"2021-06-24T05:33:48.000Z","updated":"2021-06-24T09:00:10.000Z","comments":true,"path":"2021/06/24/gRPC入门java示例/","link":"","permalink":"http://yiiiqing.github.io/2021/06/24/gRPC%E5%85%A5%E9%97%A8java%E7%A4%BA%E4%BE%8B/","excerpt":"","text":"gRPC 入门 java 示例前言入职新公司一周后,一直在干看代码,感觉理解起来进度很慢,现在终于有任务给我了 是需要写一个基于 gRPC 的接口 开始学习起来 学东西首先要看的就是官网 https://grpc.io/ 这是 java入门教程: https://grpc.io/docs/languages/java/quickstart/ Intro看官网就够够了: https://grpc.io/docs/what-is-grpc/introduction/ In gRPC, a client application can directly call a method on a server application on a different machine as if it were a local object, making it easier for you to create distributed applications and services. As in many RPC systems, gRPC is based around the idea of defining a service, specifying the methods that can be called remotely with their parameters and return types. On the server side, the server implements this interface and runs a gRPC server to handle client calls. On the client side, the client has a stub (referred to as just a client in some languages) that provides the same methods as the server. gRPC clients and servers can run and talk to each other in a variety of environments - from servers inside Google to your own desktop - and can be written in any of gRPC’s supported languages. So, for example, you can easily create a gRPC server in Java with clients in Go, Python, or Ruby. In addition, the latest Google APIs will have gRPC versions of their interfaces, letting you easily build Google functionality into your applications. RPC 就不赘述了, 说一下 gRPC gRPC 就是 RPC 的一种实现,简单来说就是 定义了一份通信标准 server 端去实现这个通信标准并且启动 gRPC 服务器去处理 client 端的请求. client 端有一份 stub(存根),提供和 server 端一样的方法 server 和 client 端可以是不同机器不同环境不同语言下 Protocol Buffers众所周知,RPC 协议一个重点就是商榷传输的规则,gRPC 采用的是 Protocol Buffers 的方式 关于 Protocol Buffers 的具体情况有机会再写一篇 简而言之就是写了一份 .proto文件,根据这个文件利用插件生成 server 端和 client 端的对应语言的代码 生成代码需要下载安装 protoc 下载地址见 github: https://github.com/protocolbuffers/protobuf/releases, 需要将/src添加到环境变量 protocol buffer java 生成教程: https://developers.google.com/protocol-buffers/docs/reference/java-generated java 示例一: 官网(太监)我直接跟着官网走的,这里有一个https://grpc.io/docs/languages/java/basics/ 编写protoc 文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657syntax = &quot;proto3&quot;;option java_multiple_files = true;option java_package = &quot;io.grpc.examples.routeguide&quot;;option java_outer_classname = &quot;RouteGuideProto&quot;;option objc_class_prefix = &quot;RTG&quot;;package routeguide;service RouteGuide &#123; rpc GetFeature(Point) returns (Feature) &#123;&#125; rpc ListFeatures(Rectangle) returns (stream Feature) &#123;&#125; rpc RecordRoute(stream Point) returns (RouteSummary) &#123;&#125; rpc RouteChat(stream RouteNote) returns (stream RouteNote) &#123;&#125;&#125;message Point &#123; int32 latitude = 1; int32 longitude = 2;&#125;message Rectangle &#123; Point lo = 1; Point hi = 2;&#125;message Feature &#123; string name = 1; Point location = 2;&#125;message FeatureDatabase &#123; repeated Feature feature = 1;&#125;message RouteNote &#123; Point location = 1; string message = 2;&#125;message RouteSummary &#123; int32 point_count = 1; int32 feature_count = 2; int32 distance = 3; int32 elapsed_time = 4;&#125; 编译生成 java 类生成 proto 对应的代码刚开始我直接 protoc 1protoc --java_out=src/main/java/ src/main/proto/route_guide.proto # 使用下一步的代码 仅仅生成了proto 文件对应的代码 生成 grpc 代码网上google了之后发现是需要使用插件才可以生成 grpc 代码 maven 仓库: https://repo1.maven.org/maven2/io/grpc/protoc-gen-grpc-java/1.38.1/ 链接是 1.38 .1版本的 发现都是.exe 结尾的,我是 mac 怎么办,后来查询到只需要给予执行权限就行了 找到对应版本下载后,执行 1chmod u+x protoc-gen-grpc-java-1.38.1-osx-x86_64.exe 然后执行 12345protoc \\&gt; --java_out=src/main/java/ \\&gt; --plugin=protoc-gen-grpc-java=/Users/yiqing/Downloads/protoc-gen-grpc-java-1.38.1-osx-x86_64.exe \\&gt; --grpc-java_out=src/main/java/ \\&gt; src/main/proto/route_guide.proto 即可发现新增了关键的 RouteGuideGrpc.java 文件 好的,终于可以继续看教程了,下一步就是编写服务端和客户端的代码了 好的,鄙人不才,官网的示例感觉根本运行不起来,教程很过时 所以重新做了一个简单的示例 java 示例二: 简洁版实现简单的客户端上传两个int,返回两个 int 之和 创建 maven 项目话不多说 修改 pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;grpcjava&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;grpc.version&gt;1.34.1&lt;/grpc.version&gt; &lt;protobuf.version&gt;3.12.0&lt;/protobuf.version&gt; &lt;protoc.version&gt;3.12.0&lt;/protoc.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-bom&lt;/artifactId&gt; &lt;version&gt;$&#123;grpc.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-netty-shaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.grpc&lt;/groupId&gt; &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java-util&lt;/artifactId&gt; &lt;version&gt;$&#123;protobuf.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.6.1&lt;/version&gt; &lt;configuration&gt; &lt;protocArtifact&gt;com.google.protobuf:protoc:$&#123;protoc.version&#125;:exe:$&#123;os.detected.classifier&#125;&lt;/protocArtifact&gt; &lt;pluginId&gt;grpc-java&lt;/pluginId&gt; &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:$&#123;grpc.version&#125;:exe:$&#123;os.detected.classifier&#125;&lt;/pluginArtifact&gt; &lt;protoSourceRoot&gt;src/main/resources/proto&lt;/protoSourceRoot&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;compile&lt;/goal&gt; &lt;goal&gt;compile-custom&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 这个方法是采用 maven 编译生成 grpc 代码的 创建proto 文件注意 pom 中的 protoSourceRoot 目录,在该目录下新建 proto 文件, add.proto 123456789101112131415161718syntax = &quot;proto3&quot;;option java_package = &quot;zone.yiqing.grpc&quot;;option java_outer_classname = &quot;AddServiceProto&quot;;option java_multiple_files = true;service AddService&#123; rpc add(AddRequest) returns (AddReply)&#123;&#125;&#125;message AddRequest&#123; int32 a = 1; int32 b = 2;&#125;message AddReply&#123; int32 res = 1;&#125; 其中标注了语法为proto3 根据 proto 生成类在 maven 中直接点击 maven install 但是看到项目中没有生成任何文件 去 target 中,查看 generated-sources 中,protobuf 文件夹 其中重要的是我们生成的 AddServiceImplBase 类 123456789101112131415161718192021public static abstract class AddServiceImplBase implements io.grpc.BindableService &#123; /** */ public void add(zone.yiqing.grpc.AddRequest request, io.grpc.stub.StreamObserver&lt;zone.yiqing.grpc.AddReply&gt; responseObserver) &#123; asyncUnimplementedUnaryCall(getAddMethod(), responseObserver); &#125; @java.lang.Override public final io.grpc.ServerServiceDefinition bindService() &#123; return io.grpc.ServerServiceDefinition.builder(getServiceDescriptor()) .addMethod( getAddMethod(), asyncUnaryCall( new MethodHandlers&lt; zone.yiqing.grpc.AddRequest, zone.yiqing.grpc.AddReply&gt;( this, METHODID_ADD))) .build(); &#125; &#125; 可以看到 add 方法已经添加 传入参数为 AddRequest 返回参数为 void 的原因: gRPC 的入参和返回值都在参数里,即io.grpc.stub.StreamObserver&lt;zone.yiqing.grpc.AddReply&gt; responseObserver.这里通过一个对象去监听了返回值 真正实现 addService 的话,需要继承这个AddServiceImplBase并且重写方法 编写 Server 端 在项目中新建一个类 AddService,写一个 main 方法,并继承AddServiceGrpc.AddServiceImplBase 可见尽管在 target 中,也是可以继承的 重写 add 方法, idea 快捷键control + o 删掉里面的东西,添加自己写的方法,返回两者之和 注意 AddReply 的构造方法 在 main 方法中启动 server 1234567891011121314151617181920212223242526/** * @author yiqing.zhang * @date 2021-06-24. */public class AddServer extends AddServiceGrpc.AddServiceImplBase &#123; public static void main(String[] args) throws IOException &#123; ServerBuilder .forPort(7777) .addService(new AddServer()) .build() .start(); System.out.println(&quot;server on 7777&quot;); &#125; @Override public void add(AddRequest request, StreamObserver&lt;AddReply&gt; responseObserver) &#123; int add = myAdd(request.getA(), request.getB()); responseObserver.onNext(AddReply.newBuilder().setRes(add).build()); responseObserver.onCompleted(); &#125; public int myAdd(int a, int b) &#123; return a + b; &#125;&#125; 编写 Client 端 在项目中新建 AddClient 类 添加一个构造类,其中创建一个 channel,并且创建一个 stub stub是用来请求的,请求的时候 client 是通过 将参数传给 stub,stub 传给服务端的 在 main 方法中创建 channel 和发起请求 12345678910111213141516171819202122232425262728/** * @author yiqing.zhang * @date 2021-06-24. */public class AddClient &#123; AddServiceBlockingStub stub; ManagedChannel channel; public static void main(String[] args) &#123; AddClient client = new AddClient(); int a = 1; int b = 1; AddReply addReply = client.stub.add(AddRequest.newBuilder().setA(a).setB(b).build()); System.out.println(addReply.getRes()); &#125; public AddClient() &#123; channel = ManagedChannelBuilder .forAddress(&quot;127.0.0.1&quot;, 7777) //要去连接的 server 地址和端口 .usePlaintext() // 文本的类型 .build(); stub = AddServiceGrpc.newBlockingStub(channel); &#125;&#125; 启动 server运行 server,发现 server 立即退出,说明应该是新开了一个线程去创建 server,当主线程结束后也退出了. 修改一下代码添加 while(true)&#123;&#125; 可以看到端口已经在运行了: 123yiqings-laptop:~ yiqing$ lsof -i:7777COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEjava 36278 yiqing 64u IPv6 0x37ddc7b92240c489 0t0 TCP *:cbt (LISTEN) 启动 client可以看到控制台打印出了结果 2 done!","categories":[{"name":"中间件","slug":"中间件","permalink":"http://yiiiqing.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"gRPC","slug":"gRPC","permalink":"http://yiiiqing.github.io/tags/gRPC/"},{"name":"RPC","slug":"RPC","permalink":"http://yiiiqing.github.io/tags/RPC/"}]},{"title":"MySQL-docker安装","slug":"MySQL-docker安装","date":"2021-06-22T09:48:39.000Z","updated":"2021-06-22T09:51:09.000Z","comments":true,"path":"2021/06/22/MySQL-docker安装/","link":"","permalink":"http://yiiiqing.github.io/2021/06/22/MySQL-docker%E5%AE%89%E8%A3%85/","excerpt":"","text":"docker 运行 mysql最近入职了新公司，还在搭建环境和了解项目阶段 配置环境肯定少不了 mysql 这次我打算在 docker 中安装 mysql5.7 步骤 docker 安装（略） 拉取镜像 12docker search mysqldocker install mysql:5.7 直接运行 1docker run -itd --name mysql-test -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql 问题这里运行之后发现 mysql 的配置文件都是默认的，比如字符集什么的都是 lain，解决方法可以是修改容器中的配置，但是这样就违背了 docker 的初衷，将 docker容器当做操作系统了 解决: 最好是挂载一个配置文件 对于 5.7 版本的配置文件官方解释如下 The MySQL startup configuration is specified in the file /etc/mysql/my.cnf, and that file in turn includes any files found in the /etc/mysql/conf.d directory that end with .cnf. Settings in files in this directory will augment and/or override settings in /etc/mysql/my.cnf. If you want to use a customized MySQL configuration, you can create your alternative configuration file in a directory on the host machine and then mount that directory location as /etc/mysql/conf.d inside the mysql container. 如果想要自定义配置，建议向 /etc/mysql/conf.d 目录中创建 .cnf 文件。 所以创建一个目录用于挂载 这里注意要饭放在 docker与 mac share 的目录下，如果不是也可以添加 share 目录，问题不大 123mkdir -p /Users/yiqing/Documents/programming/docker_v/mysql/confcd /Users/yiqing/Documents/programming/docker_v/mysql/conftouch my.cnf 后期就在这个 my.cnf中修改配置 比如设定 mysql 字符集 123456789[client]default-character-set=utf8[mysqld]character-set-server=utf8collation-server=utf8_general_ci[mysql]default-character-set=utf8 done!","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/tags/Docker/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/tags/MySQL/"}]},{"title":"控制反转与依赖注入","slug":"控制反转与依赖注入","date":"2021-06-22T09:43:33.000Z","updated":"2021-06-22T09:47:37.000Z","comments":true,"path":"2021/06/22/控制反转与依赖注入/","link":"","permalink":"http://yiiiqing.github.io/2021/06/22/%E6%8E%A7%E5%88%B6%E5%8F%8D%E8%BD%AC%E4%B8%8E%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/","excerpt":"","text":"控制反转和依赖注入最近入职了新公司,新公司用的是 Guice 框架进行的依赖注入, 为了学习 Guice,先复习一遍IOC 和 DI Inversion of Control 控制反转以下是来源于一个国外网站的解释 Inversion of Control is a principle in software engineering which transfers the control of objects or portions of a program to a container or framework. We most often use it in the context of object-oriented programming. 个人翻译一下就是: 软件工程中的控制反转,就是指将对象或者程序的某一部分的控制权交给容器或者框架. 我们经常在 OOP 开发时使用到这种思想 IoC enables a framework to take control of the flow of a program and make calls to our custom code 这句话就是核心了,IoC 让框架来控制程序流并且调用我们自己的代码 The advantages of this architecture are(IoC 的优点): decoupling the execution of a task from its implementation 将程序的实现与执行分离 making it easier to switch between different implementations 使在不同实现的切换更加简单 greater modularity of a program 程序模块化程度更高 greater ease in testing a program by isolating a component or mocking its dependencies, and allowing components to communicate through contracts 通过隔离组件或模拟其依赖项，并允许组件通过合约进行通信，从而更轻松地测试程序 Dependency Injection 依赖注入 Dependency injection is a pattern we can use to implement IoC, where the control being inverted is setting an object’s dependencies. 依赖注入是一种我们可以用来实现 IoC 的模式，其中被反转的控制是设置对象的依赖关系。 也就是说设置对象的依赖关系这个事儿从程序员来干变成让程序来干了 区别来看一下传统方式注入依赖的方法 123456public class Store &#123; private Item item; public Store()&#123; item = new ItemImpl1(); &#125;&#125; 也就是说我们需要在构造 Store 的时候自己new一个 Item 的一个实现类的实例,然后注入 如果使用依赖注入 DI,我们忽略具体的Item 接口实现类 123456public class Store &#123; private Item item; public Store(Item item)&#123; this.item = item; &#125;&#125; 这就是依赖注入模式下的构造函数 当然具体实现类是怎么注入的, 交给框架来实现 主要是要充分理解 IoC 和 DI 的思想,这是最重要的 参考资料 https://www.baeldung.com/inversion-control-and-dependency-injection-in-spring","categories":[{"name":"Design","slug":"Design","permalink":"http://yiiiqing.github.io/categories/Design/"}],"tags":[{"name":"DI","slug":"DI","permalink":"http://yiiiqing.github.io/tags/DI/"},{"name":"IoC","slug":"IoC","permalink":"http://yiiiqing.github.io/tags/IoC/"}]},{"title":"Guice","slug":"Guice","date":"2021-06-22T09:34:11.000Z","updated":"2021-06-22T11:43:10.000Z","comments":true,"path":"2021/06/22/Guice/","link":"","permalink":"http://yiiiqing.github.io/2021/06/22/Guice/","excerpt":"","text":"Guice新公司不是使用 spring,而是使用 Guice 来进行依赖注入的,对我来说还是新东西,又可以学习了 Guice 官网: https://github.com/google/guice 概述 Put simply, Guice alleviates the need for factories and the use of new in your Java code. Think of Guice’s @Inject as the new new. You will still need to write factories in some cases, but your code will not depend directly on them. Your code will be easier to change, unit test and reuse in other contexts. 以上是 git 主页对于 guice 的介绍第一段,其实重点就是一句话: Think of Guice’s @Inject as the new new. 相对于 spring 来说,最大的优势就在于轻量级,guice 它只做依赖注入,是一个纯粹的依赖注入框架 关于 spring 的 IoC 实现和 DI 方法,可以查看: https://www.baeldung.com/inversion-control-and-dependency-injection-in-spring 而且 Spring 从2.5 开始提供了基于注解的自动装配机制来简化依赖注入。 @Autowired：基于 类型 的自动装配注入 @Resource：基于 名称 的自动装配注入 话说回来,那 Guice 的依赖注入是什么样的? 先实践一下吧 使用添加依赖1. maven直接添加在 maven 的 pom.xml中添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.google.inject&lt;/groupId&gt; &lt;artifactId&gt;guice&lt;/artifactId&gt; &lt;version&gt;4.1.0&lt;/version&gt;&lt;/dependency&gt; 2. 作为 Guice 的 extension 添加公司使用的是 jooby 框架,jooby 还有另一种第三方方式引入 guice. 参考文档可以查看 jooby 官网: https://jooby.io/#dependency-injection-guice 12345&lt;dependency&gt; &lt;groupId&gt;io.jooby&lt;/groupId&gt; &lt;artifactId&gt;jooby-guice&lt;/artifactId&gt; &lt;version&gt;2.9.6&lt;/version&gt;&lt;/dependency&gt; 当然现在使用第一种方式先添加 简单使用这里假设我们有这样一个场景,我们设计一个 class 来支持服务业务中的三种通信方式: Email, SMS, IM 先定义一个接口,接口有一个实现类 123public interface Communicator &#123; boolean sendMessage(String message);&#125; 123456public class DefaultCommunicatorImpl implements Communicator &#123; public boolean sendMessage(String message) &#123; System.out.println(&quot;Sending Message + &quot; + message); return true; &#125;&#125; 这样我们的 communication 类可以写成 1234567891011public class Communication &#123; // 注意这个是 com.google.inject 包的 @Inject private Communicator communicator; public boolean sendMessage(String message) &#123; return communicator.sendMessage(message); &#125;&#125; 写一个 main 方法 123456public class Test &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new BasicModule()); Communication comms = injector.getInstance(Communication.class); &#125;&#125; 这个 main 方法就是找到一个 Communication 的类的实例 但是上面的 BasicModule 又是什么呢? The Module is the basic unit of definition of bindings 定义依赖绑定的基本单元 Guice has adopted a code-first approach for dependency injection and management so you won’t be dealing with a lot of XML out-of-the-box. Guice bindingBinding is to Guice as wiring is to Spring. With bindings, you define how Guice is going to inject dependencies into a class. 也就是说定义 guice 怎么去注入依赖进入一个类 在本例中,BasicModule 如下 1234567public class BasicModule extends AbstractModule &#123; @Override protected void configure() &#123; bind(Communicator.class).to(DefaultCommunicatorImpl.class); &#125;&#125; 这个表明了DefaultCommunicatorImpl的实例 Instance 将被注入于 Communicator 变量被发现的地方 这个表明了, Guice 是通过代码来注入并管理依赖的,而不是和 spring 一样是使用 xml 的 另一种方式: 命名绑定 named binding12@Inject @Named(&quot;DefaultCommunicator&quot;)Communicator communicator; 为此,我们有以下绑定: 123456@Overrideprotected void configure() &#123; bind(Communicator.class) .annotatedWith(Names.named(&quot;DefaultCommunicator&quot;)) .to(DefaultCommunicatorImpl.class);&#125; 基于注解的绑定: 使用@Provides 12345678910111213public class BasicModule extends AbstractModule &#123; @Override protected void configure() &#123; bind(Communication.class) .toInstance(new Communication(true)); &#125; @Provides @Singleton public Communicator getCommunicator() &#123; return new DefaultCommunicatorImpl(); &#125;&#125; Singleton注入一个单例 12bind(Communicator.class).annotatedWith(Names.named(&quot;AnotherCommunicator&quot;)) .to(Communicator.class).in(Scopes.SINGLETON); 这个表示任何Communicator如果被*@Named(“AnotherCommunicator”)* 标注的话,都将会得到一个scope单例的注入. 这个注入是lazily initiated 延时加载的 TIP问题如果我们有另一个实现类比如AnotherCommunicatorImpl 注入肯定不能直接@Inject 这样怎么办? 解决方法使用@Named注解提供为属性赋值的功能 首先在注入绑定的时候使用 1234567@Inject@Named(&quot;communicator&quot;)private Communicator communicator;@Inject@Named(&quot;anotherCommunicator&quot;)private Communicator anotherCommunicator; 然后在定义绑定的时候使用 12345678910111213@Provides@Singleton@Named(&quot;communicator&quot;)public Communicator getCommunicator() &#123; return new DefaultCommunicatorImpl();&#125;@Provides@Singleton@Named(&quot;anotherCommunicator&quot;)public Communicator getAnotherCommunicator() &#123; return new AnotherCommunicatorImpl();&#125; 查找实例injector.getInstance(XXX.class); 的过程：先根据指定的类来 new Key()，Key 包括类信息 XXX.class 和注解信息，XXX.class的 hashcode 和注解的 hashcode 决定了 Key 的 hashcode，getProvider 时是根据 Key 的 hashcode 来判断是否是同一个Key，然后取到 Provider，由 Provider 提供最终的示例。 参考资料: https://jooby.io/#dependency-injection-guice https://www.baeldung.com/guice https://www.jianshu.com/p/7fba7b43146a","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"Guice","slug":"Guice","permalink":"http://yiiiqing.github.io/tags/Guice/"},{"name":"DI","slug":"DI","permalink":"http://yiiiqing.github.io/tags/DI/"},{"name":"IoC","slug":"IoC","permalink":"http://yiiiqing.github.io/tags/IoC/"}]},{"title":"大话数据结构读书笔记","slug":"大话数据结构读书笔记","date":"2021-06-21T09:36:26.000Z","updated":"2021-09-26T03:32:49.000Z","comments":true,"path":"2021/06/21/大话数据结构读书笔记/","link":"","permalink":"http://yiiiqing.github.io/2021/06/21/%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"大话数据结构读书笔记这是在补数据结构时候做的笔记 笔记中的引用模块代表自己的一些想法 1. 数据结构绪论数据结构：相互之间存在一种或多种特定关系的数据元素的集合 学科：数据结构是一门研究非数值计算的程序设计问题中的操作对象，以及它们之间的关系和操作等相关问题的学科 1.4 基本概念和术语1.4.1 数据数据：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合。 声音图像等也是可以转化为字符数据来处理的 1.4.2 数据元素数据元素：是组成数据的，有一定意义的基本单位，在计算机中通常作为整体处理。也被称为记录。 1.4.4 数据对象数据对象：是性质相同的数据元素的集合，是数据的子集 也就是一类数据结构的的集合。个人理解这种东西都是数据而已，没有必要做详细的区分 1.4.5 数据结构数据结构：相互之间存在一种或多种特定关系的数据元素的集合 研究数据结构的意义就是了解待处理对象的特性和处理对象之间存在的关系，从而编写出一个好的程序 1.5 逻辑结构与物理结构1.5.1 逻辑结构指数据对象中数据元素之间的相互关系。 集合结构 集合结构中的数据元素除了同属一个集合外，它们之间没有其他关系。 各个数据元素是平等的，共同属性只是：同属一个集合 线性结构 线性结构中的数据元素之间是一对一关系 类似链表连起来 树形结构 树形结构中数据元素之间存在一种一对多的层次关系 图形结构 图形结构的数据元素是多对多的关系 我认为这几种结构其实是对元素之间关系的一种抽象，两个元素之间： 无关系：集合 一对一：线性 一对多：树 多对多：图 1.5.2 物理结构（存储结构）是指数据的逻辑结构在计算机中的存储形式 存储结构应正确反映数据元素之间的逻辑关系，这是重点和难点 两种：顺序存储和链式存储 顺序存储结构 把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系是一致的 链式存储结构 把数据元素存放在任意的存储单元里，这组存储单元可以是连续的，也可以是不连续的 存储关系不能反映逻辑关系，因此需要指针存放关联元素位置 1.6 抽象数据类型1.6.1 数据类型数据类型：指一组性质相同的值的集合及定义在此集合上的一些操作的总称 因为高级语言开发，不用考虑整数在计算机内部表示方式，CPU 为了加减具体实现了什么，无论什么计算机，什么语言，一般都会有整数运算，字符运算等，我们可以抽象出来 1.6.2 抽象数据类型Abstract Data Type：是指一个数学模型及定义在该模型上的一组操作 比如整型，操作有加减乘除 比如 point，有x，y，z 抽象数据类型体现了程序设计中问题分解，抽象和信息隐藏的特性 2. 算法2.2 数据结构与算法关系就是相辅相成的关系 2.3 两种算法的比较举例一个 1+2+3+…+100 可以直接用 for 循环写，但是也可以构造另一个 100+99+…+1的序列，两者相加除 2 用程序来实现就是 123int i,sum=0,n=100;sum = (1+n)*n/2;printf(&quot;5d&quot;,sum); 明显这一种方法会更快，如果第一种要循环 2.4 算法定义算法是解决特定问题求解步骤的描述,在计算机中表现为指令的有限序列,并且每条指令表示一个或多个操作. 没有通用的算法可以解决所有问题! 2.5 算法的特性五个基本特性:输入,输出,有穷性,确定性和可行性 2.5.1 输入输出算法有零个或多个输入 算法有一个或多个输出 肯定会有输出,不一定有输入 很好理解,没输出的话用算法干嘛,闲的吗 2.5.2 有穷性算法在执行有限的步骤之后,自动结束而不会出现无限循环,并且每个步骤在可接受的时间内完成 所以,死循环就不满足这个特性 有穷是实际应用中的有穷,不是数学意义上的 2.5.3 确定性算法的每一步都有确定的含义,不会出现二义性 2.5.4 可行性算法的每一步必须是可行的 也就是说能用,能在计算机上运行 2.6 算法设计的要求解决问题的算法不是唯一的,但是相对好的算法对于解决问题才有帮助 2.6.1 正确性算法的正确性: 是指算法至少应该拥有输入输出和加工处理无歧义性,能正确反映问题的需求,能够得到问题的正确答案 正确有四个层次,一般我们以第三层次作为判断算法是否正确的标准,即: 算法程序对于非法的输入数据能够得出满足规格说明的结果 2.6.2 可读性算法的可读性: 算法设计的另一目的是为了便于阅读,理解和交流 不能追求一味地代码量少等 2.6.3 健壮性算法的健壮性: 当输入数据不合法时,算法也能做出相关处理,而不是产生异常或莫名其妙的结果 2.6.4 时间效率高和存储量低算法的时间效率高和存储量低: 设计算法应该尽量满足时间效率高和存储量低的需求 人都希望花最少的钱干最大的事 2.7 算法效率的度量方法事前分析好于事后统计 2.7.1 事后统计方法利用计算机计时器对不同算法的程序的运行时间进行比较,从而确定算法效率的高低 缺点: 很可能写了很久发现是垃圾算法 时间比较依赖计算机的运行速度 效率高的算法在小的测试数据面前无法体现明显差异 2.7.2 事前分析估算方法在计算机程序编制前,依据统计方法对算法进行估算 测定运行时间最可靠的方法, 就是计算对运行时间有消耗的基本操作的执行次数. 运行时间与这个技术成正比 不关心编程语言以及运行的计算机,只关心算法的话, 就不计算循环索引递增,循环终止条件,变量声明,打印结果等操作. 最终,在分析程序的运行时间时,最重要的是把程序看成是独立于程序设计语言的算法或一系列步骤 分析一个算法运行时间时,重要的是把基本操作的数量与输入规模关联起来,即基本操作的数量必须表示成输入规模的函数 输入规模为 n,随着 n 越来越大,不同算法在时间效率上的差异也就越来越大 2.8 函数的渐进增长比如两个算法, 2n+3 和 3n+1,哪个更快? 明显只有 n=1 时第二个才更优,所以我们说整体上第一个要好过第二个 函数的渐进增长: 给定两个函数 f(n)和 g(n),如果存在一个整数 N,使得对于所有的 n&gt;N,f(n)总是比 g(n)大,那么我们说 f(n)的增长渐进快于 g(n) 而且随着 n 的增大, +3 和+1 不影响算法变化,所以我们忽略这些加法常数. 我们再观察发现,去掉与 n 相乘的常数,结果也没有改变,所以与最高次项相乘的常数并不重要,可以将 2n²=&gt;n² 2n²和 2n²+3n+1 比较时,发现随着 n 值越来越大,两者非常趋近 最终我们得出结论: 判断一个算法的效率时,函数中的常数和其他次要项常常可以忽略,而更应该关注主项(最高次项)的阶数 事前估算方法的理论依据: 某个算法,随着 n 的增大,它会越来越优于某个算法,或者越来越差于某个算法.所以我们通过算法时间复杂度来估算算法时间效率 2.9 算法时间复杂度2.9.1 算法时间复杂度在进行算法分析时,语句总的执行次数 T(n)是关于问题规模 n 的函数,进而分析 T(n)随 n 的变化情况并确定 T(n)的数量级.算法的时间复杂度,也就是算法的时间量度,记作: T(n) = O(f(n)) 它表示随问题规模 n 的增大,算法执行时间的增长率和 f(n)的增长率相同,称作算法的渐进时间复杂度,简称为时间复杂度. 其中 f(n)是问题规模 n 的某个函数 这是大 O()记法 一般情况下,随着 n 的增大, T(n)增长最慢的算法为最优算法 2.8 中的例子,可以是 O(n),O(1),O(n²) n 是输入规模 2.9.2 推导大 O 阶方法步骤: 用常数 1 取代运行时间中的所有加法常数 在修改后的运行次数中,只保留最高阶项 如果最高阶项存在且不是 1,则取出与这个项相乘的常数 得到的结果就是大 O 阶 2.9.3 常数阶O(1) sum = (1+n)*n/2 这个有 1 句和10 句,都是 O(1) 因为无论 n 为多少,上段只是之星 1 次和 10 次的差异,这种与问题的大小(也就是n)无关,执行时间恒定,所以 O(1)的时间复杂度,又叫常数阶 2.9.4 线性阶要确定某个算法的阶次,常常要确定某个特定语句或整个语句集运行的次数. 分析算法的复杂度,关键要分析循环结构的运行情况 12345int i;for(i=0;i&lt;n;i++)&#123; /* 时间复杂度为O(1)的程序步骤序列*/&#125; 因为循环体中的代码需要执行 n 次,所以时间复杂度为 O(n) 2.9.5 对数阶123456int count = 1;while(count&lt;n)&#123; count = count * 2; /* 时间复杂度为O(1)的程序步骤序列*/&#125; 因为每次 count*2后, 距离 n 更近了.也就是说, 有多少个 2相乘后大于 n,则会退出循环. 2的 x 次方=n得到 x=log以 2 为底,n 为真数 所以这个循环的时间复杂度为 O(logn) 2.9.6 平方阶 12345678int i,j;for(i=0;i&lt;n;i++)&#123; for(j=0;j&lt;n;j++) &#123; /* 时间复杂度为O(1)的程序步骤序列*/ &#125;&#125; O(n)再循环 n 次,所以为 O(n²) 如果内循环的循环次数改为 m,则为 O(m✖️n) 循环的时间复杂度等于循环体的复杂度乘以改循环运行的次数 理解大 O 推导并不难,难的是对数列的一些相关运算,这里更多的是数学知识和能力. 2.10 常见的时间复杂度O(1) O(log n) O(n) O(nlog n) O(n²) 其他比如 O(n³)一般不去讨论 2.11 最坏情况与平均情况查找 n 个随机数字数组中的数字,可能第一个数字就是(O(1)),也可能是最后一个(O(n)) 最坏情况运行时间是一种保证,就是运行时间不会再坏了.这是最重要的需求 平均运行时间在上例中是n/2, 平均运行时间是最有意义的,因为是期望的运行时间. 对算法的分析,一种为平均时间复杂度,一种是最坏时间复杂度 一般没有特殊说明,都是最坏时间复杂度 2.12 算法空间复杂度算法的空间复杂度通过计算算法所需的存储空间实现,算法空间复杂度的计算公式记作: S(n) = O(f(n)) n 为问题的规模,f(n)为语句关于 n 所占存储空间的函数 2.14 结语一台老 CPU 计算机运行 O(n)比一台速度提高100 倍的新 CPU 运行 O(n²)的程序,效率高的是老 CPU,所以说,原因就在于算法的优劣直接决定了程序运行的效率. 3. 线性表 List3.2 定义线性表(List): 零个或多个数据元素的有限序列 几个点: 序列: 元素是有顺序的 有限: 计算机中处理的对象都是有限的 在较复杂的线性表中,一个数据元素可以由若干个数据项组成 3.3 线性表的抽象数据类型数据:一对一的数据元素 操作: InitList ListEmpty ClearList GetElem LocateElem ListInsert ListDelete ListLength 3.4 线性表的顺序存储结构3.4.1 顺序存储结构定义线性表的顺序存储结构: 指的是用一段地址连续的存储单元一次存储线性表的数据元素 3.4.1 顺序存储方式顺序存储结构需要三个属性: 存储空间的其实位置: 数组 data, 它的存储位置就是存储空间的存储位置. 线性表的最大存储容量: 数组长度 MaxSize. 线性表的当前长度: length. 3.4.3 数组长度和线性表长度区别线性表的长度是线性表中数据元素的个数,可变,但是小于等于数组长度 3.4.4 地址计算方法第 i 个元素的位置y可以由第一个元素x推算得出$$LOC(y)=LOC(x)+(i-1)*c$$其中 c 是一个元素占用的存储单元个数 由此可见,可以随时算出线性表中任意位置的地址,不管第一个还是最后一个都是相同的时间,所以时间复杂度为 O(1) 3.5 顺序存储结构的插入和删除3.5.1 获得元素操作获取线性表的第 i 个元素,就是把数组 i-1 下标的值返回 3.5.2 插入插入算法思路: 如果插入位置不合理,抛出异常 如果线性表长度大于等于数组长度,则抛出异常或动态增加容量 从最后一个位置开始向前遍历到第 i 个位置,分别将他们都向后移动一个位置 将要插入元素填入位置 i 表长加1 3.5.3 删除操作类似于上面的插入算法 删除算法思路: 如果删除位置不合理,抛出异常 取出删除元素 从删除元素位置开始遍历到最后一个元素位置,分别将它们都向前移动一个位置 表长减 1 插入和删除的复杂度只有插入到最后一个或者删除最后一个,时间复杂度才是 O(1),因为不需要移动元素 平均的情况,比如插入中间,移动元素次数为(n-1)/2 所以去常数和系数后得出,平均时间复杂度还是 O(n) 所以: 线性表的顺序存储结构,存取数据时间复杂度为 O(1);增删时时间复杂度都是 O(n). 也就说明,比较适合元素个数不太变化,更多为存取数据的应用 3.5.4 线性表顺序存储结构的优缺点优点: 无须为表示表中元素之间的逻辑关系而增加额外的存储空间 可以快速地存取表中任一位置的元素 缺点: 插入删除操作需要移动大量元素 当线性表长度变化较大时,难以确定存储空间的容量 造成存储空间的”碎片” 3.6 线性表的链式存储结构3.6.2 线性表链式存储结构定义在链式结构中,除了要存数据元素信息外,还要存储它的后级元素的存储地址 因此, 为了表示每个数据元素 ai 与其直接后继数据元素ai+1 之间的逻辑关系,对数据元素 ai 来说,除了存储其本身的信息之外,还需存储一个指示其直接后继的信息.我们把存储数据元素的信息成为数据域,把存储直接后继位置的域成为指针域.指针域中存储的信息称作指针或链.这两部分信息组成数据元素 ai 的存储映像,成为结点 Node. n 个节点链结成一个链表,成为线性表(a1,a2,…,an)的链式存储结构,如果链表的每个结点中只包含一个指针域,所以叫做单链表 链表中第一个结点的存储位置叫做头指针 最后一个结点指针为”空”(通常用 NULL 表示) 有时为了方便操作,会在单链表的第一个结点前附设一个结点,成为头结点. 头结点的数据域可以不存储任何信息(可以存线性表长度等公共数据), 头结点的指针域指向第一个结点的指针. 3.6.3 头指针与头结点的异同 头指针 是链表指向第一个结点的指针,若链表有头结点,则指向头结点 头指针具有标识作用,所以常常用头指针冠以链表的名字 不论链表是否为空,头指针均不为空.头指针是链表的必要元素 头结点 头结点是为了操作的统一和方便而设立的,放在第一元素的结点之前,其数据域一般无意义(也可存放线性表的长度) 有了头结点,对在第一元素前插入和删除第一结点,其操作与其他结点的操作就统一了 头结点不一定是链表必须要素 3.6.4 线性表链式存储结构代码描述123456typeof struct Node&#123; ElemType data; struct Node *next;&#125; Node;typeof struct Node *LinkList;/*定义 LinkList*/ 由这个结构定义克制,结点由存放数据元素的数据域和存放后继结点地址的指针域组成. 3.7 单链表的读取和顺序存储结构不同的是,单链表获取第 i 个元素智能从头开始找,找到第 i 个元素位置. 因此,最坏情况下时间复杂度为 O(n) 3.8 单链表的插入与删除3.8.1 单链表的插入假设存储元素 e 的结点为 s,要插入到 p 和 p-&gt;next 之间: s-&gt;next=p-&gt;next; p-&gt;next=s; 也就是让 p 的后继结点改成 s 的后继结点,再把结点 s 变成 p 的后继结点(顺序不能更换!) 3.8.2 单链表的删除要删除结点 q,实际上就是将它的前继结点的指针绕过,指向它的后继结点即可 q=p-&gt;next; p-&gt;next=q-&gt;next; 时间复杂度算法由两部分组成: 遍历查找第 i 个元素 插入和删除 整个算法删除和插入都是 O(n). 但是考虑从第i 个元素插入10 个元素的情况 如果是顺序存储结构,每一次插入都要移动 n-i 个元素,每次都是 O(n). 单链表,只需要第一次找到 第 i 个位置的指针,O(n),接下来就是赋值移动指针,10 次, O(1) 所以: 对于插入或删除越频繁的操作,单链表效率越高 3.9 单链表的整表创建链表是一个动态结构. 所占用空间的大小和位置是不需要预先分配划定的. 分两种: 头插法 插入新结点始终在第一的位置 尾插法 就是将之前的表尾终端结点的指针指向新结点 然后将最后的指针置为空 3.10 单链表的整表删除思路: 声明一结点 p 和 q 将第一个结点赋值给 p 循环 将下一结点赋值给 q 释放 p 将 q 赋值给 p q 变量存在的必要: 保存下一个结点以便删除 3.11 单链表结构与顺序存储结构优缺点 存储分配方式 顺序存储结构用一段连续的存储单元依次存储线性表的数据元素 单链表采用链式存储结构,用一组任意的存储单元存放线性表的元素 时间性能 查找 顺序存储结构: O(1) 单链表: O(n) 插入和删除 顺序存储结构: O(n) 需要平均移动表长一半的元素 单链表: O(1) 算出某位置的指针后,插入删除为 O(1) 空间性能 顺序存储结构需要预分配存储空间,分大了,浪费,分小了容易溢出 单链表不需要分配存储空间,只要有就可以分配,元素个数不受限制 结论 频繁查找,少插入和删除,宜采用顺序存储结构(用户注册的信息) 频繁插入删除,宜采用单链表(用户的登录信息) 元素个数变化大或未知,最好用单链表,不用考虑存储空间如果事先知道大致长度,用顺序存储结构效率高 3.12 静态链表静态链表: 用数组来代替指针,来描述单链表 让数组的元素都是由两个数据域组成,data 和 cur.存放元素和 next 指针(该元素的后继在数组中的下标) 对数组的第一个和最后一个元素作为特殊元素,不存数据. 将未被使用的数组元素成为备用链表. 数组的第一个元素的 cur 存放备用链表的第一个结点的下标; 数组的最后一个元素的 cur 存放第一个有数值的元素的下标 3.12.1 静态链表的插入操作先把数据放到第一个空闲的位置a,然后从头循环找到要插入的位置b,将这个元素b下标指到刚才放的位置a,将刚才放的那个元素的指针指向b 的下一个,就完事儿了,结束后修改有数值的元素下标和备用链表的下标值. 3.12.2 静态链表的删除操作某个数据a 要删除: 将 a 的cur 指向的下标赋值给存放第一个有数值的元素的下标 将 a 的下标赋值给存放备用链表的节点的下标(也就是说这个位置成为优先空位) 3.12.3 静态链表优缺点优点: 插入和删除时,只需要修改游标,不需要移动段素,从而改进了在顺序存储结构中的插入和删除操作需要移动大量元素的缺点 缺点: 没有解决连续存储分配带来的表长难以确定的问题 失去了顺序存储结构随机存取的特性 总的来说,静态链表其实是为了给没有指针的高级语言设计的一种能实现单链表能力的方法.理解思想即可 3.13 循环链表循环链表: 将单链表中终端结点的指针端由空指针改为指向头结点,就使整个单链表形成一个环,这种头尾相接的单链表成为单循环链表,简称循环链表(circular linked list) 循环的判断条件: 原来是判断 p-&gt;next 是否为空, 现在是 p-&gt;next 不等于头结点,则循环未结束 使用尾指针用指向终端结点的尾指针来表示循环链表,此时查找开始结点和终端节点就很方便 终端结点: rear,查找终端结点 O(1) 开始结点: rear-&gt;next-&gt;next,其时间复杂度也是 O(1) 合并 保存 A 表的头结点: p=rearA-&gt;next; 将本是指向 B 表的第一个结点(不是头结点)赋值给 rearA-&gt;next(也就是删除B 的头结点): rearA-&gt;next = rearB-&gt;next-&gt;next 将原来 A 的头结点赋值给rearB-&gt;next rearB-&gt;next =p; 释放 p; 3.14 双向链表 double linked list双向链表是在单链表的每个结点中,再设置一个指向其前驱结点的指针域. 多付出的代价: 在插入和删除时,需要更改两个指针变量 插入: 将结点 s 插入 p 和p-&gt;next 之间: 1234s -&gt; prior = p;s -&gt; next = p -&gt; next;p -&gt; next -&gt; prior = s;p -&gt; next = a; 先搞定 s 的前驱和后继,再搞定后结点的前驱,最后解决前结点的后继,第四步需要最后执行以免后结点 删除: 删除结点 p: 12p -&gt; prior -&gt; next = p -&gt; next;p -&gt; next -&gt; prior = p -&gt; prior; 3.15 总结回顾线性表是零个或多个具有相同类型的数据元素的有限序列 两大结构: 顺序存储结构 链式存储结构 这两种结构是后面其他数据结构的基础 4. 栈与队列4.2 栈的定义4.2.1 栈的定义栈(stack)是限定仅在表尾进行插入和删除操作的线性表. 允许插入和删除的一端称为栈顶(top) 另一端称为栈底(bottom) 后进先出结构(Last In First Out) LIFO 结构 4.2.2 进栈出栈变化形式栈没有对元素进出的时间进行限制,在不是所有元素都进栈的情况下,事先进去的元素也可以先出栈,只要保证是栈顶元素出栈就可以.所以有很多顺序 4.3 栈的抽象数据类型ADT 栈 stack DATA ​ 同线性表.元素具有相同的类型,相邻元素具有前驱和后继关系 Operation InitStack: 初始化操作,建立一个空栈 DestroyStack: 若栈存在,则销毁它 ClearStack: 将栈清空 StackEmpty: 若栈为空,返回 true,否则返回 false GetTop: 若栈存在且非空,返回栈顶元素 Push: 若栈存在,入栈 Pop: 删除栈顶元素 StackLength: 返回栈的元素个数 endADT 4.4 栈的顺序存储结构及实现4.4.1 栈的顺序存储结构因为是线性表,所以是数组来实现的 下标为 0 的一端为栈底 栈的结构定义: 123456typeof int SElemType; /* 类型根据实际情况而定,这里假设为 int */typedef struct&#123; SElemType data[MAXSIZE]; int top; /* 用于栈顶指针 */&#125;SqStack; 4.4.2 进栈操作1Status Push(SqStack *S, SElemType e)&#123; if(S-&gt;top == MAXSIZE -1) &#123; return ERROR; &#125; S-&gt;top++; /*栈顶指针增加一*/ S-&gt;data[S-&gt;top]=e; return OK;&#125; 4.4.3 出栈操作1Status Pop(SqStack *S, SElemType *e)&#123; if(S-&gt;top==-1) return ERROR; *e=S-&gt;data[S-&gt;top]; /*将要删除的栈顶元素赋值给 e*/ S-&gt;top--; /*栈顶指针减少一*/ return OK;&#125; 进栈和出栈没有涉及任何循环语句,因此时间复杂度均是 O(1) 4.5 两栈共享空间用一个数组来存储两个栈 数组的两个端点分别为栈的底端,两个栈如果要增加元素,就是两端点向中间延伸 栈为空: 栈 1 为空就是 top1 等于-1;栈 2 为空,就是 top2 等于 n 栈满:除极端情况,就是两个栈见面之时,也就是两个指针相差 1 时,即 top1 + 1 == top2 为栈满 使用这种数据结构,通常都是当两个栈的空间需求有相反关系时.一个增长一个缩短 4.6 栈的链式存储结构及实现4.6.1 栈的链式存储结构简称链栈 把栈顶放在单链表的头部.(所以对于链栈来说,是不需要头结点的) 基本不存在栈满的情况. 对于空栈来说,链栈的空就是 top=NULL 的时候 4.6.2 进栈操作1// 插入元素 e 为新的栈顶元素Status Push(LinkStack *S, SElemType e)&#123; LinkStackPtr s =(LinkStackPtr)malloc(sizeof(StackNode)); s-&gt;data=e; s-&gt;next=s-&gt;top; // 把当前栈顶元素赋值给新结点的直接后继 S-&gt;top=s; S-&gt;count++; return OK;&#125; 4.5.3 出栈操作1// 若栈不空,则删除 S 的栈顶元素,用e 返回其值,并返回 OK;否则返回 ERRORStatus Pop(LinkStack *S,SElemType *e)&#123; LinkStackPtr p; if(StackEmpty(*S)) return ERROR; *e = S-&gt;top-&gt;data; p=S-&gt;top; //将栈顶结点赋值给 p S-&gt;top = S-&gt;top-&gt;next; //使得栈顶指针下移一位 free(p); // 释放结点 p S-&gt;count--; return OK; 链栈的进栈 push 和出栈 pop 都没有循环操作,时间复杂度 O(1) 对比顺序栈和链栈: 它们在时间复杂度上是一样的,均为 O(1). 对于空间性能,顺序栈需要实现确定一个固定长度,链栈没有长度问题 结论: 如果栈的使用过程中元素变化不可预料,有时很小,有时非常大,那么最好使用链栈,反之,如果变化可控,建议使用顺序栈 4.7 栈的作用栈的引入简化了程序设计的问题,划分了不同关注层次,使得思考范围缩小,更加聚焦于我们要解决的问题的核心. 4.8 栈的应用—递归栈有一个很重要的作用: 在程序设计语言中实现了递归 4.8.1 斐波那契数列1// 斐波那契的递归函数int Fbi(int i)&#123; if(i&lt;2) return i == 0?0:1; return Fbi(i-1) + Fbi(i-2); //递归&#125;int main()&#123; int i; for(int i = 0; i&lt;40;i++) printf(&quot;%d&quot;,Fbi(i)); return 0;&#125; 4.8.2 递归定义把一个直接调用自己或通过一系列的调用语句间接地调用自己的函数,称作递归函数 每个递归定义必须至少有一个条件,满足时递归不再执行,即不再引出自身而是返回值退出 迭代和递归的区别是: 迭代使用的是循环结构,递归使用的是选择结构. 递归能使程序的结构更清晰,更简洁,更容易让人理解,但是递归调用会建立函数的副本,会耗费大量的时间和内存.迭代则不需要反复调用函数和占用额外的内存. 所以应该视不同情况选择不同的实现 因为递归退回的顺序是它前行顺序的逆序,所以很符合栈这样的数据结构 现在的高级语言,这样的递归是不需要用户来管理这个栈的,一切都由系统代劳 4.9 栈的应用—四则运算表达式求值4.9.1 后缀表示法定义对于9+(3-1)*3+10/2,使用后缀表达式为: 931-3*+10 2/+ 叫后缀的原因是所有的符号都在运算数字后面出现 4.9.2 后缀表达式计算结果后缀表达式: 9 3 1-3*+10 2/+ 规则: 从左到右遍历表达式的每个数字和符号,遇到数字就进栈,遇到符号,就将处于栈顶的两个数字出栈,进行运算,运算结果进栈,知道最终获得结果 4.9.3 中缀表达式转后缀表达式平时的标准四则运算为中缀表达式 转换规则: 从左到右遍历中缀表达式的每个数字和符号, 若是数字就输出,即成为后缀表达式的一部分; 若是符号,则判断其与栈顶符号的优先级,是右括号或优先级低于栈顶符号(*/ &gt; +-),则栈顶元素依次出栈并输出,并将当前符号进栈,一直到最终输出为止. 所以我们发现,要让计算机具有处理我们通常的标准表达式的能力, 最重要的就是两步: 将中缀表达式转化为后缀表达式(栈用来进出运算的符号) 将后缀表达式进行运算得出结果(栈用来进出运算的数字) 4.10 队列的定义队列(queue) 是只允许在一段进行插入操作,而在另一端进行删除操作的线性表 是FIFO 的线性表. 允许插入的一端称为队尾,允许删除的一端称为对头. 4.11 队列的抽象数据类型1 ADT 队列(queue)DATA 同线性表.元素具有相同类型,相邻元素具有前驱和后驱关系OPERATION InitQueue: 初始化操作,建立一个空队列 DestroyQueue: 若队列存在,则销毁它 ClearQueue:将队列清空 QueueEmpty:若队列为空,则返回 true,否则返回 false GetHead: 若队列存在且非空,返回对头元素 EnQueue:插入 DeQueue:删除对头元素 QueueLength:返回元素个数 endEDT 4.12 循环队列栈和队列都是线性表,所以都存在顺序存储和链式存储两种方式 4.12.1 队列顺序存储的不足如果用两个指针来指向 front 和 rear,如果一个元素入队,然而数组末尾已经占用,就会产生数组越界的错误,然而可能之前有出队列的元素造成下标小的位置空余,这种现象叫做”假溢出” 4.12.2 循环队列定义解决假溢出的方法就是后面满了,再从头开始,也就是头尾相接的循环. 我们把这种头尾相接的循序存储结构称为循环队列 如何判断队列满? 方法一: 设置 flag 方法二:保留一个元素空间,当队列满时,数组还有一个空闲单元 重点第二种 队列满的条件: (rear+1)%QueueSize==front 取模的目的为了整合 rear 与 front 大小为一个的问题 当rear&gt;front 时,队列长度为 rear-front 当 rear&lt;front 时,队列长度为0+rear+QueueSize-front,为 rear-front+QueueSize. 所以通用的长度计算公式为: (rear-front+QueueSize)%QueueSize 单是顺序存储,若不是循环队列,算法的时间性能是不高的,但循环队列又面临着数组可能会溢出的问题. 4.13 队列的链式存储结构及实现其实就是线性表的单链表,只不过它只能尾进头出而已,我们把它称为链队列 两个指针,front 和 rear. front 指向头结点,rear 指向终端结点 空队列时,都指向头结点 4.13.1 队列的链式存储结构—入队就是在链表尾部插入结点,也就是 将新的结点赋值给原结点的后继 移动 rear 指针 4.13.2 队列的链式存储结构—出队 头结点的后继结点出队 将头结点的后继改为它后面的结点 如果除头结点只剩一个元素时,将 rear 指向头结点 4.14 总结 栈 顺序栈 两栈共享空间 链栈 队列 顺序队列 循环队列 链队列 5. 串5.2 串的定义串(string)是由零个或多个字符组成的有限序列,又名叫字符串 5.3 串的比较串的比较是通过组成串的字符之间的编码来进行的,而字符的编码指的是字符在对应字符集中的符号 ASCII 编码: 由 7 位二进制数表示一个字符,总共可以表示 128 个字符,后来拓展到 8 位,总共可以表示 256 个字符. Unicode 编码:因为各种语言的文字太多而出现,比较常用的是呀 ongoing16 位的二进制数表示一个字符,这样总共可以表示 约是 65 万多个字符,为了与 ASCII 兼容,前 256 个字符与 ASCII 码完全相同 对于两个不相等的串,判定大小: 给定两个串:s=”a1a2…an”, t=”b1b2…bm”,当满足以下条件之一时,s&lt;t n&lt;m,且 ai=bi 例如当 s=”hap”,t=”happy”,就有 s&lt;t,因为 t 比 s 多了两个字母 当存在某个 k&lt;=min(m,n),使得 ai=bi(i=1,2,…,k-1),ak&lt;bk 例如当 s=”happen”,t=”happy”,因为两串的前4 个字母均相同,而两串第 5 个字母,e 的 ASCII 为 101,y 的 ASCII 为 121,所以 s&lt;t 5.4 串的抽象数据类型线性表更关注的是单个元素的操作,比如查找一个元素,插入或删除一个元素,但串中更多的是查找子串位置,得到指定位置子串,替换子串等操作 5.5 串的存储结构5.5.1 串的顺序存储结构串的顺序存储结构是用一组地址连续的存储单元来存储串中的字符序列的. 一般使用定长数组来定义 串值的存储空间可在程序执行过程中动态分配而得. 比如在计算机中存在一个自由存储区,叫做”堆”. 5.5.2 串的链式存储结构与线性表相似,结构中的每一个元素数据是一个字符. 一个结点可以存放一个字符,也可存放多个字符,最后一个结点若是未占满,可以用”#”或其他非串值字符值补全 串的链式存储结构除了在连接串与串操作有一定方便之外,总的来说不如顺序存储结构灵活,性能也不如顺序存储结构好 5.6 朴素的模式匹配算法子串的定位操作通常称作串的模式匹配 简单来说,就是对主串S的每一个字符串作为子串开头,与要匹配的字符串T进行匹配,对主串做大循环,每个字符开头做 T 的长度的小循环,直到匹配成功或全部遍历完成为止. 最好的情况: O(1) 稍差一些: O(n+m). n 是主串长度,m 为要匹配的子串长度,平均是(n+m)/2次查找,时间复杂度为 O(n+m) 最坏的情况: 每次不成功的匹配都发生在串 T 的最后一个字符, 所以是O((n-m+1)*m). 这个算法非常低效 5.7 KMP 模式匹配算法5.7.1 KMP 模式匹配算法原理如果我们知道 T 串中首字符”a”与 T 中后面的字符均不相等(这是前提).而 T 的第二位在第一次比较的时候已经判断是相等的,所以这次的判断(S 第二位和 T 第一位对比)是可以省略的 对于在子串中有与首字符相等的字符,也可以省略一部分不必要的判断步骤 5.7.2 next 数组值推导算法推导过程略 核心思想为主串当前位置的下标 i 不回溯,考虑 j 的值 j 值的下一值的推导结果即 next 数组 5.7.3 KMP 模式匹配算法实现算法略 和朴素匹配算法的改动就是去掉了 i 值回溯的部分,而 get_next 函数时间复杂度为 O(m),while 循环的时间复杂度为O(n). 整个算法的循环的时间复杂度为 O(n+m), 相较于朴素匹配的 O((n-m+1)*m)来说,是好一些 但是 KMP 算法仅当模式与主串之间存在许多”部分匹配”的情况下才体现出它的优势,否则两者差异并不明显 5.7.4 KMP 模式匹配算法改进如果 T 串的第 2,3,4,5 位置的字符都与首位的”a”相等, 那么可以用首位 next[1]的值去取代与它相等的字符后续 next[j]的值. 5.7.5 nextval 数组值推导过程略 实际上就比如 T 的第三个字符”a”的 next 值为 1,所以与第一位的”a”比较得知它们相等,所以 nextval[3]=nextval[1]=0; 总结改进过的 KMP 算法,它是在计算出 next 值的同时,如果 a 位字符与它 next 值指向的 b 位字符相等,则该 a 位的 nextval 就指向 b 位的 nextval 值,如果不等,则该 a 位的 nextval 值就是它自己 a 位的 next 的值 5.8 总结回顾我们在使用这些函数的时候,也要理解它们当中的原理,以便于在碰到复杂问题的时候,可以更加灵活的使用.比如 KMP 模式匹配算法 6. 树6.2 树的定义之前都是一对一的线性结构,一对多的情况需要树 树 Tree: 是 n(n&gt;=0) 个结点的有限集. n=0 时称为空树. 在任意一颗非空树中: 有且仅有一个特定的称为根(root)的结点 当 n&gt;1时,其余结点可分为 m(m&gt;0)个互不相交的有限集 T1,T2,….,Tm,其中每一个集合本身又是一棵树,并且称为根的子树(SubTree). 注意: 在树的定义中也用到了树的概念 n&gt;0时根结点是唯一的 m&gt;0 时,子树的个数没有限制,但它们一定是互不相交的 6.2.1 结点分类树的结点包含一个数据元素及若干指向其子树的分支. 结点拥有的子树数称为结点的度(Degree). 度为 0 的结点称为叶结点(Leaf)或终端结点; 度不为 0 的结点称为分支结点或非终端结点. 除根节点之外,分支节点也称为内部结点. 树的度是树内各结点的度的最大值. 拥有的子树数其实就是这个结点有几个分支 所以分支的最大值为树的度 6.2.2 结点间关系结点的子树的根称为该结点的孩子(Child), 该结点称为孩子的双亲 (Parent) 同一个双亲的孩子之间为兄弟结点(Sibling) 结点的祖先是根到该结点所经分支上的所有结点 某结点为根的子树中的任一结点都称为该结点的子孙 6.2.3 数的其他相关概念结点的层次(Level)从根开始定义起,根为第一层,根的孩子为第二层. 数中结点的最大层次称为数的深度(Depth)或高度. 如果将树中结点的各子树看成从左至右是有次序的,不能互换的,则称该树为有序树,否则称为无序数. 森林(Forest)是 m(m&gt;=0) 棵互不相交的树的集合. 6.3 数的抽象数据类型略 6.4 树的存储结构简单的顺序存储结构是不能满足对树的实现的 不过充分利用顺序存储和链式存储结构的特点,完全可以实现对树的存储结构的表示. 双亲表示法 孩子表示法 孩子兄弟表示法 6.4.1 双亲表示法在每个结点中,附设一个指示器指示其双亲结点到链表中的位置. 也就是说,每个结点除了知道自己是谁之外,还知道它的双亲在哪. 所以查找双亲的时间复杂度为 O(1). 但是如果我们要知道结点的孩子是什么,只能遍历整个结构 特殊的改进: 可以添加一个长子域便于找到孩子 存储结构的设计是一个非常灵活的过程.一个存储结构设计得是否合理,取决于基于该存储结构的运算是否适合,是否方便,时间复杂度好不好等. 6.4.2 孩子表示法每个结点有多个指针域,其中每个指针指向一棵树的根结点, 我们把这种方法叫做多重链表表示法 树的每个结点的度,也就是孩子数是不同的.两种方案: 方案一指针域的个数就等于树的度 比如树的度为 3,指针域的个数就是 3,每个结点都有三个指针域 但是对于树种各结点的度相差很大的时候,浪费空间 方案二每个结点指针域的个数等于该结点的度, 我们专门取一个位置来存储结点指针域的个数 克服了浪费空间的缺点,空间利用率高了,但是由于每个结点的链表是不同的结构,加上要维护结点的数值,在运算上就会带来时间上的损耗. 更好的方法? 仔细观察,为了遍历数,把每个结点放到一个顺序存储结构的数组中是合理的,单每个结点的孩子有多少是不确定的,所以再建立一个单链表 方案三把每个结点的孩子结点排列起来,以单链表作存储结构,则 n 个结点有 n 个孩子列表,如果是叶子结点则此单链表为空. 然后 n 个头指针又组成一个线性表,采用顺序存储结构,存放进一个一维数组中. 需要使用两种结点结构: 孩子链表的孩子结点 child: 存放某个结点在表头数组中的下标 next: 指针域,用来存储指向某结点的下一个孩子结点的指针 表头数组的表头结点 data: 存放某结点的数据信息 firstchild 是头指针域,存放该结点的孩子链表的头指针 优点: 利于查找某个结点的孩子,或者找某个结点的兄弟,只需要查找这个结点的孩子单链表即可 遍历整个树也方便,只需要对头结点的数组循环 缺点: 无法知道某个结点的双亲,需要整棵树遍历 孩子表示法的改进:表头数组的结点多存一个域,记录其双亲结点的下标 这种方法称为孩子双亲表示法. 6.4.3 孩子兄弟表示法任意一棵树,它的结点的第一个孩子如果存在就是唯一的,它的右兄弟如果存在也是唯一的. 因此我们设置两个指针,分别指向该结点的第一个孩子和此结点的右兄弟 结点结构由三部分组成: data:数据域 firstchild:指针域, 存储该结点的第一个孩子结点的存储地址 rightsib:指针域,存储该结点的右兄弟结点的存储地址 优点: 查找某个结点的某个孩子方便 缺点: 找双亲不便(改进: 增加 parent 指针域) 最大好处: 将一颗复杂的树变成了一颗二叉树.这样就可以利用二叉树的特性和算法来处理这棵树了 6.5 二叉树的定义在某个阶段都是两种结果的情形,比如开关,01,真假,对错,都适合用树状结构来建模,而这种树是一种很特殊的树状结构,叫做二叉树 二叉树(Binary Tree) 是 n (n&gt;=0) 个结点的有限结合,该集合或者为空集(称为空二叉树), 或者由一个根节点和两棵互不相交的,分别称为根节点的左子树和右子树的二叉树组成. 6.5.1 二叉树特点 每个结点最多有两棵子树 左子树和右子树是有顺序的, 次序不能任意颠倒 即使树中某结点只有一棵子树,也要区分它是左子树还是右子树. 6.5.2 特殊二叉树 斜树 所有的结点都只有左子树的二叉树叫做左斜树 所有的结点都只有右子树的二叉树叫做右斜树 明显特点: 每一层只有一个结点,结点的个数与二叉树的深度相同 所以,线性表结构就可以理解为是树的一种极其特殊的表现形式. 满二叉树 所有的分支结点都存在左子树和右子树,并且所有叶子都在同一层上 注意: 还需要所有的叶子都在同一层上,这就做到了整棵树的平衡 特点: 叶子只出现在最下一层 非叶子结点的度一定是 2 同样深度的二叉树中,满二叉树的结点个数最多,叶子数最多 完全二叉树 对一棵具有 n 个节点的二叉树按层序编号,如果编号为 i (1&lt;=i&lt;=n) 的结点与同样深度的满二叉树中编号为 i 的结点在二叉树中位置完全相同,则这棵二叉树称为完全二叉树 完全二叉树是满二叉树的子集 关键词: 按层序编号 特点: 叶子只出现在最下两层 最下层的叶子一定集中在左部连续位置 倒数第二层,如果有叶子结点,一定都在右部连续位置 如果结点度为 1,则该结点只有左孩子,即不存在只有右子树的情况 同样结点数的二叉树,完全二叉树的深度最小(因为尽可能的把左边补满,把叶子留在右边) 6.6 二叉树的性质 在二叉树的第 i 层上至多有 2 的 i-1 次方个节点 深度为 k 的二叉树至多有 2 的 k 次方-1 个节点(k&gt;=1) 其实就是把每一层装满,可以根据字节的每一位为 1 理解 对任何一颗二叉树T,如果其终端结点数为 n0,度为 2 的结点数位 n2, 则 n0 = n2 + 1 通过结点数和分支线数角度推算 具有 n 个结点的完全二叉树的深度为$$⌊log_2n⌋+1$$注意向下取整符号 如果对一棵有 n 个节点的完全二叉树 (其深度如 4) 的结点按层序编号,对任一结点 i(1&lt;=i&lt;=n)有: 如果 i=1,则结点 i 是二叉树的根,无双亲; 如果 i&gt;1,则其双亲是结点[i/2]. 如果2i&gt;n, 则结点 i 无左孩子(结点 i 为叶子结点); 否则其左孩子是结点 2i 因为每下一层的编号是上一层编号的 2 倍或 2 倍+1,n 不够当然是叶子 如果 2i+1&gt;n,则结点 i 无右孩子; 否则其右孩子是结点 2i+1 6.7 二叉树的存储结构6.7.1 二叉树顺序存储结构二叉树是一种特殊的数,由于其特殊性,使得用顺序存储结构也能实现. 考虑完全二叉树,编号依照顺序来的,所以可以依次放入数组 考虑一般的二叉树,将其按照完全二叉树编号,只不过把不存在的结点标识出来 考虑极端情况,一棵深度为 k 的右斜树,它只有 k 个结点,却需要分配$$2^k -1$$个存储单元空间,这显然是浪费 所以: 顺序存储结构一般只用于完全二叉树 6.7.2 二叉链表二叉树每个结点最多有两个孩子,所以为它设计一个数据域和两个指针域. 这样的链表叫做二叉链表 data: 数据域 lchild: 指向左孩子的指针 rchild: 指向右孩子的指针 如果有需要,还可以增加一个指向双亲的指针域,那样就称之为三叉链表 6.8 遍历二叉树二叉树的遍历(traversing binary tree) 是指从根节点触发,按照某种次序依次访问二叉树中所有结点,使得每个结点被访问一次且仅被访问一次 6.8.2 二叉树遍历方法从左到右的习惯方式下,一共四种: 前序遍历 规则是若二叉树为空,则空操作返回,否则先访问根节点,然后前序遍历左子树,再前序遍历右子树 也就是先根,然后左结点,右结点 中序遍历 规则是若树为空,则空操作返回, 否则从根结点开始(注意并不是访问), 中序遍历根结点的左子树,然后是访问根节点,最后中序遍历右子树. 也就是对于每一个子树,都是先左结点,根,右结点 后序遍历 规则是若树为空,则空操作返回,否则从左到右,先叶子后结点的方式遍历访问左右子树,最后访问根节点 也就是先左右,后根 层序遍历 规则是若树为空,则空操作返回,否则从树的第一层,也就是根结点开始访问,从上而下逐层遍历,在同一层中,按从左到右对结点逐个访问 遍历方式有什么用? 因为对于计算机来说,它只有循环判断等方式,也就是说,只能处理线性序列,而这四种遍历方法,其实就是把树中的结点变成某种意义的线性序列. 6.8.3 前序遍历算法二叉树定义是用递归的方式,所以遍历算法也可以采用递归 1// 二叉树的前序遍历递归算法void PreOrderTraverse(BiTree T)&#123; if(T==null) return; printf(&quot;%c&quot;,T-&gt;data); // 结点操作 PreOrderTraverse(T-&gt;lchild); // 先前序遍历左子树 PreOrderTraverse(T-&gt;rchild); // 最后前序遍历右子树&#125; 理解递归函数要从栈的角度理解 6.8.4 中序遍历算法和前序遍历算法仅仅是代码顺序的差异 123456789// 二叉树的中序遍历递归算法void InOrderTraverse(BiTree T)&#123; if(T==null) return; InOrderTraverse(T-&gt;lchild); // 中序遍历左子树 printf(&quot;%c&quot;,T-&gt;data); // 结点操作 InOrderTraverse(T-&gt;rchild); // 最后中序遍历右子树&#125; 6.8.5 后序遍历算法同样 123456789// 二叉树的后序遍历递归算法void PostOrderTraverse(BiTree T)&#123; if(T==null) return; PostOrderTraverse(T-&gt;lchild); // 中序遍历左子树 PostOrderTraverse(T-&gt;rchild); // 最后中序遍历右子树 printf(&quot;%c&quot;,T-&gt;data); // 结点操作&#125; 6.8.6 推导遍历结果题目 1: 已知一棵二叉树的前序遍历序列为 ABCDEF,中序遍历序列为 CBAEDF,请问后序遍历结果是多少? (CBEFDA) 题目2: 二叉树的中序序列是 ABCDEFG,后序序列是 BDCAFGE,求前序序列. (EACBDGF) 我的方法: 根据前序根最前,后序根最后的规则,将大树拆小树,小树拆小小树判定 二叉树遍历的性质: 已知前序遍历序列和中序遍历序列,可以唯一确定一棵二叉树 已知后序遍历序列和中序遍历序列,可以唯一确定一棵二叉树 已知前序和后序遍历,是不能确定一棵二叉树的, 原因: 前序 ABC,后序 CBA,我们只能知道 A 是根节点,B 是 A 的孩子,但是不知道 C 是 B 的左子树还是右,B 是 A 的左子树还是右 6.9 二叉树的建立为了让每个结点确认是否有左右孩子,将二叉树中每个结点的空指针引出一个虚结点,其值为一特定值,比如”#”. 我们称这种处理后的二叉树为原二叉树的拓展二叉树 拓展二叉树可以做到一个遍历序列可以确定一棵二叉树 算法略 6.10 线索二叉树6.10.1 线索二叉树原理一个 n 个结点的二叉链表,一共是 2n 个指针域,n-1 条分支线数,所以存在 2n-(n-1) = n+1个空指针域,浪费了内存资源 在二叉链表,我们只能知道每个结点指向其左右孩子结点的地址,而不知道其前驱和后继(遍历结果) 所以利用空指针,存放指向结点在某种遍历次序下的前驱和后继结点的地址. 这种指向前驱和后继的指针称为线索,加上线索的二叉链表称为线索链表,相应的二叉树称为线索二叉树(Threaded Binary Tree) 我们把二叉树进行中序遍历后,将所有空指针中的 rchild,改为指向它的后继结点, 将这棵二叉树的空指针域中的 lchild,改为指向当前结点的前驱. 通过这种形式,我们可以把一棵二叉树转变成一个双向链表,这样对插入删除结点,查找结点带来方便. 对二叉树以某种次序遍历使其变为线索二叉树的过程称作是线索化. 如何区分指针是指向孩子还是前驱/后驱? 每个结点增设两个标志域 ltag 和 rtag, 仅仅存放 0/1 的 boolean 型变量,内存空间小 tag为 0 时指向该结点的孩子,1 时指向前驱/后继 6.10.2 线索二叉树结构实现二叉树线索存储结构定义: 1typedef enum &#123;Link,Thread&#125; PointerTag;typedef struct BiThrNode&#123; TElemType data; struct BiThrNode *lchild, *rchild; PointerTag LTag; PointerTag RTag;&#125; BiThrNode, *BiThrTree; 线索化的实质就是将二叉链表中的空指针改为指向其前驱或后继的线索.由于前驱和后继的信息只有在遍历该二叉树时才能得到,所以,线索化的过程就是在遍历的过程中修改空指针的过程 1BiThrTree pre; // 全局变量,始终指向刚访问过的结点// 中序遍历线索化void InThreading(BiThrTree p)&#123; if(p) &#123; InThreading(p-&gt;lchild); // 递归左子树线索化 if(!p-&gt;lchild) // 没有左孩子 &#123; p-&gt;LTag=Thread; // 前缀线索 p-&gt;lchild=pre; // 左孩子指针指向前驱 &#125; if(!pre-&gt;rchild) // 没有右孩子 &#123; pre-&gt;RTag=Thread; // 后缀线索 pre-&gt;rchild=p; // 前驱右孩子指针指向后继(当前结点 p) &#125; pre=p; // 保持 pre 指向 p 的前驱 InThreading(p-&gt;rchild); // 递归右子树线索化 &#125;&#125; 遍历发现其实就是操作双向链表,所以添加一个头结点, 令其 lchild 域的指针指向二叉树的根结点,其 rchild 域的指针指向中序遍历时访问的最后一个结点 令中序的第一个结点的 lchild 指针和最后一个结点的 rchild 指针均指向头结点 这样的好处: 我们既可以从第一个结点起顺后继进行遍历,也可以从最后一个结点起顺前驱进行遍历. 算法略 它等于一个链表的扫描,时间复杂度为 O(n) 由于它充分利用了空指针域的空间,又保证了创建一次遍历就可以终生受前驱后继信息,所以,如果所用的二叉树需经常遍历或查找结点时需要某种遍历序列中的前驱和后继,那么采用线索二叉链表的存储结构是非常不错的选择 6.11 树,森林与二叉树的转换6.11.1 树转换为二叉树步骤如下 加线. 在所有兄弟结点之间加一条连线 去线. 对树中每个结点,只保留它与第一个孩子的连线,删除它与其他孩子结点之间的连线. 层次调整. 以树的根节点为轴心,将整棵树顺时针旋转一定的角度,使之结构层次分明. 注意第一个孩子是二叉树结点的左孩子,兄弟转换过来的孩子是结点的右孩子 其实就是将树每一个结点的多个结点转换成深度 左孩子: 第一个孩子 右孩子: 兄弟 6.11.2 森林转换为二叉树森林 = 若干棵树 把森林的每一棵树理解成兄弟 步骤如下: 把每棵树转换为二叉树 第一棵二叉树不动,从第二棵二叉树开始,依次把后一棵二叉树的根结点作为前一棵二叉树的根结点的右孩子,用线连起来,当所有的二叉树连起来后就得到了由森林转换来的二叉树 所以这么来看,森林中每一棵树的排位顺序也影响了最后转换结果 6.11.3 二叉树转化为数步骤如下: 加线. 若结点的左孩子结点存在(也就是说有大儿子), 则将这个左孩子的所有 n 个右孩子结点都作为此结点的孩子. 将该结点与这些右孩子结点用线连接起来(如果有大孩子,则将大孩子的所有右孩子(原本是树结构下结点的大孩子的兄弟)连起来) 去线. 删除原二叉树中所有结点与右孩子结点的连线(因为以前是树结构下的兄弟) 层次调整 6.11.4 二叉树转换为森林判断一棵二叉树能够转换成一棵树还是森林? 看二叉树的根结点有没有右孩子,有就是森林,没有就是一棵树 树只有一个根结点,转换为二叉树,根结点也只有一个左孩子! 它的所有兄弟都作为左孩子的右结点下面了 转换步骤: 从根结点开始, 若右孩子存在,则把右孩子结点的连线删除,再查看分离后的二叉树,循环这一步,直到所有右孩子结点的连线都删除为止,得到分离的二叉树. 将每颗分离后的二叉树转换为树即可. 6.11.5 树与森林的遍历树的遍历分为两种方式: 先根遍历. 先访问树的根结点,然后依次先根遍历根的每棵子树 后根遍历. 先访问每棵子树,最后访问根结点 森林的遍历也分为两种方式: 前序遍历: 先访问森林中第一棵树的根结点 依次先根遍历根的每棵子树 再依次用同样的方式遍历除去第一棵树的剩余树构成的森林. 其实就是把几个树的遍历连起来 后序遍历: 先访问森林中第一棵树,后根遍历每棵子树,最后访问根结点 重复 1 遍历除去第一棵树的剩余树构成的森林 结论: 森林的前序遍历和二叉树的前序遍历结果相同 森林的后序遍历和二叉树的中序遍历结果相同 也就是说: 当以二叉链表作树的存储结构时,树的先根遍历和后根遍历完全可以借用二叉树的先序遍历和中序遍历的算法来实现. 也就是说,我们找到了对树和森林这种复杂问题的简单解决方法 6.12 赫夫曼树及其应用6.12.1 赫夫曼树最基本的压缩编码方法: 赫夫曼编码 编码中提到的特殊的二叉树称为赫夫曼树 6.12.2 赫夫曼树定义与原理从树中一个结点到另一个结点之间的分支构成两个结点之间的路径,路径上的分支数目称作路径长度. 树的路径长度就是从树根到每一结点的路径长度之和 考虑到带权的结点,假设有 n 个权值构造一棵有 n 个叶子结点的二叉树.自重带权路径长度 WPL 最小的二叉树称作赫夫曼树(最优二叉树). 赫夫曼树的赫夫曼算法 根据给定的 n 个权值{w1,w2,…,wn},构成 n 棵二叉树的集合 F={T1,T2,…,Tn},其中每棵二叉树 T1中只有一个带权为 w1的根结点,其左右子树为空. 在 F 中选取两棵根结点的权值最小的树作为左右子树构造一棵新的二叉树,且置新的二叉树的根结点的权值为其左右子树上根结点的权值之和. 在 F 中删除这两棵树,同时将新得到的二叉树加入 F 中 重复 2,3 步骤,知道 F只含一颗树位置. 这棵树就是赫夫曼树 6.12.3 赫夫曼编码一般地,设需要编码的字符集为{d1,d2,…dn}, 各个字符在电文中出现的次数或频率集合为{w1,w2,…wn},以 d1,d2,…dn为叶子结点,以w1,w2,…wn作为相应叶子结点的权值来构造一棵赫夫曼树. 规定赫夫曼树的左分支代表 0,右分支代表 1,则从根结点到叶子结点所经过的路径分支组成的 0 和 1 的序列便为该结点对应字符的编码,这就是赫夫曼编码. 因为在解码时,还是要用到赫夫曼树,所发送方和接收方必须要约定好同样的赫夫曼编码规则 6.13 总结 树的定义(递归) 树的存储结构: 双亲表示法 孩子表示法 孩子兄弟表示法 通过孩子兄弟表示法,可以将树 -&gt; 二叉树 二叉树: 斜树 满二叉树 完全二叉树 二叉树的存储结构由于其特殊性使得既可以用顺序存储结构又可以用链式存储结构表示 遍历是二叉树最重要的一门学问 前序遍历 中序遍历 后序遍历 层序遍历 二叉链表有很多空指针 -&gt; 如何构造线索二叉树 树,森林,二叉树互相转换的方法 二叉树的应用 -&gt; 赫夫曼树和赫夫曼编码. 7. 图7.2 图的定义图是一种较线性表和树更加复杂的数据结构. 在图形结构中,结点之间的关系可以是任意的,图中任意两个数据元素之间都可能相关 图(Graph) 是由顶点的有穷非空集合和顶点之间边的集合组成,通常表示为: $G(V,E)$, 其中,G 表示一个图,V 是图G 中顶点的集合,E 是图 G 中边的集合. 数据元素在线性表中叫元素,在树中叫结点,在图中叫顶点(Vertex) 图结构中,不允许没有顶点,顶点集合 V 有穷非空 线性表中,相邻的元素之间具有线性关系; 树结构中,相邻两层的结点具有层次关系; 图中,任意两个顶点之间都可能有关系,顶点之间的逻辑关系用边来表示,边集可以是空的 7.2.1 各种图定义无向边: 若顶点 vi 到 vj之间的边没有方向,则称这条边为无向边(Edge), 用无序偶对 (vi,vj​) 来表示. 如果图中任意两个顶点之间的边都是无向边,则称该图为无向图 (Undirected graphs). 有向边: 若从顶点 vi 到 vj 的边有方向,则称这条边为有向边,也称为弧(Arc). 用有序偶 &lt;vi , vj &gt; 来表示, vi 表示弧尾 (Tail), vj 称为弧头 (Head). 如果图中任意两个顶点之间的边都是有向边, 则称该图为有向图 (Directed graphs). 无向边用小括号”()”表示,有向边用尖括号”&lt;&gt;”表示 若不存在顶点到其自身的边,且一条边不重复出现,则称这样的图为简单图. (本书讨论的范围) 无向图中, 如果任意两个顶点之间都存在边, 则称该图为无向完全图. 含有 n 个顶点的无向完全图有$n*(n-1)/2$ 条边. 在有向图中,如果任意两个顶点之间都存在方向互为想反的两条弧, 则称该图为有向完全图. 含有 n 个顶点的有向完全图有$n*(n-1)$ 条边. 有很少条边或弧的图称为稀疏图,反之称为稠密图. (这里稀疏和稠密都是相对的模糊的概念) 有些图的边或弧具有与它相关的数字,这种与图的边或弧相关的树叫做权(Weight). 这些权可以表示从一个顶点到另一个顶点的距离或耗费. 这种带权的图通常称为网(Network). 如果一个图的顶点集和边集都是另一个图的子集,则称此图是另一个图的子图(Subgraph) 7.2.2 图的顶点与边间的关系对于一个无向图,如果一个边在边集中, 则称这个边的两个顶点互为邻接点(Adjacent),即两个顶点相邻接. 边依附(Incident)于这两个顶点,或者说两个顶点相关联. 顶点v 的度(Degree)是和 v 相关联的边的数目,记为 TD(v). 边其实就是各顶点度数和的一半, 多出的一半是因为重复两次计数. 对于有向图, 一个叫邻接到顶点,一个叫邻接自顶点. 以顶点 v 为头的弧的数目称为 v 的入度(InDegree),记为 ID(v); 以 v 为尾的弧的数目称为 v 的出度(OutDegree),记为 OD(v); 顶点 v 的度为 $TD(v) = ID(v) + OD(v)$. 出度和入度都是正的 各顶点的出度和等于入度和 路径的长度是路径上的边或弧的数目 第一个顶点到最后一个顶点相同的路径称为回路或环(Cycle). 序列中顶点不重复出现的路径称为简单路径. 除了第一个顶点和最后一个顶点之外,其余顶点不重复出现的回路,称为简单回路或简单环. 7.2.3 连通图相关术语无向图中,如果两个顶点之间有路径,则称两个顶点是连通的. 如果对于图中任意两个顶点都是连通的, 则称图是连通图(Connected Graph) 无向图中的极大连通子图称为连通分量 要是子图 子图要是连通的 连通子图含有极大顶点数 具有极大顶点数的连通子图包含依附于这些顶点的所有边 有向图G中,如果对于每一对 vi , vj 从 vi 到 vj 和从 vj 到 vi 都存在路径,则称 G 是强连通图. 有向图中的极大强连通子图称作有向图的强连通分量. 一个连通图的生成树是一个极小的连通子图, 它还有图中全部的 n 个顶点,但只有足以构成一棵树的 n - 1 条边. 如果一个图有 n 个顶点和小于 n-1条边,则是非连通图 如果它多于 n-1边条,必定构成一个环 如果一个有向图恰有一个顶点的入度为 0, 其余顶点的入度为 1, 则是一棵有向树. 一个有向图的生成森林由若干棵有向树组成,含有图中全部顶点, 但只有足以构成若干棵不相交的有向树的弧 7.2.4 图的定义与术语总结 图按照有无方向分为无向图和有向图 无向图由顶点和边构成 有向图由顶点和弧构成. 弧有弧尾和弧头之分 图按照边或弧的多少分稀疏图和稠密图 如果任意两个顶点都存在边叫完全图,有向的叫有向完全图 若无重复的边或顶点到自身的边叫简单图 顶点有邻接点,依附的概念 无向图顶点的边数叫做度 有向图顶点分为入度和出度 图上的边或弧上带权则成为网 图中顶点间存在路径 两顶点存在路径则说明是连通的 如果路径最终回到起始点则成为环 当中不重复叫简单路径 若任意两顶点都是连通的,则图就是连通图; 有向则称强连通图 图中有子图,若子图极大连通则就是连通分量,有向的则称强连通分量. 有向图中连通且 n 个顶点 n-1 条边叫生成树 有向图中一顶点入度为 0 其余顶点入度为 1 的叫有向树. 一个有向图由若干棵有向树构成生成森林 7.3 图的抽象数据类型 略 7.4 图的存储结构顺序存储结构: 无法以数据元素在内存中的物理位置来表示元素之间的关系 多重链表: 尽管可以实现图结构但是会有很多存储单元的浪费 7.4.1 邻接矩阵顶点用一维数组可以存储, 但是边或者弧是顶点之间的关系,一维不行,那么就考虑二维数组 图的邻接矩阵(Adjacency Matrix) 存储方式是用两个数组来表示图. 一个一维数组存储图中顶点信息, 一个二维数组(称为邻接矩阵)存储图中的边或弧的信息. 设图 G 有 n 个顶点,则邻接矩阵是一个 n * n 的方阵. 矩阵的对角线为 0 是因为没有顶点到自身的边, 值为 1 表示有边存在, 0 表示不存在. 无向图无向图的边数组是一个对称矩阵 对称矩阵: 左上角到右下角的主对角线为轴,右上角的元与左下角的元全都是相等的 矩阵推断图的信息: 判定两顶点是否有边更容易 某个顶点的度,就是这个顶点 vi 在第 i 行或 i 列的元素之和. 求顶点 vi 的所有邻接点就是将矩阵中第 i 行元素扫描一遍,值为 1 就是邻接点 有向图因为是有向图,所以矩阵并不对称 判断顶点 vi到 vj是否存在弧,只需要查找矩阵中 $arc[i][j]$ 是否为1 即可 vi的所有邻接点就是将矩阵第 i 行元素扫描一遍,查找 $arc[i][j]$ 为 1 的顶点 网图使用 Wij 表示权值. ∞ 表示一个不可能的极限值 (不是零的原因是规避权值为 0 的情况,主对角线就是 0) n个顶点和 e 条边的无向网图的创建,时间复杂度为$O(n+n^2+e)$, 其中对邻接矩阵的初始化耗费了$O(n^2)$的时间 7.4.2 邻接表由于对于边数大量小于顶点的图,邻接矩阵对存储空间有极大的浪费. 我们考虑对边或弧使用链式存储的方式. 采用一种类似树的孩子表示法. 这种数组与链表相结合的存储方法成为邻接表(Adjacency List) 处理方法: 图中顶点用一个一维数组存储. 每个数据元素还需要存储指向第一个邻接点的指针,以便查找该顶点的边信息. 每个顶点vi 的所有邻接点构成一个线性表, 由于个数不定,所以用单链表, 无向图称为顶点 vi的边表,有向图则称为顶点 vi作为弧尾的出边表 对于带权值的网图, 可以在边表结点定义中再增加一个 weight 数据域,存储权值信息即可 本算法的时间复杂度对于 n 个顶点 e 条边来说,是$O(n+e)$ 7.4.3 十字链表(有向图优化)邻接表缺点: 邻接表关心了出度问题,想了解入度就必须遍历整个图; 逆邻接表解决了入度却不了解出度的情况. 十字链表(Orthogonal List): 就是把邻接表和逆邻接表结合起来的一种存储方法 重新定义顶点表结点结构: data firstin: 入边表头指针 firstout: 出边表头指针 重新定义边表结点结构 tailvex: 弧起点在顶点表的下标 headvex: 弧终点在顶点表中的下标 headlink: 入边表指针域,指向终点相同的下一条边 taillink: 出边表指针域., 指向起点相同的下一条边 (weight); 权值 其实就是 v0 有一条从 v1 来的话,firstin 指向 v1 的边表的那个 v1 指向 v0 的那一个, 再将这一个边结点的 headlink 指向 v0 的下一个入边 所以每个顶点的 firstin 指针开始到结束就能找到所有的入边 十字链表除了结构复杂, 创建图算法的时间复杂度是和邻接表相同的, 因此,在有向图的应用中,十字链表是非常好的数据结构模型 7.4.4 邻接多重表(无向图优化)邻接表的问题: 如果删除(v0,v2) 这条边,需要对邻接表结构中右边表的两个结点进行删除,比较麻烦 邻接多重表结构: ivex: 与某条边依附的两个顶点在顶点表中下标(为了方便,设置为与一旁的顶点下标相同) ilink: 指向依附顶点 ivex 的下一条边 ilink指向的结点的 jvex 一定要和它本身的 ivex 值相同 jvex: 与某条边依附的两个顶点在顶点表中下标 jlink: 指向依附顶点 jvex 的下一条边 不论 ilink 还是 jlink,指向的地方是结点 7.4.5 边集数组边集数组是由两个一维元素构成. 一个是存储顶点的信息; 另一个是存储边的信息, 这个边数组每个数据元素由一条边的起点下标(begin),终点下标(end)和权(weight)组成. 要查找一个顶点的度需要扫描整个边数组,效率不高 适合对边依次进行处理的操作,不适合对顶点相关的操作 7.5 图的遍历图的遍历 (Traversing Graph): 从图中某一顶点出发访问遍历图中其余顶点,且使每个顶点仅被访问一次. 两种遍历次序方案: 深度优先遍历和广度优先遍历 7.5.1 深度优先遍历Depth_First_Search,简称 DFS. 其实就是一个递归,像是一棵树的前序遍历 从图中某个顶点 v 出发,访问此顶点,然后从 v 的未访问的邻接点出发深度优先遍历图,直至图中所有和 v 有路径相同的顶点都被访问到. 如果是非连通图,一次深度优先遍历后, 若图中尚有顶点未被访问,则另选图中一个未曾被访问的顶点作为起始点,重复上述过程,直至图中所有顶点都被访问到为止. 一步一步来,假设每次选择最右边的走,碰见重复的后退回上一步走右边第二个. 邻接矩阵: 123456789101112131415161718192021222324typedef int Boolean; //Boolean 是布尔类型,其值为 TRUE 或 FALSEBoolean visited[MAX]; // 访问标志的数组// 邻接矩阵的深度优先递归算法void DFS(MGraph G, int i)&#123; int j; visited[i] = TRUE; printf(&quot;%c &quot;,G.vexs[i]); // 遍历 for(j = 0; j &lt; G.numBertexes; j++) // 遍历整个矩阵才能找到邻接点 if(G.arc[i][j] == 1 &amp;&amp; !visited[j]) DEF(G,j); // 对未访问过的邻接顶点递归调用&#125;// 邻接矩阵的深度遍历操作void DFSTraverse(MGraph G)&#123; int i; for(i = 0; i &lt; G.numVertexes; i++) visited[i] = FALSE; // 初始顶点状态为未访问 for(i = 0; i &lt; G.numVertexes; i++) if(!visited[i]) // 对未访问过的顶点调用 DFS, 若是连通图,只会执行一次 DFS(G,i);&#125; 图结构是邻接表的话,在递归函数中将数组换成了链表 123456789101112131415161718192021222324// 邻接表的深度优先递归算法void DFS(GraphAdjList GL, int i)&#123; EdgeNode *p; visited[i] = TRUE; pringf(&quot;%c &quot;, GL-&gt;adjList[i].data); // 访问 p = GL-&gt;adjList[i].firstedge; // 顶点集的第一个边 while(p) &#123; if(!visited[p-&gt;adjvex]) DFS(GL,p-&gt;adjvex); // 对未访问的邻接顶点递归调用(去找第一个边的下一个边的顶点) p = p-&gt;next; &#125;&#125;// 邻接表的深度遍历操作void DFSTraverse(GraphAdjList GL)&#123; int i; for(i = 0; i &lt; GL-&gt;nemVertexes; i++) visited[i] = FALSE; // 初始顶点状态为未访问 for(i = 0; i &lt; GL-&gt;nemVertexes; i++) if(!visited[i]) // 对未访问过的顶点调用 DFS, 若是连通图, 只会执行一次 DFS(G,i);&#125; 对于n 个顶点 e 条边的图来说, 邻接矩阵由于是二维数组,查找每个顶点的邻接点需要访问矩阵中所有元素,因此都需要 O(n^2^) 时间. 邻接表做存储结构时,找邻接点所需的时间取决于顶点和边的数量,所以是 O(n+e). 对于有向图而言,算法上没有变化,可以通用. 7.5.2 广度优先遍历Breadth_First_Search, 简称 BFS. 类似树的层序遍历 算法大致就是构造一个队列,先从一个结点放进去, 然后将第一个结点出队列,将其所有队列中没有的关联结点入队列 继续出队列,重复上一步,知道队列全部出来. 两种方式比较深度优先遍历和广度优先遍历算法的时间复杂度相同 深度优先适合目标比较明确,以找到目标为主要目的的情况 广度优先适合在不断扩大遍历范围时找到相对最优解的情况 两者与算法实现无关,是方法论的问题. 是矛盾又统一的两方面 7.6 最小生成树一个带权值的图,即网结构. 所谓的最小成本,就是 n 个顶点,用 n-1 条边把一个连通图连接起来,使得权值的和最小. 我们把构造连通网的最小代价生成树称为最小生成树(Minimum Cost Spanning Tree) 经典的寻找最小生成树的有两种算法,普利姆算法和克鲁斯卡尔算法 7.6.1 普利姆(Prim)算法先构造图的邻接矩阵 然后算法略 算法定义: 假设$N = (P,{E})$ 是连通网,TE 是 N 上最小生成树中边的集合. 算法从 U={u0} , TE={} 开始.重复执行下述操作: 在所有 $u ∈ U, v ∈ V -U$ 的边 $(u,v)∈E$中找一条代价最小的边 (u0, v0) 并入集合 TE, 同时 v0 并入 U, 直至 U=V 为. 此时 TE 中必有 n-1 条边, 则$T(V,{TE})$ 为 N 的最小生成树 由算法中的嵌套循环可知算法的时间复杂度为 O(n^2^) 简单的绘图方法就是,找一个点,作为子树集合,画一个圆圈包起来, 剩下的点集到这个圆圈的距离最短的那个加入子树集合,重新画圈,反复重复. 是以某顶点为起点,逐步找各顶点上最小权值的边来构建最小生成树的 7.6.2 克鲁斯卡尔(Kruskal)算法K 算法直接以边为目标. 将图先转化为边集数组, 并且对他们按权值从小到大排序 算法略 定义如下: 假设$N=(V,{E})$是连通网, 则令最小生成树的初始状态为只有 n 个顶点而无边的非连通图$T{V,{}}$, 图中每个顶点自成一个连通分量. 在 E 中选择代价最小的边,若该边依附的顶点落在 T 中不同的连通分量上, 则将此边加入到 T 中, 否则舍去此边而选择下一条代价最小的边. 以此类推, 直至 T 中所有顶点都在同一连通分量上为止. 此算法的 Find 函数由边数 e 决定,时间复杂度为$O(loge)$, 而外面有一个 for 循环 e 次. 所以 K 算法的时间复杂度为$O(eloge)$ 对比克鲁斯卡尔算法(K 算法)主要针对边展开,边数少效率高,对于稀疏图有很大优势 普利姆算法(P 算法)对于稠密图, 边数多的情况更好. 7.7 最短路径非网图: 没有边上的权值,最短路径就是指两顶点之间经过的边数最少的路径; 网图: 最短路径,是指两顶点之间经过的边上的权值之和最少的路径, 并且我们称路径上的第一个顶点是源点,最后一个顶点是终点. 7.7.1 迪杰斯特拉(Dijkstra)算法这是一个按路径长度递增的次序产生最短路径的算法 这个算法不是一下子就求出了两点之间的最短路径,而是一步步求出它们之间顶点的最短路径,过程中都是讲基于已经求出的最短路径的基础上,求得更远顶点的最短路径,最终得到想要的结果. 算法略 算法是一个嵌套 算法核心两步,一是找到某个点到源点的最近距离,二是根据这个最近距离更新这个点相邻的结点的最短距离 通过 D 算法解决了从某个源点到其余各顶点的最短路径问题. 从循环嵌套可知, 时间复杂度为 $O(n^2)$ 如果要知道任意顶点到其余所有顶点的最短距离,就是将每个顶点当做源点做一次 D 算法, 就是再来一次循环, 时间复杂度就成了$O(n^3)$ 7.7.2 弗洛伊德(Floyd)算法算法略 算法的核心就是构建两个二维数组 D,P D 代表顶点到顶点的最短路径权值和的矩阵 P 代表对应顶点的最小路径的前驱矩阵. 然后依次选择下一个中转并更新 D 和 P 建议笔算理解 三重循环,时间复杂度为 $O(n^3)$ 面临需求所有顶点至所有顶点的最短路径问题时,弗洛伊德 F 算法应该是不错的选择. 7.8 拓扑排序是无环的图的应用. 无环即图中没有回路 7.8.1 拓扑排序介绍如果把工程比作图,某些活动肯定在某些活动之后才开始, 这样的工程图肯定是无环的有向图 AOV网: 在一个表示工程的有向图中, 用顶点表示活动, 用弧表示活动之间的优先关系, 这样的有向图为顶点表示活动的网, 我们称为 AOV 网(Activity On Vertex Nextwork) AOV 网中不能存在回路 拓扑序列: 设 $G=(V,E)$ 是一个具有 n 个顶点的有向图,V 中的顶点序列 v1, v2, … , vn 满足若从顶点 vi 到 vj 有一条路径, 则在顶点序列中顶点 vi 必在顶点 vj 之前. 则我们称这样的顶点序列为一个拓扑序列 拓扑序列有可能不止一条 拓扑排序,其实就是对一个有向图构造拓扑序列的过程 如果此网的全部顶点都被输出,则说明它是不存在环(回路)的 AOV 网 如果输出顶点少了, 哪怕是少了一个,也说明这个网存在环(回路), 不是 AOV 网 这个少的原因书中没有描述清楚, 我的理解是: 如果是环,则这个顶点无法满足既在前又在后,所以无法放入拓扑序列, 所以最后输出的顶点肯定少. 7.8.2 拓扑排序算法对 AOV 网进行拓扑排序的基本思路: 从 AOV 网中选择一个入度为 0 的顶点输出,然后删除此顶点,并删除以此顶点为尾的弧, 继续重复此步骤,知道输出全部顶点或者 AOV 网中不存在入度为 0 的顶点为止 由于需要删除顶点,所以用邻接表 由于始终要找入度为 0 的点,所以顶点表结构中增加一个入度域 in; 边表不变 结构: in: 入度的数字 data: 数据 firstedge: 边表头指针 结构代码: 12345678910111213141516171819typeof struct EdgeNode // 边表结点&#123; int adjvex; // 邻接点域,存储该顶点对应的下标 int weight; // 用于存储权值,对于非网图可以不需要 struct EdgeNode *next; // 链域,指向下一个邻接点&#125;EdgeNode;typeof struct VertexNode // 顶点表结点&#123; int in; // 顶点入度 int data; // 顶点域, 存储顶点信息 EdgeNode *firstedge; // 边表头指针&#125;VertexNode, AdjList[MAXVEX];typedef struct&#123; AdjList adjList; int numVertexes,numEdges; // 图中当前顶点数和边数&#125;graphAdjList,*GraphAdjList; 算法代码略 思想就是: 先初始化一个栈, 将所有入度为 0 的顶点入栈. 然后出栈栈顶元素a, 找到其连接的顶点, 并将它们的入度减少一位. 如果入度减少到 0, 入栈 删除刚刚出栈的元素a 再次循环3-5 对于一个具有 n 个顶点 e 条弧的 AOV 网来说, 初始化时候扫描顶点表,入度为 0 入栈的时间复杂度为$ O(n)$; 之后循环的时候,每个顶点进栈一次,出栈一次,入度减一一次, 共 e 次 整个算法时间复杂度为 $O(n+e)$ 7.9 关键路径拓扑排序没有解决最短路径问题. 在一个表示工程的带权有向图中, 用顶点表示事件, 用有向边表示活动, 用边上的权值表示活动的持续时间, 这种有向图的边表示活动的网, 我们称之为 AOE 网 (Activity On Edge Network) AOE 网只有一个源点一个汇点 与 AOV 的不同: AOV 顶点表示活动, 只描述活动的先后制约. AOE 是用边表示活动的网,边上的权值表示活动持续的时间 我们把路径上各个活动所持续的时间之和称为路径长度, 从源点到汇点具有最大长度的路径叫关键路径, 在关键路径上的活动叫关键活动. 只有缩短关键路径上的关键活动时间才可以减少整个工期长度 7.9.1 关键路径算法原理如果一个活动最早开始时间和最晚开始时间不相等,就意味着有空闲. 所以找到两者相等的,就是关键活动了,活动间的路径就是关键路径 为此,定义如下参数: 事件的最早发生时间 etv (earliest time of vertex): 即顶点 vk的最早发生时间. 事件的最晚发生时间 ltv (latest time of vertex): 即顶点 vk的最晚发生时间. 活动的最早开工时间 ete (earliest time of edge): 即弧ak的最早发生时间 活动的最晚开工时间 lte (latest time of edge): 即弧 ak 的最晚发生时间. 可以由 1 和 2 求出 3 和 4, 判断 ete[k] 和 lte[k] 是否相等来判断 ak 是否是关键活动 7.9.2 关键路径算法将 AOE 网转化为邻接表, 与拓扑排序的邻接表结构不同在于弧链表增加了 weight 域,用来存储弧的权值 也就是顶点集合依旧有一个域存储入度 算法略 由好几个算法构成,首先修改了拓扑排序算法,拓扑排序后得到 etv, 然后算出 ltv ( ltv 的算法其实是将拓扑序列倒过来进行的), 然后通过比较 ete 和 lte 得出关键活动 妙哇! 分析整个关键路径算法, 拓扑排序时间复杂度为$O(n+e)$; 初始化 ltv 数组 $O(n)$ 计算 ltv 的循环 $O(n+e)$ 求 ete 和 lte 并对相同下标的它们做比较 $O(n+e)$ 所以最终时间复杂度是 $O(n+e)$ 7.10 总结回顾图是最复杂的数据结构 多读几遍.就可以基本理解 图的数据结构(五种): 邻接矩阵 邻接表 边集数组 十字链表 邻接多重表 最重要的是邻接矩阵和邻接表,分别代表着边集是用数组还是链表的方式存储; 十字链表是邻接矩阵的一种升级; 邻接多重表是邻接表的升级; 边集数组更多对边的关注 具体使用什么?稠密图,或读存数据较多,结构修改较少的图: 邻接矩阵 反之: 邻接表 遍历: 深度和广度两种 图的应用 最小生成树 普利姆 Prim 算法 走一步看一步,逐步生成 克鲁斯卡尔 Kruskal 算法 更有全局意识,从图中最短权值的边入手 最短路径 迪杰斯特拉 Dijkstra 算法 强调单源顶点查找路径的方式 弗洛伊德 Floyd 算法 利用矩阵变换, 用最清爽的代码实现了多顶点间最短路径求解的方案,原理理解有难度,算法很简洁 有向无环图 拓扑排序: 有效分析出一个有向图是否存在环 最短时间问题: 求关键路径算法 7.11 结尾语通往牛逼的路上一路狂奔 8. 查找8.1 开场白搜索引擎工作原理: 我制作了一个网页 世界各地的蜘蛛会访问 (蜘蛛就是搜索引擎公司服务器上的软件) 蜘蛛抓取并复制网页,并且通过网页上的连接爬取更多的页面, 将所有信息纳入搜索引擎网站的索引数据库 当搜索时,会带着单词在索引数据库中检索所有包含关键词的网页, 根据浏览次数与关联性等算法确定网页级别,排列出顺序,呈现在网页 8.2 查找概论需要被查的数据所在的集合,统称查找表 查找表 (Search Table) 是由同一类型的数据元素(或记录) 构成的集合. 关键字(Key) 是数据元素中某个数据项的值, 又称为键值, 用它可以标识一个数据元素. 若此关键字可以唯一地标识一个记录, 则称此关键字为主关键字 (Primary Key). 对于那些可以识别多个数据元素(或记录)的关键字,我们称为次关键字(Secondary Key) 查找 ( Searching ) 就是根据给定的某个值, 在查找表中确定一个其关键字等于给定值的数据源元素(或记录). 查找表分类: 静态查找表 Static Search Table: 只作查找操作的查找表 主要操作有: 查询某个”特定的”数据元素是否在查找表中 检索某个”特定的”数据元素和各种属性 动态查找表 Dynamic Search Table: 在查找过程中同时插入查找表中不存在的数据元素,或者从查找表中删除已经存在的某个数据元素 操作: 查找时插入元素 查找时删除元素 为了提高查找的效率, 我们需要专门为查找操作设置数据结构, 这种面向查找操作的数据结构称为查找结构 对于静态查找表来说,不妨用线性表结构,这样可以使用顺序查找算法, 如果对主关键字排序,则可以使用折半查找等技术高效查找 对于动态查找,会复杂些,可以考虑二叉排序树的查找技术 8.3 顺序表查找顺序表查找 (Sequential Search) 又叫线性查找, 是最基本的查找技术, 它的查找过程是: 从表中第一个(或最后一个)记录开始,逐个进行记录的关键字和给定值比较,若某个记录的关键字和给定值相等,则查找成功,找到所查的记录; 如果知道最后一个(或第一个)记录,其关键字和给定值都不等时,则表中没有所查的记录,查找不成功 8.3.1 顺序表查找算法12345678910int Sequential_Search(int *a, int n, int key)&#123; int i; for(i=1;i&lt;=n;i++) &#123; if(a[i] == key) return i; &#125; return 0;&#125; 在数组 a(注意元素值从下标 1 开始)中查看有没有关键字 key 8.3.2 顺序表查找优化设置一个哨兵,可以解决不需要每次让 i 与 n 作比较 1234567891011int Sequential_Search2(int *a, int n, int key)&#123; int i; a[0]=key; // 设置 a[0] 为关键字值,哨兵 i=n; while(a[i]!=key) &#123; i--; &#125; return i; // 返回 0 则说明查找失败&#125; 在总数据较多时,效率提高很大 时间复杂度为 $O(n)$ 顺序查找技术在 n 很大时,查找效率极为低下 8.4 有序表查找8.4.1 折半查找折半查找 (Binary Search) 技术, 又称为二分查找. 它的前提是线性表中的记录必须是关键码有序(通常从小到大有序), 线性表必须采用顺序存储. 折半查找的基本思想是: 在有序表中, 取中间记录作为比较对象, 若给定值与中间记录的关键字相等,则查找成功; 若给定值小雨中间记录的关键字, 则在中间记录的左半区域继续查找; 若给定值大于中间记录的关键字,则在中间记录的右半区域查找. 不断重复上述过程,直到查找成功或失败为止 1234567891011121314151617int Binary_search(int *a,int n,int key)&#123; int low,high,mid; low=1; //定义最低下标为记录首位 high=n; //定义最高下标为记录末位 while(low&lt;=high) &#123; mid=(low+high)/2; //折半 if(key&lt;a[mid]) high=mid-1; else if (key&gt;a[mid]) low=mid+1; else return mid; &#125; return 0;&#125; 折半算法的时间复杂度为 $O(logn)$ 但是由于折半查找的前提是有序表顺序存储, 对于需要频繁执行插入或删除操作的数据集,维护有序的排序会有不小的开销,那就不建议使用 8.4.2 插值查找 为什么折半查找?不是折$1/4$ 或更多? 折半查找的等式为:$$mid=\\frac {low+high} {2} = low+\\frac 1 2(high-low)$$对于这个 1/2 进行改进$$mid=low+ \\frac {key - a[low]} {a[high]-a[low]}(high-low)$$将上述折半查找的第八行更改为 mid=low+(high-low)*(key-a[low])/(a[high]-a[low]); 插值查找( Interpolation Search) 是根据要查找的关键字 key 与查找表中最大最小记录的关键字比较后的查找方法,其核心在于插值的计算公式$\\frac {key - a[low]} {a[high]-a[low]}$ 从时间复杂度来看,也是$O(logn)$ 8.4.3 斐波那契查找首先有一个斐波那契数列数组 F 123456789101112131415161718192021222324252627282930313233int Fibonacci_Search(int *a,int n,int key)&#123; int low,high,mid,i,k; low=1; // 定义最低下标为记录首位 high=n; // 定义最高下标为记录末位 k=0; while(n&gt;F[k]-1) // 计算 n 位于斐波那契数列的位置 k++; for(i=n;i&lt;F[k]-1;i++) // 将不满的数值补全 a[i]=a[n]; while(low&lt;=high) &#123; mid=low+F[k-1]-1; // 计算当前分隔的下标 if(key&lt;a[mid]) // 若查找记录小于当前分隔记录 &#123; high=mid-1; // 最高下标调整到分隔下标 mid-1 处 k=k-1; // 斐波那契数列下标减一位 &#125; else if (key&gt;a[mid]) // 若查找记录大于当前分隔记录 &#123; low=mid+1; // 最低下标调整到分隔下标 mid+1 处 k=k-2; // 斐波那契数列下标减两位 &#125; else &#123; if(mid&lt;=n) return mid; // 若相等说明 mid 即为查找到的位置 else return n; // 若 mid&gt;n 说明是补全数值,返回 n &#125; &#125; return 0;&#125; 今天和对象吵架,没怎么看进去 斐波那契算法的核心在于: 当 key=a[mid] 时,查找就成功; 当 key&lt;a[mid] 时,新范围是第 low 个到第 mid-1 个,此时范围个数为 F[k-1]-1 个; 当 key&gt;a[mid] 时,新范围是第 m+1个到第 high 个,此时范围个数为 F[k-2]-1 个 时间复杂度 $O(logn)$ 区别时间复杂度都是 $O(logn)$ 三种有序表的查找本质上是分隔点的选择不同,各有优劣,实际开发时可根据数据的特点综合考虑. 8.5 线性索引查找排序代价高昂,数据量海量的情况下怎么查找表? 索引 数据结构的最终目的是提高数据的处理速度 索引是为了加快查找速度而设计的一种数据结构 索引就是把一个关键字与它对应的记录相关联的过程 索引按照结构可分为 线性索引: 将索引项集合组织为线性结构,也称索引表 稠密索引 分块索引 倒排索引 树形索引 多级索引 8.5.1 稠密索引稠密索引是指在线性索引中, 将数据集中的每个记录对应一个索引项. 稠密索引表的索引项一定是按照关键码有序的排列 有序就说明可以用到折半,插值,斐波那契等有序查找算法 8.5.2 分块索引因为稠密索引项空间代价很大,为了减少索引项个数,对数据集进行分块,使分块有序,再对每一块建立一个索引项,从而减少索引项的个数 分块有序,是把数据集的记录分成了若干块,并且这些块需要满足: 块内无序, 为了减少排序开销 块间有序, 要求第二块所有记录的关键字都要大于第一块中所有记录的关键字 对于分块有序的数据集,每块对应一个索引项,这种索引方法叫分块索引. 索引项结构分三个数据项: 最大关键码, 存储每一块中的最大关键字 存储了块中的记录个数, 便于循环 用于指向块首元素的指针, 便于开始遍历 分块索引表查找步骤: 在分块索引表中查找要查关键字所在的块 根据首指针找到相应的块,并在块中顺序查找关键码 分块索引在兼顾了对细分块不需要有序的情况下,大大增加了整体查找的速度,所以普遍被用于数据库表查找等技术的应用当中 8.5.3 倒排索引比如将几篇文章拆成英文单词(不重复)和文章编号(记录单词出现的文章号,可以是多个) 索引项的通用结构: 次关键码, 例如英文单词 记录号表, 例如文章编号 其中记录号表存储具有相同次关键字的所有记录的记录号 (可以是指向记录的指针或者是该记录的关键字). 这样的索引方法就是倒排索引 (inverted index). 称为倒排索引的原因: 由于不是由记录来确定属性值,而是由属性值来确定记录的位置 优点: 查找记录非常快 缺点: 记录号不定长 8.6 二叉排序树普通顺序存储因为无序查找效率低 有序线性表,查找效率加快,但是插入和删除,需要耗费大量时间 假设需要对集合做查找,在我们创建此集合时就考虑用二叉树结构,而且是排好序的二叉树. 这样当对它中序遍历时,就可以得到一个有序的序列, 所以称它为二叉排序树 二叉排序树 (Binary Sort Tree), 又称为二叉查找树. 它或者是一棵空树, 或者是具有下列性质的二叉树. 若它的左子树不空, 则左子树上所有结点的值均小于它的根结构的值; 若它的右子树不空,则右子树上所有结点的值均大于它的根节点的值; 它的左,右子树也分别为二叉排序树 这种结构利于插入和删除的实现. 8.6.1 二叉排序树查找操作二叉树的结构 123456// 二叉树的二叉链表结点结构定义typeof struct BiTNode // 结点结构&#123; int data; // 结点数据 struct BiTNode *lchild, *rchild; // 左右孩子指针&#125;BiTNode, *BiTree 二叉排序树的查找 (递归): 123456789101112131415161718192021// 递归查找二叉排序树中 T 是否存在 key// 指针 f 指向 T 的双亲,其初始调用值为 NULL// 若查找成功, 则指针 p 指向该数据元素结点,并返回 TRUE// 否则指针 p 指向查找路径上访问的最后一个结点并返回 FALSEStatus SearchBST(BiTree T, int key, BiTree f, BiTree *p)&#123; if(!T) &#123; *p=f; return FALSE; &#125; else if (key==T-&gt;data) // 查找成功 &#123; *p = T; return TRUE; &#125; else if (key &lt; T-&gt;data) return SearchBST(T-&gt;lchild,key,T,p); // 在左子树继续查找 else return SearchBST(T-&gt;rchild,key,T,p); // 在右子树继续查找&#125; 8.6.2 二叉排序树插入操作123456789101112131415161718192021// 当二叉排序树 T 中不存在关键字等于 key 的数据元素时// 插入 key 返回 TRUE,否则返回 FALSEStatus InsertBST(BiTree *T, int key)&#123; BiTree p,s; // 这个 p 最后的指向见查找代码 if(!SearchBST(*T,key,NULL,&amp;p)) &#123; s = (BiTree) malloc (sizeof(BiTNode)); s-&gt;data = key; s-&gt;lchild = s-&gt;rchild = NULL; if(!p) // 是一个空树 *T = s; // 插入 s 为新的根结点 else if (key &lt; p-&gt;data) p-&gt;lchild = s; // 插入 s 为左孩子 else p-&gt;rchild = s; // 插入 s 为右孩子 return TRUE; &#125; else return FALSE; // 树中已有关键字相同的结点&#125; 所以一段构建二叉排序树的代码: 1234567int i;int a[10] = &#123;62,88,58,47,35,73,51,99,37,93&#125;;BiTree T=NULL;for(i=0;i&lt;10;i++)&#123; InsertBST(&amp;T,a[i]);&#125; 8.6.3 二叉排序树删除操作对于要删除的结点是叶子结点,或者只有左子树或只有右子树,比较好解决, 直接删除或将它的左子树或右子树整个移动到删除结点的位置即可 (独子继承父业) 但是当结点既有左子树又有右子树, 不好处理 我们将它的两个子树找出一个结点来代替它. (前驱或后继) 遍历树代码: 123456789101112131415// 若二叉排序树 T 中存在关键字等于 key 的数据元素时,则删除该数据元素结点, 并返回 TRUE,否则返回 FALSEStatus DeleteBST(BiTree *T, int key)&#123; if(!*T) // 递归也没找到关键字等于 key 的数据元素 return FALSE; else &#123; if(key==(*T)-&gt;data) // 找到关键字等于 key 的数据元素 return Delete(T); else if (key&lt;(*T)-&gt;data) return DeleteBST(&amp;(*T)-&gt;lchild,key); else return DeleteBST(&amp;(*T)-&gt;rchild,key); &#125;&#125; Delete 的代码 12345678910111213141516171819202122232425262728// 从二叉排序树中删除结点 p,并重接它的左或右子树Status Delete(BiTree *p)&#123; BiTree q,s; if((*p)-&gt;rchild==NULL) // 右子树空则只需重接左子树 &#123; q=*p; *p=(*p)-&gt;lchild; free(q); &#125; else if ((*p)-&gt;lchild==NULL) // 只需重接它的左子树 &#123; q=*p; *p=(*p)-&gt;rchild; free(q); &#125; else &#123; q=*p; s=(*p)-&gt;lchild; while(s-&gt;rchild) // 转左,然后向右走到尽头(找前驱) &#123; q=s; s=s-&gt;rchild; &#125; (*p)-&gt;data=s-&gt;data; // s 指向被删结点的直接前驱 if(q!=*p) q-&gt;rchild=s-&gt;lchild; // 重接 q 的右子树 else q-&gt;lchild=s-&gt;lchild; //重接 q 的左子树 free(s) &#125; return TRUE;&#125; q 其实就是 s 的双亲,如果 s 没有右结点就说明是前驱的原因是: 前驱是中序遍历的前一个,也就是左孩子-&gt;根-&gt;右孩子, 推断便知道, 找结点右子树的没有右孩子的将是最后一个结点 8.6.4 二叉排序树总结二叉排序树是以链接的方式存储, 保持了链接存储结构在执行插入或删除操作时不用移动元素的优点,只要找到合适的插入和删除位置后,仅需修改链接指针即可 查找性能取决于二叉排序的性质. 但是形状是不固定的. 如果我们得到的是希望的二叉排序树, 深度与完全二叉树相同, 那么查找的时间复杂度为 $O(logn)$, 近似折半查找. 不平衡的最坏情况就是极端的斜树, 查找时间复杂度为$O(n)$, 等同于顺序查找 如何让二叉树平衡呢??? 8.7 平衡二叉树( AVL 树 )平衡二叉树(Self-Balancing Binary Search Tree), 是一种二叉排序树, 其中每个结点的左子树和右子树的高度差至多等于 1. 是一种高度平衡的二叉排序树. 我们将二叉树上结点的左子树深度减去右子树深度的值称为平衡银子 BF(Balance Factor),那么平衡二叉树上所有结点的平衡银子只可能是-1,0和 1. 距离插入结点最近的, 且平衡因子的绝对值大于 1 的结点为根的子树, 我们称为最小不平衡子树. 插入某个点时,比较它附近的结点,计算平衡因子,最开始找到的也就是最近的结点. 8.7.1 平衡二叉树实现原理基本思想: 每当插入一个结点, 先检查是否因插入而破坏了树的平衡性, 若是,找出最小不平衡子树. 调整, 使之称为新的平衡树. 调整: 当最小不平衡子树根结点的平衡因子 BF 大于 1, 右旋, 小于 -1 就左旋. 插入结点后, 最小不平衡子树的 BF 与它的子树的 BF 符号相反时, 就需要对结点(子树)先进行一次旋转以使得符号相同后, 再反向旋转一次才能够完成平衡操作. 算法略 8.8 多路查找树 ( B 树 )前面讨论的数据结构,处理数据都是在内存中. 若要操作的数据集非常大, 要使用硬盘, 这样时间复杂度就会变化. 为了降低对外存设备的访问次数, 需要新的数据结构: 打破之前谈的树一个结点只能存储一个元素的限制 多路查找树( muitl-way search tree ), 其每一个结点的孩子数可以多于两个,且每一个结点处可以存储多个元素. 由于是查找树, 所有元素之间存在某种特定的排序关系 四种特殊形式: 2-3 树 2-3-4 树 B 树 B+ 树 8.8.1 2-3 树一种多路查找树: 其中的每一个结点都具有两个孩子或三个孩子(我们称它为 2 结点或 3 结点) 一个 2 结点包含一个元素和两个孩子(或没有孩子), 不能只有一个孩子; 一个 3 结点包含一大一小两个元素和三个孩子(或没有孩子). 如果某个 3 结点有孩子的话, 左子树包含小于较小元素的元素, 右子树包含大于较大元素的元素, 中间子树包含介于两元素之间的元素. 2-3 树的插入和删除很复杂, 了解还是用到了再了解吧 8.8.2 2-3-4 树2-3-4 树就是 2-3 树的概念扩展, 包括了 4 结点的使用. 一个 4 结点包含小中大三个元素和四个孩子(或无). 插入和删除略 8.8.3 B 树主角来了 B 树 (B-tree) 是一种平衡的多路查找树, 2-3 树和 2-3-4 树都是 B 树的特例. 结点最大的孩子数目称为 B 树的阶 (order). 因此, 2-3 树是 3 阶 B 树, 2-3-4 树是 4 阶 B 树. 一个 m 阶的 B 树具有如下属性: 如果根结点不是叶子结点, 则至少有两棵子树 每一个非根的分支结点都有 k-1 个元素和 k 个孩子, 其中$⌈m/2⌉ \\le k \\le m$. 每一个叶子结点 n 都有 k-1 个元素, 其中$⌈m/2⌉ \\le k \\le m$ 所有的叶子结点都位于同一层次 所有分支结点都包含下列信息数据 $(n, A_0,K_1,A_1,K_2,A_2,…,K_n,A_n)$, 其中 $K_i(i=1,2,…,n)$ 为关键字, 且 $K_i &lt; K_{i+1}$ $A_{i-1}$所指子树中所有结点的关键字均小于$K_i(i=1,2,…,n)$ $A_n$ 所指子树中所有结点的关键字均大于$K_i(i=1,2,…,n)$ 在 B 树上查找的过程是一个顺时针查找结点和在结点中查找关键字的交叉过程. B 树的插入和删除, 方式与 2-3 和 2-3-4 树相类似, 只不过阶数可能很大. B 树为什么能减少内外存交换数据次数?外存如硬盘,是将所有信息分割成大小相等的页面, 每次硬盘读写都是一个或多个完整的页面, 一个硬盘一页的长度可能是 211 到 214 个字节 在一个 B 树应用中, 数据量很大,无法放入内存时, 对 B 树进行调整, 使得 B 树的阶数(或结点的元素)与硬盘存储的页面大小相匹配. 比如一棵 B 树的阶为 1001(即 1 个结点包含 1000 个关键字), 高度为 2, 那么它可以存储超过 10 亿个关键字, 我们只要让根结点持久地保留在内存中,name 查找某一个关键字只需要最多两次硬盘的读取. 8.8.4 B+ 树对于树结构来说, 我们都可以通过中序遍历来顺序查找树中的元素, 这一切都是在内存中进行. 可是 B 树结构,我们往返于每个结点也就意味着, 我们必须得在硬盘的页面之间进行多次访问 B+树是应文件系统所需而出的一种 B 树的变形树, 严格意义上, 它已经不是之前定义的树了. 在 B 树中,每一个元素在该树中只出现一次, 有可能在叶子结点上, 也有可能在分支结点上; 而在 B+ 树中, 出现在分支结点中的元素会被当做它们在该分支结点位置的中序后继者(叶子结点)中再次列出. 另外, 每一个叶子结点都会保存一个指向后一叶子结点的指针. 根结点中的关键字在叶子结点再次列出 并且所有叶子结点都链接在一起 一棵 m 阶的 B+ 树和 m 阶的 B 树的差异在于: 有 n 棵子树的结点中包含 n 个关键字 所有的叶子结点包含全部关键字的信息, 及指向含这些关键字记录的指针, 叶子结点本身依关键字自小而大顺序链接 所有分支结点可以看成是索引, 结点中仅含有其子树中的最大(或最小)关键字 好处随机查找,就从根结点触发,与 B 树的查找方式相同, 只不过在分支结点找到了待查找的关键字,它也只是用来索引的, 还是要到达包含此关键字的终端结点 如果需要从最小关键字进行从小到大的顺序查找,我们就可以从最左侧的叶子结点触发,不经过分支结点,直接遍历所有关键字 B+ 树的结构特别适合带有范围的查找 B+ 树的插入删除都与 B 树相似, 只不过插入和删除的元素都是在叶子结点上进行而已 8.9 散列表查找(哈希表)概述顺序表查找都需要比较. 能否直接通过关键字得到要查找的记录内存存储位置呢? 8.9.1 散列表查找定义我们只需要通过某个函数 f,使得存储位置=f(关键字), name 就可以通过查找关键字不需要比较就可以获得需要的记录的存储位置. 这就是散列技术. 散列技术是在记录的存储位置和它的关键字之间建立一个确定的对应关系 f,使得每个关键字 key 对应一个存储位置 f(key). 我们把这种对应关系 f 称为散列函数, 又称为哈希(Hash)函数. 采用散列技术将记录存储在一块连续的存储空间中, 这块存储空间称为散列表或哈希表(Hash table). 8.9.2 散列表查找步骤两步 存储时,通过散列函数计算记录的散列地址, 并按此散列地址存储该记录. 查找记录时, 我们通过同样的散列函数计算记录的散列地址, 按此散列地址访问该记录. 散列技术既是一种存储方法,也是一种查找方法 散列表的记录之间不同于前几种结构,没有逻辑关系, 散列技术只与关键字有关联. 因此,散列主要是面向查找的存储结构 优点散列技术最适合的求解问题是查找与给定值相等的记录. 简化了比较,效率大大提高 缺点同样的关键字对应很多记录的情况,不适合散列技术 散列表也不适合范围查找 关键如何设计一个简单,均匀,存储利用率高的散列函数? 两个关键字计算出来的地址一样时怎么解决冲突(collision)? 8.10 散列函数的构造方法好的散列函数: 计算简单 散列地址分布均匀 8.10.1 直接定址法直接取关键字的某个线性函数为散列地址,即$$f(key)=a \\times key+b$$ 优点简单,均匀,不会有冲突 缺点需要事先知道关键字的分布情况,适合查找表较小且连续的情况. 现实中不常用 8.10.2 数字分析法通过分析,抽取关键字中的某些数字. 比如手机号的后四位 适合事先知道关键字的分布且关键字的若干位分布均匀的情况 8.10.3 平方取中法关键字平方取中间的几位数作为散列地址. 适合不知道关键字分布, 位数不是很大的情况 8.10.4 折叠法将关键字从左到右分割成位数相等的几部分, 将这几部分叠加求和, 并按照散列表长,取后几位作为散列地址 适合实现不知道关键字的分布,适合关键字位数较多的情况 8.10.5 除留余数法是最常用的构造散列函数方法 对于散列表长为 m 的散列函数公式为:$$f(key)=key\\mod p (p\\le m)$$mod 是取模(取余数) 很显然, 本方法的关键就在于选择合适的 p 根据前辈的经验, 若散列表表长为 m,通常 p 为小于等于表长(最好接近 m)的最小质数或不包含小于 20 质因子的合数. 8.10.6 随机数法当关键字的长度不等时,采用这个方法构造散列函数比较合适 总结关键字是字符串, 转化为数字来对待, 比如 ASCII 或者 Unicode 现实中,视不同情况采用不同的散列函数, 参考因素: 计算散列地址所需的时间 关键字的长度 散列表的大小 关键字的分布情况 记录查找的频率 需要综合这些因素选择散列函数 8.11 处理散列冲突的方法如果发现使用散列函数前两个关键字$key_1 \\ne key_2$, 但是却有$f(key_1)=f(key_2)$, 有冲突了,怎么解决呢? 8.11.1 开放定址法开放定址法就是一旦发生了冲突, 就去寻找下一个空的散列地址, 只要散列表足够大, 空的散列地址总能找到, 并将记录存入 公式:$$f_i(key)=(f(key)+d_i)\\mod m \\ (d_i=1,2,3,…,m-1)$$也就是如果有冲突, 给散列的结果加上 1 然后再取模, 如果冲突就加上 2, 以此类推 我们把这种解决冲突的开放定址法称为线性探测法 但是这个会导致本来不是同义词却需要争夺一个地址的情况, 我们称这种现象为堆积 一种改善方法为, 不仅往后寻找地址,还往前寻找, 并且加入平方运算, 为了不让关键字都聚集在某一块区域, 这种方法称为二次探测法$$f_i(key)=(f(key)+d_i) \\mod m \\ (d_i=1^2,-1^2,2^2,-2^2,…,q^2,-q^2,q\\le{m/2})$$另一种改善方法, 在冲突时, 对于位移量$d_i$采用随机函数计算得到, 我们称之为随机探测法 注意: 这里的随机数是伪随机数, 在查找时,用同样的随机种子, 每次得到的随机数列相同,最终能得到相同的散列地址 8.11.2 再散列函数法事先准备多个散列函数$$f_i(key)=RH_i(key) (i=1,2,…,k)$$$RH_i$就是不同的散列函数, 每当散列冲突时,就换一个散列函数计算 8.11.3 链地址法将所有关键字为同义词的记录存储在一个单链表中, 我们称这种表为同义词子表, 在散列表中只存储所有同义词子表的头指针, 所以如果有冲突, 也只是增加结点而已. 优点提供了绝不会出现找不到地址的保障 缺点带来了查找时需要遍历单链表的性能损耗 8.11.4 公共溢出区法为所有冲突的关键字建立一个公共的溢出区来存放. 查找时, 给定值通过散列函数计算出地址后, 与就基本表的位置比对,相等则查找成功; 不相等, 去溢出表顺序查找. 适用于冲突数据较少的情况 8.12 散列表查找实现8.12.1 散列表查找算法实现首先定义一个散列表结构 12345678910#define SUCCESS 1#define UNSUCCESS 0#define HASHSIZE 12#define NULLKEY -32768typeof struct&#123; int *elem; // 数据元素存储基址, 动态分配数组 int count; // 当前数据元素个数&#125;HashTable;int m=0; // 散列表表长, 全局变量 散列表初始化: 1234567891011// 初始化散列表Status InitHashTable(HashTable *H)&#123; int i; m=HASHSIZE; H-&gt;count=m; H-&gt;elem=(int *) malloc (m*sizeof(int)); for(i=0;i&lt;m;i++) H-&gt;elem[i]=NULLKEY; return OK;&#125; 散列函数(可随时更换算法): 12345// 散列函数int Hash(int key)&#123; return key % m; // 除留余数法&#125; 进行插入 1234567void InsertHash(HashTable *H, int key)&#123; int addr = Hash(key); // 求散列地址 while (H-&gt;elem[addr] != NULLKEY) // 出现冲突 addr = (addr+1) % m; //开放定址法线性探测 H-&gt;elem[addr] = key; // 有空位插入&#125; 散列表的查找 1234567891011121314// 散列表查找关键字Status SearchHash(HashTable H,int key, int *addr)&#123; *addr = Hash(key); // 求散列地址 while(H.elem[*addr] != key) // 不为空,冲突 &#123; *addr = (*addr + 1) %m; // 开放定址法线性探测 if(H.elem[*addr] == NULLKEY || *addr == Hash(key)) // 循环回到了原点 &#123; return UNSUCCESS; //关键字不存在 &#125; &#125; return SUCCESS;&#125; 查找与插入类似,多做一个不存在关键字的判断 8.12.2 散列表查找性能分析如果没有冲突, 是目前各种查找中效率最高的, 时间复杂度为 $O(1)$, 这只是理想状态. 散列表的平均查找长度取决于? 散列函数是否均匀 处理冲突的方法 线性探测处理冲突可能产生堆积, 显然没有二次探测法好, 链地址法不会产生人核对及, 因而拥有更佳的平均查找性能 散列表的装填因子 装填因子是记录个数/散列表长度. 标志着散列表装满的程度 我们总可以选择一个合适的装填因子以便将平均查找长度限定在一个范围之内, 让时间复杂度趋向 $O(1)$ 虽然浪费了一定空间,但是查找效率大大提升, 总体值得 8.13 总结查找表有静态查找表,动态查找表 对于顺序查找表, 注意设置哨兵的技巧 有序查找, 折半查找使得性能比顺序查找从$O(n)$变成了$O(logn)$, 其他的有序查找: 插值查找,斐波那契查找. 三者各有优缺点. 线性索引查找: 稠密索引, 分块索引, 倒排索引. 二叉排序树是动态查找最重要的数据结构. 为了达到最优, 最好是平衡的二叉树. 因此就需要了解平衡二叉树(AVL 树)的数据结构, 要了解如何处理平衡性的问题. 要掌握 B 树是针对内存外存之间的存取而专门设计的 B+树的设计思想 散列表是非常高效的查找数据结构, 注意散列函数的选择和处理冲突的方法 9. 排序9.2 排序的基本概念与分类假设含有 n 个记录的序列为${r_1,r_2,….,r_n}$, 其相应的关键字分别为${k_1,k_2,…,k_n}$, 需确定 1,2,…,n 的一种序列 $p_1,p_2,…,p_n$, 使其对应的关键字满足$k_{p1} \\le k_{p2} \\le … \\le k_{pn}$ (非递减或非递增) 关系, 即使得序列称为一个按关键字有序的序列 ${r_{p1},r_{p2},…,r_{pn}}$, 这样的操作就成为排序. 排序的依据是关键字的大小关系, 针对不同的关键字, 可以得到不同序列 关键字可以是主关键字,也可以是次关键字, 甚至是若干数据项组合. 多个关键字的排序最终都可以转化为单个关键字的排序 9.2.1 排序的稳定性假设$k_i=k_j(1\\le i \\le n, 1 \\le j \\le n, i \\ne j)$, 且在排序前的序列中 ri 领先于 rj (即 i 小于 j). 如果排序后 ri 仍领先于 rj, 则称所用的排序方法是稳定的; 反之, 若可能使得排序后的序列中 rj 领先 ri,则称所用的排序方法是不稳定的. 意思就是关键字相等的情况下, 本来的排序顺序不变即稳定 9.2.2 内排序与外排序根据是否全部放置内存中分类 内排序是在排序整个过程中, 待排序的所有记录全部被放置在内存中. 外排序是由于排序的记录个数太多, 不能同时放置在内存, 整个排序过程需要在内外存之间多次交换数据才能进行. 对于内排序, 性能受 3 个方面: 时间性能 高效率的内排序算法应该是具有尽可能少的关键字比较次数和尽可能少的记录移动次数 辅助空间 是指除了存放待排序所占用的存储空间之外,执行算法需要的其他空间 算法的复杂性 指算法本身的复杂度, 不是指算法的时间复杂度. 按照排序过程中的主要操作, 把内排序分为: 插入排序 交换排序 选择排序 归并排序 9.2.3 排序用到的结构与函数排序用的顺序表结构 123456#define MAXSIZE 10 // 用于要排序数组个数最大值typedef struct&#123; int r[MAXSIZE+1]; // 用于存储要排序数组,r[0]用作哨兵 int length; // 记录顺序表的长度&#125;SqList; 排序最常用的数组两元素的交换 1234567// 交换 L 数组中 r 的下标为 i 和 j 的值void swap(SqList *L, int i, int j)&#123; int temp = L-&gt;r[i]; L-&gt;r[i] = r[j]; L-&gt;r[j] = temp;&#125; 9.3 冒泡排序9.3.1 最简单排序实现冒泡排序(Bubble Sort) 是一种交换排序, 它的基本思想是: 两两比较相邻记录的关键字, 如果反序则交换, 知道没有反序的记录为止. 123456789101112131415// 对顺序表 L 作交换排序(冒泡排序初级版)void BubbleSort0(SqList *L)&#123; int i,j; for(i=1;i&lt;L-&gt;length;i++) &#123; for(j=i+1;j&lt;=L-&gt;length;j++) &#123; if(L-&gt;r[i]&gt;L-&gt;r[j]) &#123; swap(L,i,j); // 交换 L-&gt;r[i] 与 L-&gt;r[j] 的值 &#125; &#125; &#125;&#125; 结果就是第一位置在一次循环后一定变成最小值 第二位位置在第二次循环后变成了第二小值 缺点: 效率低 9.3.2 冒泡排序算法1234567891011121314// 对顺序表 L 作冒泡排序void BubbleSort(SqList *L)&#123; int i,j; for(i=1;i&lt;L-&gt;length;i++)&#123; for(j=L-&gt;length-1;j&gt;=i;j--) // 注意 j 是从后往前 &#123; if(L-&gt;r[j] &gt; L-&gt;r[j+1]) &#123; swap(L,j,j+1); // 交换 L-&gt;r[j] 与 L-&gt;r[j+1] 的值 &#125; &#125; &#125;&#125; 注意,这里的 L-&gt;length 是下标,下标从 1 开始. 与之前的区别: 从队尾向前两两比较 正宗的冒泡的进步是: 除了第一次循环能找到最小值,还能将次小值提到很前的位置 9.3.3 冒泡排序优化在序列已经有序的情况下,不要再继续后面的循环判断了 增加一个标记变量 flag 来改进 1234567891011121314151617// 对顺序表 L 作改进冒泡排序void BubbleSort2(SqList *L)&#123; int i,j; Status flag=TRUE; // 标记 for(i=1;i&lt;L-&gt;length &amp;&amp; flag;i++)&#123; // 若 flag 为 true 则退出循环 flag=FALSE; // 初始为 FALSE for(j=L-&gt;length-1;j&gt;=i;j--) // 注意 j 是从后往前 &#123; if(L-&gt;r[j]&gt;L-&gt;r[j+1]) &#123; swap(L,j,j+1); // 交换 L-&gt;r[j] 与 L-&gt;r[j+1] 的值 flag=TRUE; // 如果有数据交换,则 flag 为 true &#125; &#125; &#125;&#125; 在 i 的循环增加了 flag 是否为 true 的判断 避免了已经有序的情况下的无意义循环判断 9.3.4 冒泡排序复杂度分析时间复杂度为 $O(n^2)$ 9.4 简单选择排序冒泡的思想就是不停交换, 类似搞股票频繁操作. 选择排序的初步思想就是, 能不能仅仅在关键时刻出手, 也就是找到合适的关键字再做交换呢? 9.4.1 简单选择排序算法简单选择排序法(Simple Selection Sort) 就是通过 n-i 次关键字间的比较, 从 n-i+1个记录中选出关键字最小的记录, 并和第 i 个记录交换之 12345678910111213141516// 对顺序表 L 作简单选择排序void SelectSort(SqList *L)&#123; int i,j,min; for(i=1;i&lt;L-&gt;length;i++) &#123; min = i; // 将当前下标定义为最小值下标 for(j=i+1;j&lt;=L-&gt;length;j++) // 循环之后的数据 &#123; if(L-&gt;r[min] &gt; L-&gt;r[j]) // 如果有小于当前最小值的关键字 min = j; // 将此关键字的下标赋值给 min &#125; if(i!=min) // 若 min 不等于 i,则说明找到最小值,交换 swap(L,i,min); &#125;&#125; 其实吧, 就是减少交换次数,比较次数还是和冒泡差不多 9.4.2 简单选择排序复杂度分析简单选择排序最大的特点就是交换移动数据次数相当少, 也就节约了相对应的时间. 比较次数: 无论最好最差的情况,其比较次数都是一样多, 第 i 趟排序需要进行 n-i 次关键字的比较, 此时需要比较$1+2+3+…+(n-1)=\\frac{n(n-1)}{2}$ 次. 交换次数: 最好的时候,交换 0 次,最差,交换 n-1 次 总的时间复杂度依然为$O(n^2)$ 尽管和冒泡一样,但是性能还是略优于冒泡 9.5 直接插入排序9.5.1 直接插入排序算法直接插入排序(Straight Insertion Sort) 的基本操作是将一个记录插入到已经排好序的有序表中, 从而得到一个新的, 记录数增 1 的有序表. 123456789101112131415// 对顺序表 L 作直接插入排序void InsertSort(SqList *L)&#123; int i,j; for(i=2;i&lt;=L-&gt;length;i++) &#123; if(L-&gt;r[i] &lt; L-&gt;r[i-1]) // 需将 L-&gt;r[i] 插入有序子表 &#123; L-&gt;r[0]=L-&gt;r[i]; // 设置哨兵 for(j=i-1;L-&gt;r[j]&gt;L-&gt;r[0];j--) L-&gt;r[j+1]=L-&gt;r[j]; // 记录后移 L-&gt;r[j+1]=L-&gt;r[0]; // 插入到正确位置 &#125; &#125;&#125; i 从 2开始的原因就是除了 r[0] 作为哨兵, r[1]已经放好位置 这个算法写的很难懂 java 的实现: 1234567891011121314151617181920212223242526272829public class InsertSort implements IArraySort &#123; @Override public int[] sort(int[] sourceArray) throws Exception &#123; // 对 arr 进行拷贝，不改变参数内容 int[] arr = Arrays.copyOf(sourceArray, sourceArray.length); // 从下标为1的元素开始选择合适的位置插入，因为下标为0的只有一个元素，默认是有序的 for (int i = 1; i &lt; arr.length; i++) &#123; // 记录要插入的数据 int tmp = arr[i]; // 从已经排序的序列最右边的开始比较，找到比其小的数 int j = i; while (j &gt; 0 &amp;&amp; tmp &lt; arr[j - 1]) &#123; arr[j] = arr[j - 1]; j--; &#125; // 存在比其小的数，插入 if (j != i) &#123; arr[j] = tmp; &#125; &#125; return arr; &#125;&#125; 这个比刚才那个好懂很多 将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。 从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。） 123456789101112131415161718192021// 插入排序void InsertSort(int arr[], int len)&#123; // 检查数据合法性 if(arr == NULL || len &lt;= 0)&#123; return; &#125; for(int i = 1; i &lt; len; i++)&#123; int tmp = arr[i]; int j; for(j = i-1; j &gt;= 0; j--)&#123; // 在已经排序的元素序列中从后向前扫描 //如果比tmp大把值往后移动一位 if(arr[j] &gt; tmp)&#123; arr[j+1] = arr[j]; &#125; else&#123; break; &#125; &#125; arr[j+1] = tmp; &#125;&#125; 这个也比较好理解 ① 从第一个元素开始，该元素可以认为已经被排序② 取出下一个元素，在已经排序的元素序列中从后向前扫描③如果该元素（已排序）大于新元素，将该元素移到下一位置④ 重复步骤③，直到找到已排序的元素小于或者等于新元素的位置⑤将新元素插入到该位置后⑥ 重复步骤②~⑤ 9.5.2 直接插入排序复杂度分析最好的情况, 也就是要排序的表本身是有序, 这样只有比较,没有移动的记录,时间复杂度为$O(n)$ 最坏的情况, 即排序表是逆序的, 需要比较$2+3+4+…+n= \\frac{(n+2)(n-1)}{2}$ 次, 而记录的移动次数为$\\frac{(n+4)(n-1)}{2}$ 如果排序记录是随机的, 那么根据概率相同的原则, 平均比较和移动次数约为$\\frac{n^2}{4}$ 次. 因此, 直接插入排序的时间复杂度为$O(n^2)$ 同样的复杂度, 直接插入排序比冒泡和简单选择排序性能要好一些 算法优化改进方法一如果每次都是顺序查找,效率低. 思路: 每次往前查找合适的插入位置时采用二分查找(折半查找) 1234567891011121314151617181920212223242526// 插入排序改进：二分插入排序void BinaryInsertSort(int arr[], int len) &#123; int key, left, right, middle; for (int i=1; i&lt;len; i++) &#123; key = a[i]; left = 0; right = i-1; while (left&lt;=right) &#123; middle = (left+right)/2; if (a[middle]&gt;key) right = middle-1; else left = middle+1; &#125; for(int j=i-1; j&gt;=left; j--) // 找到了之后插入位置右边全部右移 &#123; a[j+1] = a[j]; &#125; a[left] = key; // 插入 &#125; &#125; 注意要想通折半查找的跳出循环方法 方法二分析: 插入排序对几乎已排好序的数据操作时，效率很高，可以达到线性排序的效率。 插入排序在每次往前插入时只能将数据移动一位，效率比较低。 改进思路： 先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。 这其实就是希尔排序 9.6 希尔排序优秀排序算法的首要条件就是速度. 冒泡排序,简单选择排序,直接插入排序的时间复杂度都是$O(n^2)$ 9.6.1 希尔排序原理希尔排序(Shell Sort), 是第一批突破$O(n^2)$的算法之一 将原本有大量记录数的记录分组, 在子序列内分别进行直接插入排序, 当整个序列基本有序时, 再对全体记录做一次直接插入排序. 所谓基本有序, 就是小的关键字基本在前面, 大的基本在后面, 不大不小的基本在中间. 但是需要采取跳跃分隔的策略: 将相距某个”增量”的记录组成一个子序列, 这样才能保证在子序列内分别进行直接插入排序后得到的结果是基本有序而不是局部有序. 9.6.2 希尔排序算法12345678910111213141516171819202122// 对顺序表 L 作希尔排序void ShellSort(SqList *L)&#123; int i,j; int increment=L-&gt;length; do &#123; increment=increment/3+1; // 增量序列 for(i=increment+1;i&lt;=L-&gt;length;i++) &#123; if(L-&gt;r[i]&lt;L-&gt;r[i-increment]) &#123; // 需将 L-&gt;r[i] 插入有序增量子表 L-&gt;r[0]=L-&gt;r[i]; // 暂存在 L-&gt;r[0] for(j=i-increment;j&gt;0&amp;&amp;L-&gt;r[0]&lt;L-&gt;r[j];j-=increment) L-&gt;r[j+increment]=L-&gt;r[j]; // 记录后移, 查找插入位置 L-&gt;r[j+increment]=L-&gt;r[0]; // 插入 &#125; &#125; &#125; while(increment&gt;1);&#125; 书上对于这个算法的解释不足, 感觉只是讲解代码. 下面这个算法比较直观 注意的点: 三层循环的条件 同时按照 gap 分组排序的理解 1234567891011121314151617181920212223242526public class ShellSort &#123; public static void main(String[] args) &#123; int[] arr = &#123;1, 4, 2, 7, 9, 8, 3, 6&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125; public static void sort(int[] arr) &#123; for (int gap = arr.length / 2; gap &gt;= 1; gap /= 2) &#123; for (int i = gap; i &lt; arr.length; i++) &#123; int j = i; while (j - gap &gt;= 0 &amp;&amp; arr[j - gap] &gt; arr[j]) &#123; swap(arr, j - gap, j); j -= gap; &#125; &#125; &#125; &#125; public static void swap(int[] arr, int a, int b) &#123; int t = arr[a]; arr[a] = arr[b]; arr[b] = t; &#125;&#125; 9.6.3 希尔排序复杂度分析究竟选什么样的增量才是最好, 目前还没有找到. 一些经过优化的增量序列如Hibbard经过复杂证明可使得最坏时间复杂度为 $O(n^{3/2})$ 但是注意, 增量序列的最后一个增量值必须等于 1 才行. 由于记录是跳跃式的移动,希尔排序并不是一种稳定的排序方法. 因为相同的元素有可能在各自的插入排序中移动 不稳定性就是指相同元素在排序过程中被移动 9.7 堆排序是对简单选择排序的一种改进 使用了”堆”这一种数据结构 堆是具有下列性质的完全二叉树: 每个结点的值都大于或等于其左右孩子结点的值, 称为大顶堆; 或者每个结点的值都小于或等于其左右孩子结点的值, 称为小顶堆. 如果按照层序遍历的方式从 1 开始编号, 则结点之间满足: $k_i \\ge k_{2i}$ 和 $k_i \\ge k_{2i+1}$, 其中$1 \\le i \\le \\lfloor {n/2} \\rfloor$ 上述是大顶堆,小顶堆同理 将大顶堆和小顶堆用层序遍历存入数组, 则一定满足上述大小的表达. 9.7.1 堆排序算法堆排序( Heap Sort ) 就是利用堆(假设利用大顶堆) 进行排序的方法. 它的基本思想是, 将待排序的序列构造成一个大顶堆. 此时, 整个序列的最大值就是堆顶的根结点. 将它移走(其实就是将其与堆数组的末尾元素交换, 此时末尾元素就是最大值), 然后将剩余的 n-1 个序列重新构造成一个堆, 这样就会得到 n 个元素中的次小值. 如此反复执行, 便能得到一个有序序列了. 基本思想就是在每次找到最大值的时候, 将剩下的元素也按照堆这种数据结构排列, 达成了每次修改剩下元素位置的目的. 两个问题: 如何由一个无序序列构建成一个堆? 如果在输出堆顶元素后, 调整剩余元素成为一个新的堆? 代码呈上: 12345678910111213// 对顺序表 L 进行堆排序void HeapSort(SqList *L)&#123; int i; for(i=L-&gt;length/2; i&gt;0; i--) // 把 L 中的 r 构建成一个大顶堆 HeapAdjust(L,i,L-&gt;length); for(i=L-&gt;length;i&gt;1;i--) &#123; swap(L,1,i); // 将堆顶记录和当前未经排序子序列的最后一个记录交换 HeapAdjust(L,1,i-1); // 将 L-&gt;r[1..i-1] 重新调整为大顶堆 &#125;&#125; 两个循环: 构建大顶堆 逐步将每个最大值的根结点与末尾元素交换,并且再调整其成为大顶堆 堆调整函数: 12345678910111213141516// 已知 L-&gt;r[s..m] 中记录的关键字除 L-&gt;r[s] 之外均满足堆的定义// 本函数调整 L-&gt;r[s] 的关键字,使 L-&gt;r[s..m] 成为一个大顶堆void HeapAdjust(SqList *L,int s,int m)&#123; int temp,j; temp=L-&gt;r[s]; for(j=2*s;j&lt;=m;j*=2)&#123; // 沿关键字较大的孩子结点向下筛选 if(j&lt;m &amp;&amp; L-&gt;r[j]&lt;L-&gt;r[j+1]) ++j; // j为关键字中较大的记录的下标 if(temp&gt;=L-&gt;r[j]) break; // rc应插入在位置 s L-&gt;r[s]=L-&gt;r[j]; s=j; &#125; L-&gt;r[s]=temp; // 插入&#125; 再简单总结下堆排序的基本思路： 将无需序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆; 将堆顶元素与末尾元素交换，将最大元素”沉”到数组末端; 重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序 这段还是不能看书上, 直接扔代码我是真的很反感. 自己网上找了一个视频看懂了: https://www.bilibili.com/video/BV1Eb41147dK?from=search&amp;seid=7059417364240703657 下面放上 java 代码 注意点: 完全二叉树的特点 heapify 函数的递归调用 build_heap 函数 heap_sort 函数的循环中, i 的变化 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class HeapSort &#123; public static void main(String[] args) &#123; int[] arr = &#123;50, 10, 90, 30, 70, 40, 80, 60, 20&#125;; int n = 6; heap_sort(arr, 9); System.out.println(Arrays.toString(arr)); &#125; private static void heap_sort(int[] arr, int n) &#123; build_heap(arr, n); for (int i = n - 1; i &gt;= 0; i--) &#123; swap(arr, 0, i); heapify(arr, 0, i); &#125; &#125; private static void build_heap(int[] arr, int n) &#123; int last_node = n - 1; int last_parent = (last_node - 1) / 2; for (int i = last_parent; i &gt;= 0; i--) &#123; heapify(arr, i, n); &#125; &#125; private static void heapify(int[] arr, int i, int n) &#123; if (i &gt;= n) &#123; return; &#125; int left = 2 * i + 1; int right = 2 * i + 2; int max = i; if (left &lt; n &amp;&amp; arr[left] &gt; arr[max]) &#123; max = left; &#125; if (right &lt; n &amp;&amp; arr[right] &gt; arr[max]) &#123; max = right; &#125; if (max != i) &#123; swap(arr, max, i); heapify(arr, max, n); &#125; &#125; private static void swap(int[] arr, int a, int b) &#123; int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp; &#125;&#125; 9.7.2 堆排序复杂度分析 堆排序主要消耗在初始构建堆和重建堆时的反复筛选上. 构建堆来说, 每次和孩子进行比较, 其实最多两次比较和互换, 因此构建堆的时间复杂度为$O(n)$ 正式排序时, 第 i 次取堆顶记录重建堆需要用$O(logi)$的时间 (由完全二叉树某个结点到根结点的距离得出), 并且需要取 n-1 次堆顶记录, 因此, 重建堆的时间复杂度为$O(nlogn)$ 总体的时间复杂度为$O(nlogn)$ 空间复杂度上,只有一个用来交换的暂存单元. 由于记录的比较和交换是跳跃式进行,因此堆排序也是一种不稳定的排序方法 9.8 归并排序因为堆排序用到了完全二叉树, 利用了完全二叉树的深度的特性,所以效率比较高. 有没有更直接的办法利用完全二叉树来排序呢? 将无序的数组,两两合并排序后再合并,最终获得了一个有序的数组 9.8.1 归并排序算法归并排序(Merging Sort)的原理: 假设初始序列含有 n 个记录, 则可以看成是 n 个有序的子序列, 每个子序列的长度为 1, 然后两两归并, 得到$\\lceil n/2 \\rceil$ 个长度为 2 或 1 的有序子序列; 再两两归并,…, 如此重复, 直至得到一个长度为 n 的有序序列为止, 这种排序方法成为 2 路归并排序. 从这里开始书上又开始甩代码了. 懒得看. 还是去找视频看: https://www.bilibili.com/video/BV1Ax411U7Xx/?spm_id_from=333.788.recommend_more_video.0 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class MergeSort &#123; public static void main(String[] args) &#123; int[] arr = &#123;6, 8, 10, 9, 4, 5, 2, 7&#125;; mergeSort(arr, 0, arr.length-1); System.out.println(Arrays.toString(arr)); &#125; private static void merge(int[] arr, int L, int M, int R) &#123; int left_size = M - L; int right_size = R - M + 1; int[] left = new int[left_size]; int[] right = new int[right_size]; for (int i = L; i &lt; M; i++) &#123; left[i - L] = arr[i]; &#125; for (int i = M; i &lt;= R; i++) &#123; right[i - M] = arr[i]; &#125; int i = 0; int j = 0; int k = L; while (i &lt; left_size &amp;&amp; j &lt; right_size) &#123; if (left[i] &lt;= right[j]) &#123; arr[k] = left[i]; i++; k++; &#125; else &#123; arr[k] = right[j]; j++; k++; &#125; &#125; while (i &lt; left_size) &#123; arr[k] = left[i]; i++; k++; &#125; while (j &lt; right_size) &#123; arr[k] = right[j]; j++; k++; &#125; &#125; private static void mergeSort(int[] arr, int L, int R) &#123; if (L == R) &#123; return; &#125;else&#123; int M = (L + R) / 2; mergeSort(arr, L, M); mergeSort(arr, M + 1, R); merge(arr, L, M+1, R); &#125; &#125;&#125; 注意: 边界!!! 分治法 9.8.2 归并排序复杂度分析因为还是类似完全二叉树, 所以总的时间复杂度为$O(nlogn)$ 因为需要同样数量的存储空间, 空间复杂度我$O(n+logn)$ 因为两个相等的话,不会进行跳跃, 所以归并排序是一种稳定的排序算法 也就是说, 归并排序是一种比较占用内存,但却效率高且稳定的算法. 9.8.3 非递归实现归并排序算法过程略, 但是非递归实现避免了递归时深度为$log_2n$的栈空间, 空间只是用到申请归并临时用的 TR 数组, 空间复杂度为$O(n)$ 使用归并排序时,尽量考虑用非递归方法. 归并排序的优化: https://www.cnblogs.com/noKing/p/7940531.html 9.9 快速排序希尔排序是插入排序的升级 堆排序是简单选择排序的升级 快速排序是冒泡排序的升级 9.9.1 快速排序算法快速排序 (Quick Sort) 的基本思想是: 通过一趟排序将待排记录分割成独立的两部分, 其中一部分记录的关键字均比另一部分记录的关键字小, 则可分别对这两部分记录进行排序, 以达到整个序列有序的目的. 12345678910111213141516171819202122232425262728293031323334public class QuickSort &#123; public static void main(String[] args) &#123; int[] arr = &#123;3, 5, 7, 3, 8, 9, 6, 1, 0&#125;; QuickSort(arr, 0, arr.length - 1); System.out.println(Arrays.toString(arr)); &#125; private static void QuickSort(int arr[], int L, int R) &#123; if(L&lt;R)&#123; int left = L, right = R; int pivot = arr[left]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; arr[right] &gt; pivot) &#123; right--; &#125; if (left &lt; right) &#123; arr[left] = arr[right]; left++; &#125; while (left &lt; right &amp;&amp; arr[left] &lt; pivot) &#123; left++; &#125; if (left &lt; right) &#123; arr[right] = arr[left]; right--; &#125; &#125; arr[left] = pivot; QuickSort(arr, L, left - 1); QuickSort(arr, left + 1, R); &#125; &#125;&#125; 快速排序函数,其实就是将选取的 pivot 值不断交换, 它也在交换中不断更改自己的位置, 直到完全满足这个要求为止. 9.9.2 快速排序复杂度分析快速排序的时间性能取决于快速排序递归的深度, 可以用递归树来描述递归算法的执行情况. 时间复杂度推断过程很复杂, 略. 通过数学归纳法可证明, 数量级为$O(nlogn)$ 空间复杂度, 主要是递归造成的栈空间的使用. 与递归树的深度有关. 空间复杂度为$O(logn)$ 由于关键字比较和交换是跳跃进行,因此, 快速排序不稳定 9.9.3 快速排序优化 优化选取枢轴 优化不必要的交换 优化小数组时的排序方案 优化递归操作 了不起的排序算法 到现在为止, 快速排序算法经过多次优化后, 整体性能上, 是排序算法王者. 9.10 总结回顾 排序的稳定性 内排序与外排序 分类 插入排序 直接插入排序 希尔排序 交换排序 冒泡排序 快速排序 选择排序 简单选择排序 堆排序 归并排序 归并排序 没有十全十美的排序算法. 即使是快速排序, 也存在排序不稳定,需要大量辅助空间,对少量数据排序无优势等不足 分类 简单算法 冒泡 简单选择 直接插入 改进算法 希尔 堆 归并 快速 从时间复杂度来看: 从最好情况看, 后 3 种改进算法 &gt; 希尔排序 &gt;&gt; 前三种 从最坏情况看, 堆排序,归并排序&gt;快速排序&gt;其他简单排序 堆排序, 归并排序: 优等生, 发挥稳定 快速排序: 天才, 发挥看心情 从空间复杂度来看: 归并排序强调马要跑得快,得先吃饱 快速排序也有空间需求 堆排序等都是少量索取,大量付出, 对空间要求是$O(1)$ 如果环境非常在乎内存使用量, 选择归并和快速排序就不合适. 从稳定性来看: 归并排序独占鳌头 从待排序记录的个数来看: 待排序的个数 n 越小, 采用简单排序方法越合适. n 越大,采用改进排序的方法越合适 综合来说: 经过优化的快速排序是性能最好的排序算法. 9.11 结尾语数据结构和算法对于程序员的职业人生来说,就是应该学习的知识和能够赚钱的知识的交集, 用心去掌握它, 编程之路将会是坦途. You got a dream, you gotta protect it. People can’t do something themselves, they wanna tell you you can’t do it. If you want something, go get it. Period.","categories":[{"name":"笔记","slug":"笔记","permalink":"http://yiiiqing.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yiiiqing.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"过滤配置文件中#开头的注释","slug":"过滤配置文件中-开头的注释","date":"2021-06-20T09:41:55.000Z","updated":"2021-06-22T09:43:02.000Z","comments":true,"path":"2021/06/20/过滤配置文件中-开头的注释/","link":"","permalink":"http://yiiiqing.github.io/2021/06/20/%E8%BF%87%E6%BB%A4%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD-%E5%BC%80%E5%A4%B4%E7%9A%84%E6%B3%A8%E9%87%8A/","excerpt":"","text":"过滤配置文件中#开头的注释一般平时看很多配置文件，都是在注释中找配置 通过命令 1grep &quot;^[^#]&quot; xxx.properties #不加#号也是可以的 可以过滤掉那些以#开头的文本 非常实用","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"}]},{"title":"MySQL学习手册-高级","slug":"Mysql学习手册-高级","date":"2021-06-01T09:34:11.000Z","updated":"2021-09-10T06:41:34.000Z","comments":true,"path":"2021/06/01/Mysql学习手册-高级/","link":"","permalink":"http://yiiiqing.github.io/2021/06/01/Mysql%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C-%E9%AB%98%E7%BA%A7/","excerpt":"","text":"MySQL 架构配置文件二进制日志log-bin主从复制 错误日志log-error默认是关闭的,记录严重的警告和错误信息,每次启动和关闭的详细信息 默认关闭的原因是为了高效 查询日志 log 默认关闭 记录查询的语句 开启会降低 mysql 的整体性能,因为记录日志也是需要消耗系统资源的 数据文件linux 中,使用ls -1F|grep ^d查看当前系统中所有库,貌似不适用于 docker 安装的 mysql 默认路径: var/lib/mysql frm 文件: 存放表结构 myd 文件: 存放表数据 myi 文件: 存放表索引 逻辑架构 连接层 服务层 引擎层 和其他数据库相比,它的架构可以在不同场景中应用并发挥良好作用.主要体现在存储引擎的架构上. 插件式存储引擎架构将查询处理和其他的系统人物以及数据的存储提取相分离. 这种架构可以根据业务的需求和实际需要选择合适的存储引擎 连接层最上层是一些客户端和连接服务,包含本地 sock 通信和大多数基于 c/s 工具实现的类似于 tcp/ip 的通信. 主要完成一些类似于连接处理,授权认证及相关的安全方案. 在该层上引入了线程池的概念,为通过认证安全接入的客户端提供线程. 同样在该层上可以实现基于 SSL 的安全连接. 服务器也会为安全接入的每个客户端验证它所具有的操作权限. 服务层第二层架构主要完成大多核心服务功能,如 sql 接口,并完成缓存的查询, SQL 的分析和优化及部分内置函数的执行.所有跨存储引擎的功能,如过程,函数等. 在该层,服务器会解析查询并创建相应的内部解析树,并对其完成响应的优化如确定查询表的顺序,是否利用索引等,最后生成响应的执行操作. 如果是 select 操作,服务器还会查询内部的缓存. 如果缓存空间足够大,这样在解决大量读操作的环境中能够更好的提升系统的性能 引擎层存储引擎层,存储引擎真正的负责了 MySQL 中数据的存储和提取,服务器通过 API 与存储引擎. 不同的存储引擎具有的功能不同,根据实际需要选取,如 MyISAM 和 InnoDB 存储层主要是数据存储在运行于裸设备的文件系统之上,完成与存储引擎的交互 存储引擎查看存储引擎: show engines; 对比 MyISAM 和 InnoDB: 对比项 MyISAM InnoDB 主外键 不支持 支持 事务 不支持 支持 行表锁 表锁,即使操作一条记录也会锁住整个表,不适合高并发操作 行锁,操作时只锁一行,不会其他行有影响,适合高并发操作 缓存 只缓存索引,不缓存数据 不仅缓存索引还要缓存真实数据,对内存要求较高,而且内存大小对性能有决定性的影响 表空间 小 大 关注点 性能 事务 默认安装 Y Y 索引优化分析sql 性能下降原因分析性能下降 sql 慢,执行时间长,等待时间长 可能的原因: 语句写的烂 索引失效 单值 创建: create index idx_user_name on user(userName) 复合 创建: create index idx_user_name_email on user(name,email) 关联查询太多 join 设计缺陷或不得已的需求 服务器调优及各个参数设置 缓冲,线程数等 sql 执行顺序 FROM ON JOIN WHERE GROUP BY HAVING SELECT DISTINCT ORDER BY LIMIT 七种 JOIN见基础篇 主要记住两表相连一表独有要怎么做 select * from tbl_emp a left join tbl_dept b on a.deptId=b.id where b.id is null; 123456789全连接 mysql 不支持的情况下怎么实现?* 使用 union* ```mysql select * from tbl_emp a left join tbl_dept b on a.deptId=b.id union select * from tbl_emp a right join tbl_dept b on a.deptId = b.id; 两表各自的独有怎么实现? select * from tbl_emp a left join tbl_dept b on a.deptId=b.Id where b.id is null union select * from tbl_emp a right join tbl_dept b on a.deptId = b.id where a.deptId is null; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889## 索引### 简介#### 是什么**索引 (Index) 是帮助 MySQL 高效获取数据的数据结构.** 目的: 提高查找效率所以,索引是一种&quot;**排好序的快速查找数据结构**&quot;索引会影响 where 的查找和 order by 的排序我们平时说的索引,如果没有特别指明, 都是指 B 树(多路搜索树,不一定是二叉树) 结构组织的索引#### 优势劣势* 优势 * 类似大学图书馆建书目索引, 提高数据检索的效率, 降低数据库的 IO 成本 * 通过所以对数据进行排序, 降低数据排序的成本, 降低了 CPU 的消耗* 劣势 * 索引也是一张表, 该表保存了主键与索引字段, 并指向实体表的记录, 所以索引列也是要占用空间的 * 虽然索引大大提高了查询速度, 同时会降低更新表的速度, 如对表进行 INSERT, UPDATE 和 DELETE. 因为更新表时, MySQL 不仅要保存数据, 还要保存一下索引文件每次更新添加了索引列的字段, 都会调整因为更新所带来的键值变化后的索引信息 * 索引只是提高效率的一个因素, 如果 MySQL 有大数据量的表, 就需要花时间研究建立最优秀的索引#### 分类* 单值索引 * 即一个索引只包含单个列, 一个表可以由多个单列索引 * 最多不要超过 5 个. * MySQL 5.1 之前,一条查询语句只会用到一个索引 * MySQL 5.1 之后, 支持索引合并. 索引合并是利用表上的多个单列索引来定位指定行，其原理是将对每个索引的扫描结果做运算，总共有：交集、并集以及他们的组合，但是索引合并并非是一种合适的选择，因为在做索引合并时可能会消耗大量的CPU和内存资源，一般用到索引合并的情况也从侧面反映了该表的索引需要优化，可以尝试建立联合索引* 唯一索引 * 索引列的值必须唯一, 但必须有空值* 复合索引 * 即一个索引包含多个列#### 结构* BTree 索引* Hash 索引* full-text 全文索引* R-Tree 索引#### BTree重点,详见数据结构笔记一些平衡树只在叶子节点中存储值，而且叶子节点和内部节点使用不同的结构。B树在每一个节点中都存储值，所有的节点有着相同的结构。然而，因为叶子节点没有子节点，所以可以通过使用专门的结构来提高B树的性能。&gt; B+树也是重中之重#### 需要创建索引的情况1. 主键自动建立唯一索引2. 频繁作为查询条件的字段应该创建索引3. 查询与其他表关联的字段, 外键关系建立索引4. 频繁更新的字段不适合创建索引. 因为每次更新不单单是更新了记录还会更新索引5. where 条件里用不到的字段不创建索引6. 单键/组合索引的选择问题: 高并发下倾向于创建组合索引7. 查询中排序的字段, 排序字段若通过索引去访问将大大提高排序速度8. 查询中统计或者分组字段#### 不需要创建索引的情况1. 表记录太少 (300 万以上MySQL性能下降)2. 经常增删改的表. 因为提高查询速度但是却降低了更新表的速度(更新表要更新索引)3. 数据重复且分布平均的表字段. 没有意义### 性能分析#### MySQL Query OptimizerMySQL 中有专门负责优化 select 语句的优化器模块* 通过计算分析系统中收集到的统计信息,为客户端请求的 query 提供它认为最优的执行计划(它认为最优的不一定是 DBA 认为最优的, 这部分最耗费时间)#### MySQL 常见瓶颈* CPU: CPU 在饱和的时候一般发生在数据装入内存或从磁盘上读取数据的时候* IO: 磁盘 I/O 瓶颈发生在装入数据远大于内存容量的时候* 服务器硬件的性能瓶颈: top,free,iostat 和 vmstat 来查看系统的性能状态#### EXPLAIN 关键字使用 explain 关键字可以模拟优化器执行 SQL 查询语句,从而知道 MySQL 是如何处理 SQL 语句的. 分析你的查询语句或是表结构的性能瓶颈```mysqlexplain select * from tbl_emp; 可以解析: 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 各字段解释 id: select 查询的序列号,包含一组数字, 表示查询中执行 select 子句或操作的顺序 id 相同, 执行顺序由上至下 如果是子查询, id 的序列递增, id 值越大优先级越高, 越先被执行 id 如果相同,可以认为是一组,从上往下顺序执行; 在所有组中, id 值越大,优先级越高,越先执行 衍生 = derived select_type: 查询的类型, 主要用于区别普通查询,联合查询,子查询等的复杂查询 分类 SIMPLE: 简单的 select. 不包含子查询或 union PRIMARY: 查询中若包含复杂的子部分, 最外层查询被标记 SUBQUERY: 子查询 DERIVED: 在 from 列表中包含的子查询被标记为 derived(衍生). MySQL 会递归执行这些子查询, 把结果放在临时表中 UNION: 若第二个 select 出现在 union 之后,则被标记为 union; 若 union 包含在 from 子句的子查询中, 外层 select 将被标记为 derived UNION RESULT: 从 union 表中获取的 result table: 属于哪张表 type: 访问类型 分类: ALL/index/range/ref/eq_ref/const,system/NULL system: 表只有一行记录, const 类型的特例,平时不会出现 const: 表示通过索引一次就找到了, const 用于比较 primary key 或者 unique 索引. 因为只匹配一行数据所以很快 eq_ref: 唯一性索引扫描, 对于每个索引键, 表中只有一条记录与之匹配. 常见于主键或唯一索引扫描 ref: 非唯一性索引扫描, 返回匹配某个单独值的所有行. 可能会找到多个符合条件的行 range: 只检索给定范围的行, 使用一个索引来选择行. key 列显示使用了哪个索引 一般是在 where 中出现了 between, &lt;, &gt;, in等的查询 范围索引扫描比全表扫描要好, 因为不需要扫描全部索引 index: full index scan. index 与 all 区别为 index 类型只遍历索引树. all: full table scan. 遍历全表找到匹配的行 从好到差依次是: system&gt;const&gt;eq_ref&gt;ref&gt;range&gt;index&gt;ALL 一般来说, 得保证查询至少达到 range 级别, 最好能达到 ref possible_keys: 显示可能应用在这张表中的索引, 一个或多个. key: 实际使用的索引. 如果为 NULL, 则没有使用索引. 查询中若使用了覆盖索引, 则该索引仅出现在key 列表中 key_len: 表示索引中使用的字节数, 可通过该列计算查询中使用的索引的长度. 在不损失精确性的情况下, 长度越短越好 key_len 显示的值为索引字段的最大可能长度, 并非实际使用长度, 即 key_len 是根据表定义计算可得, 不是通过表内检索出的 ref: 显示索引的哪一列被使用了, 如果可能的话, 是一个常数. 哪些列或常量被用于查找索引列上的值. rows: 根据表统计信息及索引选用情况,大致估算出找到所需的记录所需要读取的行数 extra: 包含不适合在其他列显示但十分重要的额外信息 Using filesort Using temporary Using index … 覆盖索引( Covering Index) 理解方式一: select 的数据列只用从索引中就能够取得, 不必读取数据行, MySQL 可以利用索引返回 select 列表中的字段,而不必根据索引再次读取数据文件, 换句话说查询列要被所创建的索引覆盖. 理解方式二: 索引是找到行的一个方法, 但是一般数据库也能使用索引找到一个列的数据, 因此它不必读取整个行. 毕竟索引叶子结点存储了它们索引的数据; 当能通过读取索引就可以得到想要的数据, 那就不需要读取行了. 一个索引包含了(或覆盖了)满足查询结果的数据就叫做覆盖索引 注意: 如果要使用覆盖索引, 一定要注意 select 列表中值选出需要的列, 不可 select *, 因为如果将所有字段一起做索引会导致索引文件过大, 查询性能下降. 索引优化单表优化1select id,author_id from article where category_id = 1 and comments &gt; 1 order by views desc limit 1; 这种情况下建立: 1create index idx_article_ccv on article(category_id,comments,views); 这样其实是不好的. 因为 comments&gt;1 这个条件会使索引失效 应该仅仅在 category_id 和 views 上建立索引 1create index idx_article_cv on article(category_id,views); 两表优化 左连接的特性,就是左边表全部都会有. 所以根据左连接的特性, LEFT JOIN 条件用于确定如何从右表搜索行, 左边一定都有. 所以右边是我们的关键点, 一定要建立索引. 同理, 右连接RIGHT JOIN 的条件用于确定如何从左表搜索行, 右边一定都有. 所以左边是关键点, 一定要建立索引. 三表优化1select * from class left join book on class.card=book.card left join phone on book.card = phone.card; 类似上述的两表优化, 将右边的两个表都加上索引 12alter table `phone` add index z(card);alter table `book` add index y(card); 结果可以发现后两行的 type 都是 ref 并且总 rows 优化很好,效果也不错. 因此索引最好设置在需要经常查询的字段中 结论join 语句的优化: 尽可能减少 Join 语句中的 NestedLoop 的循环总次数: “永远用小结果集驱动大的结果集”. 优先优化 NestedLoop 的内层循环 保证 Join 语句中 被驱动表上 Join 条件字段 已经被索引 当无法保证被驱动表的 Join 字段被索引且内存资源充足的情况下, 不要太吝啬 JoinBuffer 的设置. 索引失效(应该避免)案例1234567891011121314create table staffs( id int primary key auto_increment, NAME varchar(24) not null default &quot;&quot; comment &#x27;xingming&#x27;, age int not null default 0 comment &#x27;nianling&#x27;, pos varchar(20) not null default &quot;&quot; comment &#x27;zhiwei&#x27;, add_time timestamp not null default current_timestamp comment &#x27;ruzhishijian&#x27; )charset utf8 comment &#x27;yuangongjilubiao&#x27;;insert into staffs(NAME,age,pos,add_time) values(&#x27;z3&#x27;,22,&#x27;manager&#x27;,NOW()),(&#x27;July&#x27;,23,&#x27;dev&#x27;,NOW()),(&#x27;2000&#x27;,23,&#x27;dev&#x27;,NOW());alter table staffs add index idx_staffs_nameAgePos(name,age,pos); 规则 (5.x 版本, 8.x 可能很多不符合) 全值匹配我最爱 最佳左前缀法则 如果索引了多列, 要遵循最左前缀法则. 指的是查询从索引的最左前列开始并且不跳过索引中的列. 不在索引列上做任何操作(计算、函数、(自动or手动)类型转换)，会导致索引失效而转向全表扫描 存储引擎不能使用索引中范围条件右边的列口 尽量使用覆盖索引(只访问索引的查询(索引列和查询列–致))，减少select * 这样 extra 中能出现 using index, 性能好 mysql在使用不等于(!=或者&lt;&gt;)的时候无法使用索引会导致全表扫描 is null ,is not null也无法使用索引 like以通配符开头(‘%abc..’)mysql索引失效会变成全表扫描的操作 字符串不加单引号索引失效(重罪) MySQL 底层会有隐形的类型转换, 见 3 少用or,用它来连接时会索引失效 小总结假设 index(a,b,c) where语句 索引是否被使用 where a = 3 Y, 使用到 a where a = 3 and b = 5 Y, 使用到a,b where a = 3 and b = 5 and c = 4 Y, 使用到 a,b,c where b = 3 或者 where b = 3 and c = 4 或者 where c = 4 N where a = 3 and c = 5 Y, 使用到a, 因为 b 中间断了 where a = 3 and b &gt; 4 and c = 5 Y, 使用到 a 和 b, c 不能用在范围之后,b 断了 where a = 3 and b like ‘kk%’ and c = 4 Y, a 能用,b 能用,c 不能用 where a = 3 and b like ‘%kk’ and c = 4 Y, 只用到 a where a = 3 and b like ‘%kk%’ and c = 4 Y, 只用到 a where a = 3 and b like ‘k%kk%’ and c = 4 Y, 使用到a,b,c 一般性建议 对于单键索引, 尽量选择针对挡圈 query 过滤性更好的索引 在选择组合索引的时候, 当前 query 中过滤性最好的字段在索引字段顺序中, 位置越靠前越好 在选择组合索引的时候, 尽量选择可以能够包含当前 query 中的 where 字句中更多字段的索引 尽可能通过分析统计信息和调整 query 的写法来达到选择合适索引的目的 优化总结口诀全值匹配我最爱, 最左前缀要遵守; 带头大哥不能死, 中间兄弟不能断; 索引列上少计算, 范围之后全失效; LIKE 百分写最右, 覆盖索引不写星; 不等空值还有 or, 索引失效要少用; VAR 引号不可丢, SQL 高级也不难! 查询截取分析查询优化永远小表驱动大表优化规则: 即小的数据集驱动大的数据集 原理: 1234select * from A where id in (select id from B)等价于for select id from Bfor select * from A where A.id = B.id 当 B 表的数据集必须小于 A 表的数据集时, 用 in 优于 exists 1234select * from A where exists (select 1 from B where B.id = A.id)等价于for select * from Afor select * from B where B.id = A.id 当 A 表的数据集小于 B 表的数据时,用 exist 优于 in 注意: A 和 B 的 id 字段应该建立索引 EXISTS select ... from table where exists (subquery) 该语法可以理解为: 将主查询的数据,放到子查询中做条件验证, 根据验证结果(TRUE/FALSE) 来决定主查询的数据结果是否得以保留 提示 EXISTS(subquery) 只返回 TRUE 或 FALSE, 因此子查询中的 select * 也可以是 SELECT 1 或其他, 官方说法是实际执行时会忽略 select 清单, 因此没有区别 EXISTS 子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比, 如果但有效率问题,可进行实际检验以确定是否有效率问题 EXISTS 子查询往往也可以用条件表达式, 其他子查询或者 JOIN 来替代, 何种最优需要具体问题具体分析 order by 关键字优化 order by 子句, 尽量使用 Index 方式排序, 避免使用 FileSort 方式排序 尽可能在索引列上完成排序操作, 遵照索引建的最佳左前缀 如果不在索引列上, filesort 有两种算法: mysql 就要启用双路排序和单路排序 双路排序 MySQL 4.1 之前是使用双路排序, 字面意思就是两次扫描磁盘, 最终得到数据, 读取行指针和 orderby 列, 对他们进行排序, 然后扫描已经排序好的列表, 按照列表中的值重新从列表中读取对应数据输出 从磁盘取排序字段, 在 buffer 进行排序, 再取其他字段 I/O 非常耗时 单路排序 从磁盘读取查询需要的所有列, 按照 orderby 列在 buffer 对它们进行排序, 然后扫描排序后的列表进行输出, 它的效率更快一些, 避免了第二次读取数据. 把随机 IO 变成了顺序 IO, 但是它会使用更多的空间, 因为它把每一行都保存在内存中了 注意 在 sort_buffer 中,单路排序比双路排序要占用很多空间, 有可能取出的数据总大小超出了 sort_buffer 的容量, 导致每次只能取 sort_buffer 容量大小的数据, 进行排序(创建 tmp 文件, 多路合并), 排完再取 sort_buffer 大小, 再排序… 从而多次 IO 本来想省一次 IO 操作, 从而导致了大量的 IO 操作, 反而得不偿失. 优化策略 不要用 select * 当 query 的字段的大小总和小于 max_length_for_sort_data 而且排序字段不是 text|blob 类型时, 会采用改进后的单路排序, 否则使用老算法双路排序 增大 sort_buffer_size 的设置 不管哪种算法, 提高这个参数都会提高效率, 根据系统能力提高, 这个参数针对进程 增大 max_length_for_sort_data 参数的设置 提高这个参数, 会增加用改进算法的概率 select * order by 无论后面怎么写, 都会是 filesort. 只要是 select 中包含了不在索引的列都会如此 总结为排序使用索引 MySQL两种排序方式: filesort 和 index MySQL能为排序与查询使用相同的索引 KEY a_b_c(a,b,c) order by 能使用索引最左前缀 order by a order by a,b order by a,b,c order by a desc, b desc, c desc 如果 where 使用索引的最左前缀定义为常量, 则 order by 能使用索引 where a = const order by b,c where a = const and b = const order by c where a = const order by b,c where a = const and b &gt; const order by b,c (本来 b 断了,但是后面连上了) 不能使用索引进行排序 order by a asc, b desc, c desc // 排序不一致 where g = const order by b,c // 丢失 a where a = const order by c // 丢失 b where a = const order by a,d // d不是索引 where a in (…) order by b,c // 对于排序来说,多个相等条件也是范围查询 group by 关键字优化 group by 实质是先排序后进行分组, 遵照索引建的最佳左前缀 当无法使用索引列, 增大 max_length_for_sort_data 参数的设置+增大 sort_buffer_size 参数的设置 where 高于 having, 能写在 where 限定的条件就不要去 having 限定了 慢查询日志 MySQL 的慢查询日志是 MySQL 提供的一种日志记录, 它用来记录在 MySQL 中响应时间超过阈值的语句, 具体指运行时间超过 long_query_time 值的 SQL, 则会被记录到慢查询日志中 默认情况下, MySQL 数据库没有开启慢查询日志, 需要手动设置 如果不是调优需要的话, 一般不建议启动该参数, 因为会有一定的性能影响 支持将日志写入文件 开启12show variables like &#x27;%low_query_log%&#x27;;set global slow_query_log=1;#开启,但是只对当前数据库生效, 如果 MySQL 重启后将会失效 如果要永久生效, 必须修改配置文件 my.cnf 在[mysqld]下增加参数 12slow_query_log=1slow_query_log_file=/var/lib/mysql/yiqing.log 查看多久算慢 1show variables like &#x27;long_query_time%&#x27;; 设置慢的阈值时间 1set global long_query_time=3; 设置后是看不出变化的, 需要重新连接或新开一个会话才能看到修改值 12show variables like &#x27;long_query_time%&#x27;;show global variables like &#x27;long_query_time&#x27;; 使用mysqldumpslow 查询12mysqldumpslow -s r -t 10 /var/lib/mysql/yiqing-slow.log... 批量数据脚本往表里插入 1000W 条数据 建表 123456789101112131415161718192021222324# 新建库create database bigData;use bigData;#1 deptcreate table dept( id int unsigned primary key auto_increment, deptno mediumint unsigned not null default 0, dname varchar(20) not null default &quot;&quot;, loc varchar(13) not null default &quot;&quot;)engine=innodb default charset=GBK;#2 empcreate table emp( id int unsigned primary key auto_increment, empno mediumint unsigned not null default 0, ename varchar(20) not null default &quot;&quot;, job varchar(9) not null default &quot;&quot;, mgr mediumint unsigned not null default 0, hiredate date not null, sal decimal(7,2) not null, comm decimal(7,2) not null, deptno mediumint unsigned not null default 0)engine=innodb default charset=GBK; 设置参数 log_bin_trust_function_creators 创建函数,保证每条数据都不同 随机产生字符串 123456789101112DELIMITER $$CREATE FUNCTION rand_string(n INT) RETURNS VARCHAR(255)BEGIN DECLARE chars_str VARCHAR(100) DEFAULT &#x27;abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ&#x27;; DECLARE return_str VARCHAR(255) DEFAULT &#x27;&#x27;; DECLARE i INT DEFAULT 0; WHILE i &lt; n DO SET return_str = CONCAT(return_str,SUBSTRING(chars_str,FLOOR(1+RAND()*52),1)); SET i = i + 1; END WHILE; RETURN return_str;END $$ 随机产生部门编号 12345678DELIMITER $$CREATE FUNCTION rand_num()RETURNS INT(5)BEGIN DECLARE i INT DEFAULT 0; SET i = FLOOR(100+RAND()*10);RETURN i;END $$ 创建存储过程 创建往 emp 表中插入数据的存储过程 12345678910111213DELIMITER $$CREATE PROCEDURE insert_emp(IN START INT(10),IN max_num INT(10))BEGINDECLARE i INT DEFAULT 0;#set autocommit =0 fE autocommiti Ï FXOSET autocommit = 0;REPEATSET i = i + 1;INSERT INTO emp(empno, ename, job, mgr, hiredate, sal, comm, deptno) VALUES ((START+i),rand_string(6),&#x27;SALESMAN&#x27; ,0001 ,CURDATE(),2000,400,rand_num());UNTIL i = max_num END REPEAT;COMMIT;END $$ 创建往 dept 表中插入数据的存储过程 123456789101112DELIMITER $$CREATE PROCEDURE insert_dept(IN START INT(10), IN max_num INT(10))BEGINDECLARE i INT DEFAULT 0;SET autocommit = 0;REPEATSET i=i+1;INSERT INTO dept(deptno ,dname, loc ) VALUES((START+i) ,rand_string(10),rand_string(8));UNTIL i = max_numEND REPEAT;COMMIT ;END $$ 调用存储过程 123456# dept 10 条DELIMITER ;CALL insert_dept(100,10);# emp 添加 50w 条DELIMITER ;CALL insert_emp(100001,500000); Show Profile简介是 MySQL 提供可以用来分析当前会话中语句执行的资源消耗情况. 可以用于 SQL 的调优的测量 默认情况下, 参数处于关闭状态, 并保存最近 15 次的运行结果 分析步骤 查看当前的 MySQL 版本是否支持 1show variables like &#x27;profiling&#x27;; 开启 1set profiling=on; 运行 SQL 1select * from tbl_emp group by id%10 limit 150000; 查看结果 1234567show profiles;+----------+------------+-----------------------------------------------+| Query_ID | Duration | Query |+----------+------------+-----------------------------------------------+| 1 | 0.00404850 | show variables like &#x27;profiling&#x27; || 2 | 0.54576350 | select * from emp group by id%10 limit 150000 |+----------+------------+-----------------------------------------------+ 诊断 SQL 123456789101112131415161718192021222324252627show profile cpu, block io for query [Query_ID];mysql&gt; show profile cpu, block io for query 2;+----------------------+----------+----------+------------+--------------+---------------+| Status | Duration | CPU_user | CPU_system | Block_ops_in | Block_ops_out |+----------------------+----------+----------+------------+--------------+---------------+| starting | 0.000208 | 0.000209 | 0.000000 | 0 | 0 || checking permissions | 0.000051 | 0.000060 | 0.000000 | 0 | 0 || Opening tables | 0.000060 | 0.000050 | 0.000000 | 0 | 0 || init | 0.000047 | 0.000047 | 0.000000 | 0 | 0 || System lock | 0.000035 | 0.000033 | 0.000000 | 0 | 0 || optimizing | 0.000018 | 0.000019 | 0.000000 | 0 | 0 || statistics | 0.000035 | 0.000035 | 0.000000 | 0 | 0 || preparing | 0.000055 | 0.000093 | 0.000000 | 0 | 0 || Creating tmp table | 0.000119 | 0.000062 | 0.000000 | 0 | 0 || Sorting result | 0.000031 | 0.000030 | 0.000000 | 0 | 0 || executing | 0.000010 | 0.000009 | 0.000000 | 0 | 0 || Sending data | 0.544337 | 0.542910 | 0.000000 | 0 | 0 || Creating sort index | 0.000060 | 0.000058 | 0.000000 | 0 | 0 || end | 0.000013 | 0.000013 | 0.000000 | 0 | 0 || query end | 0.000015 | 0.000015 | 0.000000 | 0 | 0 || removing tmp table | 0.000012 | 0.000012 | 0.000000 | 0 | 0 || query end | 0.000102 | 0.000102 | 0.000000 | 0 | 0 || closing tables | 0.000020 | 0.000019 | 0.000000 | 0 | 0 || freeing items | 0.000500 | 0.000049 | 0.000000 | 0 | 0 || cleaning up | 0.000039 | 0.000038 | 0.000000 | 0 | 0 |+----------------------+----------+----------+------------+--------------+---------------+ 要注意的结论 converting HEAP to MyISAM 查询结果太大, 内存都不够用了, 只能使用磁盘了 Creating tmp table 创建临时表 Copying to tmp table on disk 把内存中的临时表复制到磁盘, 危险!!! locked 全局查询日志永远不要在生产环境开启这个功能 配置启用 在 mysql 的 my.cnf 中,设置 123456# 开启general_log=1# 记录日志文件的路径general_log_file=/path/logfile# 输出格式log_output=FILE 编码启用 12345set global general_log=1;set global log_output=&#x27;TABLE&#x27;;# 此后,编写的 slq 语句,会记录到 mysql 库里的 general_log 表.# 查看select * from mysql.general_log; MySQL锁机制锁是计算机协调多个进程或线程并发访问某一资源的机制. 在数据库中, 除了传统的计算资源(CPU, RAM, IO等)的争用外, 数据也是一种供多个用户共享的资源. 如何保证数据并发访问的一致性, 有效性是所有数据库必须解决的一个问题, 锁冲突也是影响数据库并发访问性能的一个重要因素. 从这个角度来说, 锁对于数据库而言显得尤其重要, 也更加复杂. 锁的分类对数据操作的类型(读/写)分 读锁(共享锁): 针对同一份数据, 多个读操作可以同时进行而不会互相影响 写锁(排它锁): 当前写操作没有完成前, 它会阻断其他写锁和读锁 从对数据操作的力度分 表锁 行锁 三锁开销,加锁速度,死锁,粒度,并发性能只能就具体应用的特点来说哪种锁更合适 表锁(偏读)特点 偏向 MyISAM 存储引擎,开销小,加锁快 无死锁 锁定粒度大 发生锁冲突的概率最高, 并发度最低 案例 建表 12345678910create table mylock( id int not null primary key auto_increment, name varchar(20))engine myisam;insert into mylock(name) values(&#x27;a&#x27;);insert into mylock(name) values(&#x27;b&#x27;);insert into mylock(name) values(&#x27;c&#x27;);insert into mylock(name) values(&#x27;d&#x27;);insert into mylock(name) values(&#x27;e&#x27;); 手动增加表锁 1lock table [tablename] read(write), [tablename2] read(write),...; 查看表上加过的锁 1show open tables; 释放表锁 1unlock tables; 结论MyISAM 在执行查询语句 select 前, 会自动给涉及的所有表加读锁, 在执行增删改操作前, 会自动给涉及的表加写锁. MyISAM 的表级锁有两种模式: 表共享读锁(Table Read Lock) 表独占写锁(Table WriteLock) 两种情况 对 MyISAM 表的读操作(加读锁), 不会阻塞其他进程对同一表的读请求, 但会阻塞对同一表的写请求. 只有当读锁释放后, 才会执行其他进程的写操作 对 MyISAM 表的写操作(加写锁), 会阻塞其他进程对同一表的读和写操作, 只有当写锁释放后, 才会执行其他进程的读写操作 简而言之,就是读锁会阻塞写, 但是不会阻塞读. 而写锁则会把读和写都阻塞. MyISAM 的读写锁调度是写优先, 这也表明 MyISAM 不适合做写为主的表的引擎. 因为一旦加了写锁, 其他线程读写都会被阻塞 行锁(偏写)特点 偏向 InnoDB 存储引擎, 开销大, 加锁慢 会出现死锁 锁定力度最小, 发生锁冲突的概率最低, 并发度也最高 InnoDB 与 MyISAM 最大不同有两点: 一是支持事务; 二是采用了行级锁 简单复习数据库并发问题 更新丢失 Lost Update: 两个或多个事务选择同一行,每个事务不知道其他事务存在, 最后的更新会覆盖其他事务的更新操作 脏读 Dirty Reads: 事务 A 读到了事务 B 已修改但未提交的数据. 如果事务 B 回滚,A 读取的数据无效, 不符合一致性要求 不可重复读 Non-Repeatable Reads: 事务 A 读到了 B 已提交的修改数据, 不符合隔离性 幻读Phantom Reads: 事务 A 读到了事务 B 提交的新增数据, 不符合隔离性; 和脏读有点类似, 脏读是修改,幻读是新增数据 数据库隔离级别上面的脏读,不可重复读,幻读,其实都是数据库一致性问题,必须由数据库提供一定的事务隔离机制来解决 级别 读数据一致性 脏读 不可重复读 幻读 未提交读(read uncommitted) 最低级别,只能保证不读取物理上损坏的数据 是 是 是 已提交读(read committed) 语句级 否 是 是 可重复读(repeatable read) 事务级 否 否 是 可序列化(serializable) 最高级别,事务级 否 否 否 事务隔离约严格, 并发副作用越小, 付出的代价就越大, 因为事务隔离实质上就是使事务在一定程度上”串行化”进行, 这显然与”并发”是矛盾的. 不同的应用对于读一致性和数据库隔离程度的要求也是不同的 查看数据库的事务隔离级别: show variables like &#39;tx_isolation&#39;; MySQL默认级别是可重复读(REPEATABLE READ) 无索引行锁升级为表锁比如使用了InnoDB 自己底层做了类型转换, 使得索引失效, 会导致行锁变成表锁. 间隙锁危害 什么是间隙锁 当我们用范围条件而不是相等条件检索数据, 并请求共享或排他锁时, InnoDB 会给符合条件的已有数据记录的索引加锁; 对于键值在条件范围内但不存在的记录, 叫做”间隙(GAP)” InnoDB 也会对这个”间隙”加锁, 这种锁机制就是所谓的间隙锁(Next-Key 锁). 危害 因为 query 执行过程中通过范围查找的话,它会锁定整个范围内所有的索引键值, 即使这个键值不存在. 间隙锁有一个比较知名的弱点, 就是那些不存在的键值也会被无辜的锁定, 而造成在锁定的时候无法插入锁定键值范围内的任何数据. 在某些场景下可能会对性能造成很大的危害 面试题常考: 如何锁定一行?1select [fields] from [table_name] where [xxx] for update; 使用 select xxx for update 锁定某一行后, 其它的操作将会被阻塞, 直到锁定行的会话提交 commit 总结InnoDB 存储引擎由于实现了行级锁定, 虽然在锁定机智的实现方面带来的性能损耗可能比表级锁定会要更高一点, 但是在整体并发处理能力方面要远远优于 MyISAM 的表级锁定的. 当系统并发量较高的时候, InnoDB 的整体性能和 MyISAM 相比就会有比较明显的优势 行锁分析检查状态分析行锁争夺情况 1show status like &#x27;innodb_row_lock%&#x27;; 重要的三个变量 Innodb_row_lock_current_waits: 当前正在等待锁定的数量 Innodb_row_lock_time_avg: 从系统启动到现在锁定总时间长度 Innodb_row_lock_waits: 从系统启动到现在总共等待的次数 优化建议 尽可能让所有数据检索都用索引来完成, 避免无索引行锁升级为表锁 合理设计索引, 尽量缩小锁的范围 尽可能较少检索条件, 避免间隙锁 尽量控制事务大小, 减少锁定资源量和时间长度 尽可能低级别事务隔离 页锁开销和加锁时间介于表锁和行锁之间 会出现死锁 锁定力度介于表锁和行锁之间,并发度一般 只需了解一下 主从复制基本原理slave 会从 master 读取 binlog 来进行数据同步 三步骤 master 将该表记录到二进制日志 (binary log). 这些记录过程叫做二进制日志事件, binary log events; slave 将 master 的 binary log events 拷贝到它的中继日志 (relay log); slava 重做中继日志中的事件, 将改变应用到自己的数据库中. MySQL 复制是异步的且串行化的 基本规则 每个 slave 只有一个 master 每个 slave 只能有一个唯一的服务器 ID 每个 master 可以有多个 slave 最大问题延时 一主一从常见配置[详见另一篇 blog ]","categories":[{"name":"DB","slug":"DB","permalink":"http://yiiiqing.github.io/categories/DB/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/tags/MySQL/"}]},{"title":"Mysql学习手册-基础","slug":"Mysql学习手册-基础","date":"2021-05-06T02:29:29.000Z","updated":"2021-08-26T10:39:50.000Z","comments":true,"path":"2021/05/06/Mysql学习手册-基础/","link":"","permalink":"http://yiiiqing.github.io/2021/05/06/Mysql%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C-%E5%9F%BA%E7%A1%80/","excerpt":"","text":"概念数据库的好处 可以持久化数据到本地 结构化查询 sql结构化查询语言,用于和数据库通信的语言,不是某个数据库软件特有的,而是几乎所有的主流数据库通用的语言 操作常见命令 查看所有的数据库: show databases; 打开指定的库: use 库名 查看当前库的所有表: show tables; 查看其他库的所有表: show tables from 库名; 创建表 1234create table 表名( 列名 列类型, 列名 列类型); 查看表结构: desc 表名; 查看服务器版本 登录进mysql: select version() 未登录: mysql --version 或 mysql -V 语法规范介绍 不区分大小写;建议关键字大写,表名列名小写 每条命令用分号结尾 每条命令根据需要,可以进行缩进,或换行 注释 单行注释: #xxx 单行注释: – xxx 多行: /* xxx */ 基础查询 查询常量: SELECT 100; SELECT &#39;john&#39; 字符型和日期型的常量值必须用单引号引起来,数值型不需要 查询表达式: SELECT 100%98; 查询函数: SELECT VERSION(); 起别名: 使用as SELECT 100%98 AS result; 使用空格 SELECT last_name 姓; 别名有关键字要加双引号 SELECT last_name AS &quot;out put&quot;; 去重: SELECT DISTINCT dep_id from department; 不允许SELECT DISTINCT a, b from c;尽管语法无错误,但是没有去重效果 +号:mysql中的加号只有一个功能: 运算符 SELECT 100+90;两个都为数值型,做加法运算 SELECT &#39;123&#39;+90; 其中一方为字符型,视图将字符型数值转换为数值型;如果转换成功,则继续做加法运算,如果转换失败,则将字符型数值转换成0 SELECT &#39;john&#39;+90; //结果为90 SELECT null+10; //结果为null,只要一方为null,结果就为null 替换null: IFNULL(字段名,替换值) 判断是否为null: ISNULL 如果为null返回1,否则为0 条件查询123select 查询列表from 表名where 筛选条件; 按条件表达式筛选 条件运算符: &gt; &lt; = != &lt;&gt; &gt;= &lt;= 按逻辑表达式筛选(用于连接条件表达式) 逻辑运算符: &amp;&amp; || ! Mysql中推荐: and or not 模糊查询 like 一般和通配符搭配使用 %: 任意多个字符,包含0个 _: 任意单个字符 between and in 类似于=和or的连接简化(所以不支持模糊搜索) 列表的值类型要一致或兼容 is null = 或 &lt;&gt; 不能用于判断null is null 或 is not null可以用于判断null &lt;=&gt; 安全等于: 可以判断值和null 案例12345678910111213141516171819SELECT * FROM employeesWHERE NOT(department_id&gt;=90 AND department_id&lt;=100) OR salary&gt;15000;SELECT * FROM employeesWHERE last_name LIKE &#x27;%a%&#x27;; SELECT * FROM employeesWHERE last_name LIKE &#x27;__n_l%&#x27;;SELECT * FROM employeesWHERE last_name LIKE &#x27;_\\_%&#x27;; # 查询第二个为下划线,需要转义SELECT * FROM employeesWHERE last_name LIKE &#x27;_$_%&#x27; ESCAPE&#x27;$&#x27;; # 查询第二个为下划线,指定转义字符 排序查询1234select 查询列表from 表名where 筛选条件order by 排序列表 [asc|desc]; # 默认升序 order by 的位置一般放在查询语句的最后(除limit语句之外) 案例 按照员工年薪排序 123SELECT *, salary*12*(1+IFNULL(commision_pct,0)) 年薪FROM employeesORDER BY 年薪 DESC; 按姓名长度排序 123SELECT LENGHT(last_name) 字节长度, last_name, salaryFROM employeesORDER BY LENGTH(last_name) DESC; 查询员工信息,要求先按照工资升序,再按员工编号降序[多个字段排序] 123SELECT * FROM employeesORDER BY salary ASC, employee_id DESC; 常见函数概念将一组逻辑语句封装方法体中,对外暴露方法名 好处: 隐藏了实现细节 提高代码的重用性 调用:select 函数名(实参列表) [from 表]; 分类: 单行函数: concat,length,ifnull 分组函数: 统计使用,又称为统计函数 单行函数字符函数 length select LENGTH(&#39;张三丰&#39;);结果为9, 因为utf8下一个汉字3个字节 concat 拼接 select CONCAT(last_name,&#39;_&#39;,first_name) 姓名 from employees; upper,lower 大小写 select UPPER(&#39;jogn&#39;); substr, substring 返回子串 SELECT SUBSTR(&#39;李莫愁爱上了陆展元&#39;, 7 ) out_put; #陆展元 SELECT SUBSTR(&#39;李莫愁爱上了陆展元&#39;, 1,3 ) out_put; #李莫愁 instr 返回起始索引 SELECT INSTR(&#39;杨不悔爱上了殷六侠&#39;,&#39;殷六侠&#39;) AS out_put; #7 trim SELECT TRIM(&#39; 张翠山 &#39;) AS out_put; SELECT TRIM(&#39;a&#39; FROM &#39;aaaaa张aaa翠aaa山aaaaaa&#39;) AS out_put;#张aaa翠aaa山 lpad 用指定字符左填充 SELECT LPAD(&#39;殷素素&#39;,10,&#39;*&#39;) AS out_put;# *******殷素素 rpad 用指定字符右填充 SELECT RPAD(&#39;殷素素&#39;,12,&#39;ab&#39;) AS out_put;# 殷素素ababababa replace 替换 SELECT REPLACE(&#39;张无忌爱上了周芷若&#39;,&#39;周芷若&#39;,&#39;赵敏&#39;) AS out_put; 数学函数 round 四舍五入 SELECT ROUND(-1.65) # -2 SELECT ROUND(-1.657,2) # -1.66 保留两位 ceil 向上取整,返回&gt;=该参数的最小整数 floor 向下取整,返回&lt;=该参数的最大整数 truncate 截断 SELECT TRUNCATE(1.69999,1) # 1.6 mod 取余 MOD(a,b): a - a / b * b MOD(-10,-3): -10 - (-10)/(-3) * (-3) = -1 被除数为正,结果为正 SELECT MOD(10,3); #1 SELECT MOD(10,-3); #1 日期函数 now 返回当前系统日期+时间 SELECT NOW(); curdate 返回当前系统日期,不包含时间 SELECT CURDATE(); curtime 返回当前时间,不包含日期 SELECT CURTIME(); 可以获取指定的部分,年月日时分秒 SELECT YEAR(NOW()) 年; SELECT MONTHNAME(NOT()) 月; str_to_date 将日期格式的字符串转换成指定格式的日期 SELECT STR_TO_DATE(&#39;1998-3-2&#39;,&#39;%Y-%c-%d&#39;) AS out_put;# 1998-03-02 SELECT * FROM employees WHERE hiredate = STR_TO_DATE(&#39;4-3 1992&#39;,&#39;%c-%d %Y&#39;); 指定输入格式 date_format 将日期转换成字符 SELECT DATE_FORMAR(NOW(), &#39;%y年%m月%d日&#39;) AS out_put; 返回两个日期相差的天数: DATEDIFF 以英文形式返回月: MONTHNAME 其他函数12345SELECT VERSION();SELECT DATABASE();SELECT USER();SELECT PASSWORD(&#x27;字符&#x27;); # 返回该字符的加密形式SELECT MD5(&#x27;字符&#x27;); # 返回该字符的加密形式 流程控制函数 if SELECT IF(10&gt;5,&#39;大&#39;,&#39;小&#39;); case 使用一: switch case的效果 123456case 要判断的字段或表达式when 常量1 then 要显示的值1或语句1;when 常量2 then 要显示的值2或语句2;...else 要显示的值n或语句n;end 使用二: 多重if 123456casewhen 条件1 then 要显示的值1或语句1when 条件2 then 要显示的值2或语句2...else 要显示的值n或语句n;end 示例: 12345678SELECT salary,CASEWHEN salary&gt;20000 THEN &#x27;A&#x27;WHEN salary&gt;15000 THEN &#x27;B&#x27;WHEN salary&gt;10000 THEN &#x27;C&#x27;ELSE &#x27;D&#x27;END AS 工资级别FROM employees; 分组函数用作统计使用,又称为聚合函数或统计函数或组函数 和分组函数一通查询的字段,要求是GROUP BY后的字段 分类sum求和,avg平均值,max最大值,min最小值,count计算个数 参数支持类型sum, avg一般用于处理数值型 max, min, count可以处理任何类型 是否忽略null以上函数都忽略了null值 和distinct搭配12SELECT SUM(DISTINCT salary), SUM(salary) FROM employees;SELECT COUNT(DISTINCT salary), COUNT(salary) FROM employees; count详细介绍12SELECT COUNT(*) FROM employees; # 统计行数SELECT COUNT(1) FROM employees; # 统计行数(只要COUNT里面是常量) 效率: MYISAM存储引擎下, COUNT(*) 效率最高 INNODB存储引擎下, COUNT(*) 和 COUNT(1) c差不多,比COUNT(‘字段’) 高 分组查询语法12345select 分组函数, 列(要求出现在group by后)from 表[where 筛选条件]group by 分组列表[order by 子句] 注意: 查询列表必须特殊,要求是分组函数和group by后出现的字段 特点分组查询的筛选条件分为两类 分组前筛选 数据源: 原始表 位置: group by子句前 关键字: where 分组后筛选 数据源: 分组后的结果集 位置: group by子句后 关键字: having 分组函数做条件肯定放在having中 能用分组前筛选的优先使用分组前筛选 group支持单个字段分组,多个字段分组(用逗号隔开,无顺序),表达式或函数(使用少) 排序要放在group by之后 案例 查询每个工种的最高工资 123select max(salary), job_idfrom employeesgroup by job_id; 查询每个位置上部门个数 123select count(*), location_idfrom employeesgroup by location_id; 查询邮箱中包含a字符的,每个部门的平均工资 分组前的筛选使用where 1234select avg(salary), department_idfrom employeeswhere email like &#x27;%a%&#x27;group by department_id; 查询哪个部门的员工个数&gt;2 分组后的筛选使用having 123456# 查询每个部门的员工个数# 根据1的结果筛选,查询&gt;2的select count(*), department_idfrom employeesgroup by department_idhaving count(*)&gt;2; 查询每个工种有奖金的员工的最高工资&gt;12000的工种编号和最高工资 1234567891011# 查询每个工种有奖金的员工的最高工资select max(salary),job_idfrom employeeswhere commission_pct is not nullgroup by job_id;# 根据结果筛选最高工资&gt;12000select max(salary),job_idfrom employeeswhere commission_pct is not nullgroup by job_idhaving max(salary)&gt;12000; 查询每个部门每个工种的员工的平均工资 按多个字段分组 123select avg(salary), department_id, job_idfrom employeesgroup by job_id,department_id; 查询每个部门每个工种的员工的平均工资,并且按高低排序 排序 12345select avg(salary),department_id,job_idfrom employeesgroup by job_id,department_idhaving avg(salary)&gt;10000order by avg(salary) desc; 连接查询概念笛卡尔乘积现象: 表1有m行,表2有n行,结果为m*n行 原因: 没有有效的连接条件 如何避免: 添加有效的连接条件 分类 按年代分类(mysql) sql92标准: 仅支持内连接 sql99标准[推荐]: 支持内连接+外连接(左外和右外)+交叉连接 按功能分类 内连接 等值连接 非等值连接 自连接 外连接 左外连接 右外连接 全外连接 交叉连接 sql92标准内连接等值连接案例: 查询女神名和对应的男神名 123select name,boynamefrom boys,beautywhere beauty.boyfriend_id=boys.id 给表起别名 提高语句简洁度 区分多个重名字段 起了别名,就要用别名限定 两个表的顺序可以调换 可以加筛选,分组,排序等 非等值连接案例: 查询员工工资级别 123select salary,grade_levelfrom employees e, job_grades gwhere salary between g.`lowest_sal` and g.`highest_sal`; 自连接要求一张表中包含了所需的信息,把自己当成多张表使用 案例: 员工名和上级的名称 123select e.employee_id, e.lastname, m.employee_id, m.last_namefrom employees e, employees mwhere e.`manager_id`=m.`employee_id` sql99标准语法12345678select 查询列表from 表1 别名 [连接类型]join 表2 别名on 连接条件[where 筛选条件][group by 分组条件][having 筛选条件][order by 排序列表] 连接类型 内连接: inner 外连接 左外: left [outer] 右外: right (outer) 全外: full (outer) 交叉连接: cross 内连接语法1234select 查询列表from 表1 别名inner join 表2 别名on 连接条件 特点 可以添加排序,分组,筛选 inner可以省略 筛选条件放在where后面,连接条件放在on后面.提高分离性,便于阅读 inner join连接和sql92语法中的等值连接效果一样 分类等值连接查询员工名,部门名 1234select last_name,department_namefrom employees einner join departments don e.`department_id` = d.`department_id`; 查询员工名,部门名,工种名,按部门名降序(三表) 12345select last_name,department_name,job_titlefrom employees einner join departments d on e.`department_id`=d.`department_id`inner join jobs j on e.`job_id`=j.`job_id`order by depart_name desc; 非等值连接查询员工工资级别 1234select salary,grade_levelfrom employees ejoin job_grades gon e.`salary` between g.`lowest_sal` and g.`highest_sal`; 自连接案例: 员工名和上级的名称 1234select e.employee_id, e.lastname, m.employee_id, m.last_namefrom employees ejoin employees mon e.`manager_id`=m.`employee_id` 外连接用于查询,一个表中有,另一个表中没有的记录 用于查询除了交集部分的剩余不匹配的行 特点 外连接的查询结果为主表中的所有记录 如果从表中有和它相匹配的,则显示匹配的值 如果从表中没有和它匹配的,则显示null 外连接查询结果=内连接结果+主表中有而从表中没有的记录 左外连接, left join左边的是主表 右外连接, right join右边的是主表 左外和右外交换两个表的顺序,可以实现相同的结果 全外连接=内连接的结果+表1中有表2没有的+表2中有但表1中没有的 左外连接1234567891011# 主表bselect b.name,bo.*from beauty bleft outer join boys boon b.`boyfriend_id` = bo.`id`;# 主表boselect b.name,bo.*from boys boleft outer join beauty bon b.`boyfriend_id` = bo.`id`; 右外连接12345# 主表bselect b.name,bo.*from boys boright outer join beauty bon b.`boyfriend_id` = bo.`id`; 全外连接mysql不支持 交叉连接其实就是使用99语法来实现笛卡尔乘积 123select b.*,bo.*from beauty bcross join boys bo; 总结 子查询出现在其他语句中的select语句,称为子查询或内查询 外部的查询语句,称为主查询或外查询 分类: 子查询出现的位置: select后面 仅支持标量子查询 from后面 支持表子查询 where或having后面(重点) 标量子查询 列子查询 行子查询 exists后面(相关子查询) 表子查询 按结果集的行列数: 标量子查询(结果集只有一行一列) 列子查询(结果集只有一列多行) 行子查询(结果集有一行多列) 表子查询(结果集一般为多行多列) where或having后面 标量子查询(单行子查询) 列子查询(多行子查询) 行子查询(一行多列) 特点 子查询放在小括号内 子查询一般放在条件的右侧 标量子查询,一般搭配着单行操作符使用 &gt; &lt; &gt;= &lt;= = &lt;&gt; 列子查询,一般搭配着多行操作符使用 in, any/some, all a &gt; any(10,20,30) a大于任何一个就可以匹配(相当min) a &gt; all(10,20,30) a大于所有的(相当max) 子查询的执行优先于主查询执行 标量子查询 谁的工资比Abel高 123456789select *from employeeswhere salary&gt;( select salary from employees where last_name = &#x27;Abel&#x27; ); 返回job_id与141号员工相同, salary比143号员工多的员工 姓名,job_id,工资 1234567891011121314151617181920# 查询141号员工的job_idselect job_idfrom employeeswhere employee_id = 141# 查询143号员工的salaryselect salaryfrom employeeswhere employee_id = 143# 查询员工的姓名, job_id 和工资select last_name,job_id,salaryfrom employeeswhere job_id = ( select job_id from employees where employee_id = 141) and salary &gt; ( select salary from employees where employee_id = 143); 返回公司工资最少的员工的last_name,job_id和salary 123456select last_name, job_id, salaryfrom employeeswhere salary = ( select min(salary) from employees); 查询最低工资大于50号部门最低工资的部门id和其最低工资 1234567891011121314151617# 查询50号部门的最低工资select min(salary)from employeeswhere deplartment_id = 50;# 查询每个部门的最低工资select min(salary), department_idfrom employeesgroup by department_id# 满足min(salary) &gt; 第一步select min(salary), department_idfrom employeesgroup by department_idhaving min(salary) &gt; ( select min(salary) from employees where deplartment_id = 50;) 列子查询 查询location_id是1400或1700的部门中的所有员工姓名 1234567select last_namefrom employeeswhere department_id in ( select distinct department_id from departments where location_id in (1400,1700)); 行子查询 查询员工编号最小并且工资最高的员工信息 12345678910111213141516171819# 查询最小的员工编号select min(employee_id) from employees# 查询最高工资select max(salary) from employees# 查询员工信息select *from employeeswhere employee_id = ( select min(employee_id) from employees)and salary = ( select max(salary) from employees)# 2.0select *from employeeswhere (employee_id,salary)=( select min(employee_id),max(salary) from employees); select后面仅仅支持标量子查询 查询每个部门的员工个数 123456select d.*,( select count(*) from employees e where e.department_id = d.`department_id` # 查询某一条的时候,找对应该条的) 个数from departments d; 查询员工号=102的部门名 12345select ( select department_name from departments d where ) from后面将子查询结果充当一张表,要求必须起别名 查询每个部门的平均工资的工资等级 123456789101112131415# 查询每个部门的平均工资select avg(salary),department_idfrom employeesgroup by department_id;# 查询工资等级表select * from job_grades;# 连接1的结果,筛选select from ( select avg(salary) ag,department_id from employees group by department_id) avg_depinner join job_grades gon avg_dep.ag between g.lowest_sal and g.highest_sal; exist后面(相关子查询)语法 12exists (完整的查询语句)# 结果为0/1 查询有员工的部门名 12345678910111213141516# existselect department_namefrom departments dwhere exists( select * from employees e where d.`department_id`=e.`department_id`);#inselect department_namefrom departments d where d.`department_id` in ( select department_id from employees) 查询没有女朋友的男生信息 12345678910111213141516# inselect bo.*from boys bowhere bo.id not in ( select boyfriend_id from beauty)# existselect bo.*from boys bowhere not exists( select boyfriend_id from beauty b where bo.`id`=b.`boyfriend_id`); 分页查询语法12345678910111213select 查询列表from 表[ join type join 表2 on 连接条件 where 筛选条件 group by 分组字段 having 分组后的筛选 order by 排序字段]limit offset,size;# offset 要显示条目的起始索引(从0开始)# size 要显示的条目个数 特点 limit语句放在查询语句的最后(从执行和语法都是最后) 公式 要显示的页数 page, 每页条目数 size 123select 查询列表from 表limit (page-1)*size, size; 案例 查询前5条 12select * from employees limit 0,5;select * from employees limit 5; 查询第11-25 1select * from employees limit 10,15; 查询的执行顺序123456789select 查询列表 #7from 表 #1join type join 表2 #2on 连接条件 #3where 筛选条件 #4group by 分组字段 #5having 分组后的筛选 #6order by 排序字段 #8limit offset,size; #9 联合查询将多条查询语句的结果合并成一个结果 语法12345查询语句1union查询语句2union... 应用场景当查询的结果来自多个表,并且多个表之间没有直接的连接关系,单查询的信息一致的时候 注意: union会去重 特点 要求多条查询语句的查询烈属是一致的 要求多条查询语句的每一列的类型和顺序最好一致 union关键字默认去重,如果使用union all可以包含重复项 DML语言插入语句语法1234# 方式一insert into 表名(列名1,...) values(值1,...),(值1,...);# 方式二insert into 表名 set 列名=值,列名=值,...; 特点 插入值的类型要与列的类型一致或兼容 不可以为null的列必须插入值 列的顺序可以调换 列数和值的个数必须一致 可以省略列名,默认所有列,而且列的顺序和表中列的顺序一致 两种方式 方式一支持插入多行 方式一支持子查询 12insert into beauty(id,name,phone)select 26,&#x27;xiaoming&#x27;,&#x27;123&#x27;; 修改语句 修改单表的记录 123update 表名set 列=新值,列=新值where 筛选条件; update beauty set phone = &#39;13899992222&#39; where name like &#39;唐%&#39;; 修改多表的记录 12345678910111213# sql92update 表1 别名1, 表2 别名2set 列=值,...where 连接条件and 筛选条件;# sql99update 表1 别名inner|left|right join 表2 别名on 连接条件set 列=值,...where 连接条件and 筛选条件; 1234update boys boinner join beauty b on bo.`id`=b.`boyfriend_id`set b.`phone`=&#x27;114&#x27;where bo.`boyName`=&#x27;张无忌&#x27; 删除语句语法123456789101112131415161718# 方式一: delete# 单表delete from 表名 where 筛选条件;# 多表# sql92delete 别名1,别名2from 表1 别名1,表2 别名2where 连接条件and 筛选条件;# sql99delete 表1别名,表2别名from 表1 别名inner|left|right join 表2 别名 on 连接条件where 筛选条件;# 方式二: truncate 删除整个表truncate table 表名; 区别(面试重点) delete 可以加where条件,truncate不添加 truncate要删除,效率高一点 加入要删除的表中有自增长列 如果用delete删除后,再插入数据,自增长列的值从断点开始 如果用truncate删除,再插入数据,自增长的列的值从1开始 truncate删除没有返回值,delete删除有返回值 truncate删除不能回滚,delete删除可以回滚 案例删除张无忌女朋友的信息 1234delete bfrom beauty binner join boys bo on b.`boyfriend_id`=bo.`id`where bo.`boyName`=&#x27;张无忌&#x27;; DDL语言概念数据定义语言 库和表的管理 库的管理 创建,修改,删除 表的管理 创建修改删除 创建: create 修改: alter 删除: drop 库的管理库的创建1create database [if not exists] 库名; 库的修改12rename database books to 新库名;alter database books character set gbk; 库的删除1drop database if exists books; 表的管理表的创建1234567create table 表名( 列名 列的类型[(长度) 约束], 列名 列的类型[(长度) 约束], 列名 列的类型[(长度) 约束], ... 列名 列的类型[(长度) 约束]); 示例1234567891011121314151617create table book( id int, # 编号 bName varchar(20), # 图书名 price double, # 价格 authorId int, # 作者编号 publishDate datetime # 出版日期);DESC book;create table author( id int, aName varchar(20), nation varchar(10));DESC author; 表的修改1ALTER TABLE 表明 add|drop|modify|change column 列名 [列类型] [约束]; 修改列名1alter table book change column pulishdate pubDate datetime; # 要加类型在后面 修改列的类型或约束1alter table book modify column pubdate timestamp; 添加列 1ALTER TABLE author ADD COLUMN annual DOUBLE; 删除列 1ALTER TABLE author DROP COLUMN annual; 修改表名 1ALTER TABLE author RENAME TO book_author; 表的删除12DROP TABLE IF EXISTS book_author;SHOW TABLES; 表的复制12INSERT INTO author VALUES(1,&#x27;村上春树&#x27;,&#x27;日本&#x27;),(2,&#x27;莫言&#x27;,&#x27;中国&#x27;), 仅仅复制表的结构 1CREATE TABLE copy LIKE author; 复制表的结构外加数据 12CREATE TABLE copy2SELECT * FROM author; 复制部分数据 1234CREATE TABLE copy3SELECT id,au_nameFROM authorWHERE nation=&#x27;中国&#x27;; 仅仅复制某些字段,不复制数据 1234CREATE TABLE copy4SELECT id,au_nameFROM authorwhere 0; 数据类型分类 数值型 整数 小数 定点数 浮点数 字符型 较短的文本: char, varchar 较长的文本: text, blob(较长的二进制数据) 日期型 整型 整数类型 字节 范围 tinyint 1 无符号-128127;有符号0255 smallint 2 有符号-3276832767; 无符号065535 mediumint 3 不用记住 int, integer 4 -2147483648~2147483647 (装逼可以记住) bigint 8 不用记住 特点 如果不设置无符号还是有符号,默认是有符号,如果想设置无符号,需要添加unsigned关键字 12345CREATE TABLE tab_int( t1 INT, t2 INT UNSIGNED, t3 INT(7) ZEROFILL # 指定长度,用0填充,包含UNSIGNED) 如果插入的数值超出了整型的范围,会报out of range异常,并且插入临界值 如果不设置长度,会有默认的长度 长度代表了显示的最大宽度,如果不够在左边填充,但必须搭配zerofill使用 小数 浮点型 float(M,D) double(M,D) 定点型 dec(M,D) decimal(M,D) 特点 M和D: M: 整数部位+小数部位 D: 小数部位 超出插入临界值 M和D都可以省略. 如果是decimal,则M默认为10,D默认为0;如果是float和double,则会根据插入的数值和精度来决定精度 定点型精度较高,如果要求插入的数值的精度较高,如货币运算等,考虑使用 原则所选择的类型越简单越好,能保存数值的类型越小越好 字符型 较短的文本: char, varchar 较长的文本: text, blob(较大的二进制) 特点 写法 M的意思 特点 空间耗费 效率 char char(M) 最大的字符数,可以省略,默认1 固定长度的字符 比较耗费 高 varchar varchar(M) 最大的字符数,不可以省略 可变长度的字符 比较节省 低 binary和varbinary类型类似于char和varchar,不同的是它们包含二进制字符串而不包含非二进制字符串 enum不区分大小写 123create table tab_char( c1 ENUM(&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;)); set和enum类似,里面可以保存0-64个成员 和enum类型最大的区别就是: set类型可以一次选取多个成员,而enum只能选一个 根据成员个数不同,存储所占的字节也不同 成员数 字节数 1-8 1 9-16 2 17-24 3 25-32 4 33-64 8 12345678create table tab_set( s1 SET(&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;));insert into tab_set values(&#x27;a&#x27;); # ainsert into tab_set values(&#x27;A,B&#x27;); # a,binsert into tab_set values(&#x27;a,c,d&#x27;); # a,c,d 日期型分类 date 只保存日期 time 只保存时间 year 只保存年 datetime 保存日期+时间 timestamp 保存日期+时间 特点 字节 范围 时区影响 datetime 8 1000-9999 不受 timestamp 4 1970-2038 受 约束一种限制,用于限制表中的数据,为了保证表中的数据的准确和可靠性 六大约束 NOT NULL: 非空,用于保证该字段的值不能为空 比如姓名学号等 DEFAULT: 默认,用于保证该字段有默认值 比如性别 PRIMARY KEY: 主键,用于保证该字段的值具有唯一性,并且非空 比如编号 UNIQUE: 唯一,用于保证该字段的值具有唯一性,可以为空 比如座位号 CHECK: 检查约束[mysql中不支持] 比如要求年龄段只能为18-60 FOREIGN KEY: 外键,用于限制两个表的关系,用于保证该字段的值必须来自于主表的关联列的值 在从表中添加外键约束,用于引用主表中某列的值 比如员工表的部门编号 要求: 在从表设置外键关联 从表的外键列的类型和主表的关联列的类型要求一致或兼容,名称无要求 主表的关联列必须是一个key(是主键或唯一) 插入数据时,先插入主表,再插入从表 删除数据时,先删除从表,再删除主表 主键和唯一的对比: 主键 唯一 不允许为空 一表只能有一个 允许组合,但不推荐 primary key(a,b) 唯一 唯一 可以为空 一表可以有多个 允许组合,但不推荐 添加约束的时机: 创建表或修改表时 约束的添加分类 列级约束 位置: 列的后面.直接在字段名和类型后面追加约束类型即可 六大约束语法上都支持, 但外键约束没有效果(check也没) 表级约束 位置: 所有列的下面 除了非空,默认,其他都支持 12345CREATE TABLE 表名( 字段名 字段类型 列级约束, 字段名 字段类型, 表级约束) 添加约束创建表时添加添加列级123456789101112131415161718use students;create table major( id int primary key, majorName varchar(20));create table stuinfo( id int primary key, # 主键 stuName varchar(20) not null, gender char(1) check(gender=&#x27;男&#x27; or gender=&#x27;女&#x27;), # 检查 seat int unique, # 唯一 age int default 18, # 默认 majorId int references major(id), # 外键);desc stuinfo;# 查看所有索引, 包括主键,外键,唯一show index from stuinfo; 添加表级语法 12# 在各个字段最下面[constraint 约束名] 约束类型(字段名) 12345678910111213create table stuinfo( id int, stuName varchar(20), gender char(1), # 检查 seat int, # 唯一 age int, # 默认 majorId int, # 外键 constraint pk primary key(id), constraint uq unique(seat), constraint ck check(gender=&#x27;男&#x27; or gender=&#x27;女&#x27;), # 检查 constraint fk_stuinfo_major foreign key(majorId) references major(id)); 通用写法1234567891011create table if not exists stuinfo( id int primary key, # 主键 stuName varchar(20) not null, gender char(1) check(gender=&#x27;男&#x27; or gender=&#x27;女&#x27;), # 检查 seat int unique, # 唯一 age int default 18, # 默认 majorId int, # 为了明显区别外键 constraint fk_stuinfo_major foreign key(majorId) references major(id)); 修改表时添加约束语法1234# 1. 添加列级约束alter table 表名 modify column 字段名 字段类型 新约束;# 2. 添加表级约束alter table 表名 add [constraint 约束名] 约束类型(字段名) [外键的引用]; 示例 添加非空约束 ALTER TABLE stuinfo MODIFY COLUMN stuname VARCHAR(20) NOT NULL; 添加主键 列级 ALTER TABLE stuinfo MODIFY COLUMN id INT PRIMARY KEY; 表级 ALTER TABLE stuinfo ADD UNIQUE(seat); 添加外键 ALTER TABLE stuinfo ADD CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorId) REFERENCES major(id) ; 修改表时删除约束 删除非空约束 ALTER TABLE stuinfo MODIFY COLUMN stuname VARCHAR(20) NULL; 删除默认约束 ALTER TABLE stuinfo MODIFY COLUMN age INT; 删除主键 ALTER TABLE stuinfo DROP PRIMARY KEY; 删除唯一 ALTER TABLE stuinfo DROP INDEX seat; 删除外键 ALTER TABLE stuinfo DROP FOREIGN KEY fk_stuinfo_major; 示例 向表中id列加PRIMARY KEY约束 1234# 列级约束不可以起名ALTER TABLE emp2 MODIFY COLUMN id INT PRIMARY KEY;# 表级约束可以起名ALTER TABLE emp2 ADD constrain my_emp_id_pk PRIMARY KEY(id); 向表emp2中添加列dept_id,并在其中定义FOREIGN KEY约束,与之相关联的列是dept2表中的id列 12ALTER TABLE emp2 ADD COLUMN dept_id INT;ALTER TABLE emp2 ADD CONSTRAINT fk_emp2_dept2 FOREIGN KEY(dept_id) REFERENCES dept2(id); 标识列又称为自增长列 可以不用手动的插入值,系统提供默认的序列值 特点 标识列不一定需要和主键搭配,但要求是个key 一个表至多一个标识列! 标识列的类型只能是数值型 创建表时设置标识列123456create table tab_identity( id INT PRIMARY KEY AUTO_INCREMENT, NAME VARCHAR(20));SHOW VARIABLES LIKE &#x27;%auto_increment%&#x27;; 使用指令SHOW VARIABLES LIKE &#39;%auto_increment%&#39;;可以看到有两个参数 auto_increment_increment 步长 修改: set auto_increment_increment=3; auto_increment_offset 偏移量 起始值更改: 在某个地方手动插入一个值 修改表时设置标识列ALTER TABLE tab_identity MODIFY COLUMN id INT PRIMARY KEY AUTO_INCREMENT; 修改表时删除标识列ALTER TABLE tab_identity MODIFY COLUMN id INT; 事务事务: 一个或一组sql语句组成一个执行单元,这个执行单元要么全部执行,要么全部不执行. ACID 原子性 Atomicity 事务是一个不可分割的工作单位,事务中的操作要么都发生,要么都不发生 一致性 Consistency 事务必须使数据库从一个一致性状态变换到另一个一致性状态 隔离性 Isolation 事务的隔离性是指一个事务的执行不能被其他事务干扰.即一个事务内部的操作及使用的数据对并发的其他事务是隔离的,并发执行的各个事务之间不能互相干扰 持久性 Durability 指一个事务一旦被提交,它对数据库中数据的改变就是永久性的 事务的创建 隐式事务 事务没有明显的开始和结束的标记 比如insert,update,delete语句 显式事务 事务具有明显的开启和结束的标记 前提: 必须先设置自动提交功能为禁用 set autocommit=0; 步骤12345678910# 1. 开启事务set autocommit=0;start transaction;# 可选# 2. 编写事务中的语句# 语句一# 语句二# 3. 结束事务commit; 提交事务rollback; 回滚事务 数据库隔离级别对于同时运行多个事务,当这些事务访问数据库中相同的数据时,如果没有采取必要的隔离措施,就会导致各种并发问题 脏读 对于两个事务T1,T2,T1读取了已经被T2更新但是还没有被提交的字段. 如果T2回滚,T1读取的内容就是临时并且无效的(与幻读相比针对的是更新) 不可重复读 对于两个事务T1,T2,T1读取了一个字段,然后T2更新了该字段. 之后T1再次读取同一个字段,值会不同 幻读 对于两个事务T1,T2. T1从一个表中读取了一个字段,然后T2在该表中插入了一些新的行.之后如果T1再次读取同一个表,就会多出几行(与脏读相比针对的是插入和删除) 所以,数据库系统必须具有隔离并发运行各个事务的能力,使它们不会相互影响,避免引发各种并发问题 隔离级别一个事务与其他事务隔离的程度称为隔离级别. 数据库规定了各种事务隔离级别,不同隔离级别对应不同的干扰程度. 隔离级别越高,数据一致性就越好,但并发性越弱 数据库提供了四种隔离级别 隔离级别 描述 READ UNCOMMITTED(读未提交数据) 允许事务读取未被其他事务提交的变更. 脏读,不可重复读,幻读的问题都会出现 READ COMMITTED(读已提交数据) 只允许事务读取已经被其他事务提交的变更,可以避免脏读,但不可重复读和幻读问题仍然可能出现 REPEATABLE READ(可重复读) 确保事务可以多次从一个字段中读取相同的值.但在这个事务持续期间,禁止其他事务对这个字段进行更新.可以避免脏读和不可重复读,但是幻读的问题依然存在 SERIALIZABLE(串行化) 确保事务可以从一个表中读取相同的行,在这个事务持续期间,禁止其他事务对该表执行插入,更新和删除操作.所有并发问题都能避免,但是性能十分低下 oracle支持两种: READ COMMITED(默认), SERIALIZABLE. mysql支持四种: 默认为REPEATABLE READ 查看数据库隔离级别mysql8+: select @@transaction_isolation; mysql5.x: select @@tx_isolation; 设置隔离级别当前:set session transaction isolation level read uncommitted; 全局:set global transaction isolation level read committed; savepoint设置节点 123456set autocommit=0;start transaction;delete from account where id=25;savepoint a; # 设置保存点delete from account where id=28;rollback to a; # 回滚到保存点 删除有外键关联的主表数据级联删除12alter table stuinfo add constraint fk_stu_major foreign key(majorId) references major(id)on delete cascade; # 级联删除 级联置空12alter table stuinfo add constraint fk_stu_major foreign key(majorId) references major(id)on delete set null; # 级联置空, 将关联的外键置为空 变量 系统变量 全局变量 global 作用域: 服务器每次启动将为所有的全局变量赋初始值,针对于所有的会话(连接)有效,但不能跨重启 会话变量 session 作用域: 仅仅针对于当前会话有效 自定义变量 用户变量 作用域: 针对于当前会话(连接)有效,同于会话变量的作用域 定义和使用的位置: 会话中任何地方 语法: 必须加@ 局部变量 作用域: 仅仅在定义它的begin end中有效 定义和使用的位置: 只能在BEGIN END中,且为一句话 语法: 一般不用加@ 系统变量由系统提供,不是用户自定义,属于服务器层面 如果是全局级别,加global, 会话变量不用加,默认. 查看所有的系统变量1show global|[session] variables; # session可以不写,为默认 查看满足条件的部分系统变量1show global|[session] variables like &#x27;%char%&#x27;; 查看指定的某个系统变量的值1select @@global|[session].系统变量名 # 有个. 为某个系统变量赋值1234# 1.set global|[session] 系统变量名 = 值;# 2.set @@global|[session]|.系统变量名=值; 自定义变量使用步骤: 声明 赋值 使用(查看,比较,运算等) 用户变量 声明并初始化 赋值操作符: = 或:= (因为=类似比较所以增加了:=; set都可以,select只能后者) 123set @用户变量名=值;set @用户变量名:=值;select @用户变量名:=值; 赋值(更新用户变量的值) 1234567891011121314 # 方式一: set或select set @用户变量名=值; set @用户变量名:=值; select @用户变量名:=值; # 方式二: 通过select into select 字段 into 变量名 from 表; # 示例 set @name=&#x27;john&#x27;; set @name=100; set @count=1; select count(*) into @count from employees; 使用(查看用户变量的值) 1select @用户变量名; 局部变量 声明 12declare 变量名 类型;declare 变量名 类型 default 值; 赋值 1234567# 方式一: set或selectset 局部变量名=值;set 局部变量名:=值;select @局部变量名:=值;# 方式二: 通过select intoselect 字段 into 局部变量名 from 表; 使用 1select @局部变量名; 示例1234567891011# 用户变量set @m=1;set @n=2;set @sum = @m + @n;select @sum;# 局部变量declare m int default 1;declare n int default 2;declare sum int;set sum = m + n; 存储过程的介绍存储过程和函数,类似于java中的方法 好处: 提高代码重用性 简化操作 存储过程一组预先编译好的SQL语句的集合,理解成批处理语句 提高代码重用性 简化操作 减少了编译次数并且减少了和数据库服务器的连接次数,提高了效率 创建语法1234create procedure 存储过程名(参数列表)begin 存储过程体(一组合法的SQL语句)end 注意: 参数列表包含三部分: 参数模式,参数名,参数类型. IN stuname VARCHAR(20) 参数模式: IN: 该参数可以作为输入, 也就是说该参数需要调用方传入值 OUT: 该参数可以作为输出, 也就是该参数可以作为返回值 INOUT: 该参数既可以作为输入也可以作为输出 如果存储过程体仅仅只有一句话,BEGIN END可以省略 存储过程体中的每一条SQL语句的结尾要求必须加分号 存储过程的结尾(分号)可以使用DELIMITER重新设置 语法: 1234DELIMITER 结束标记# 示例DELIMITER $ 调用语法CALL 存储过程名(实参列表); 示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# 1. 空参列表# 插入admin中五条记录SELECT * FROM admin;DELIMITER $CREATE procedure myp1()BEGIN insert into admin(username,`password`) values(&#x27;john1&#x27;,&#x27;0000&#x27;),(&#x27;lily&#x27;,&#x27;0000&#x27;),(&#x27;rose&#x27;,&#x27;0000&#x27;),(&#x27;jack&#x27;,&#x27;0000&#x27;),(&#x27;tom&#x27;,&#x27;0000&#x27;),;END $# 调用CALL myp1()$ # 注意结束符号已经替换掉了!# 2. IN# 创建存储过程实现根据女生名查询对应的男生名的信息create procedure myp2(in beautyName varchar(20))begin select bo.* from boys bo right join beauty b on bo.id=b.boyfriend_id where b.name=beautyName;end $# 调用CALL myp2(&#x27;柳岩&#x27;)$# 创建存储过程实现用户是否登录成功create procedure myp3(in username varchar(20), in password varchar(20))begin declare result varchar(20) default &#x27;&#x27;; select count(*) into result # 赋值(局部变量) from admin where admin.username = username and admin.password = password; select if(result&gt;0,&#x27;成功&#x27;,&#x27;失败&#x27;);end $# 调用call myp3(&#x27;张飞&#x27;,&#x27;8888&#x27;)$# 3. OUT# 根据女生名,返回对应的男生名create procedure myp5(in beautyName varchar(20),out boyName varchar(20))begin select bo.boyName into boyName # 在这加上into from boys bo inner join beauty b on bo.id=b.boyfriend_id where b.name=beautyName;end $# 调用set @bName$ # 定义一个用户变量(不定义也可以)call myp5(&#x27;小昭&#x27;,@bName)$select @bName$ # 拿到结果# 根据女生名返回对应男生名和魅力值create procedure myp6(in beautyName varchar(20),out boyName varchar(20), out userCP int)begin select bo.boyName,bo.userCP into boyName,userCP # 在这加上into from boys bo inner join beauty b on bo.id=b.boyfriend_id where b.name=beautyName;end $#调用call myp6(&#x27;小昭&#x27;,@name,@cp)$ # 没有定义,也可以直接拿到结果select @name,@cp$# 4. 创建带inout模式参数的存储过程# 传入a和b两个值,最终a和b都翻倍并返回create procedure myp8(inout a int, inout b int)begin set a=a*2; set b=b*2;end $set @m=10$;set @n=20$;call myp8(@m,@n)$select @m,@n$ 删除语法DROP PROCEDURE 存储过程名 只能一次删一个 查看DESC myp2; 是错误的 SHOW CREATE PROCEDURE myp2; 修改不能修改,只能删除重建 函数一组预先编译好的SQL语句的集合,理解成批处理语句 提高代码重用性 简化操作 减少了编译次数并且减少了和数据库服务器的连接次数,提高了效率 区别存储过程: 可以有0个返回,也可以有多个返回. 适合做批量插入,批量更新 函数: 有且仅有1个返回. 适合做处理数据后返回一个结果 创建语法1234create function 函数名(参数列表) returns 返回类型begin 函数体end 注意: 参数列表 包含两部分: 参数名 参数类型 函数体: 肯定会有return语句,如果没有会报错. 如果return语句没有放在函数体的最后也不报错,但不建议 函数体中仅有一句话,则可以省略begin end 使用delimiter语句设置结束标记 调用语法1select 函数名(参数列表) 案例1234567891011121314151617181920212223242526272829303132333435#1.无参有返回#返回公司的员工个数create funtion myf1() returns intbegin declare c int default 0; #定义变量 select count(*) into c #赋值 from employees; return c;END $select myf1()$#2.有参有返回#案例1: 根据员工名,返回他的工资create function myf2(empName varchar(20)) returns doublebegin set @sal=0; #定义了一个用户变量 select salary into @sal #赋值 from employees where last_name = empName; return @sal;end $select myf2(&#x27;小明&#x27;)$#案例2: 根据部门名,返回该部门的平均工资 create function myf3(deptName varchar(20)) returns doublebegin declare sal double; select avg(salary) into sal from employees e join departments d on e.department_id = d.department_id where d.department_name=deptName; return sal;end $select myf3(&#x27;IT&#x27;)$ 查看函数1show create funtion myf3; 删除函数1drop function myf3; 案例12345678# 创建函数实现传入两个float,返回二者之和create function test_fun1(num1 float,num2 float) returns floatbegin declare mysum float default 0; set mysum=num1+num2; return mysum;end $select test_fun1(1,2)$ 流程控制结构 顺序结构: 程序从上往下依次执行 分支结构: 程序从两条或多条路径中选择一条去执行 循环结构: 程序在满足一定条件的基础上,重复执行一段代码 分支结构if函数功能: 实现简单地双分支 语法: if(表达式1,表达式2,表达式3) 执行顺序: 如果表达式1成立,则if函数返回表达式2的值,否则返回表达式3的值 应用位置: 任何地方 case结构情况1: 类似java中的switch语句,一般用于实现等值判断 情况2: 类似java中的多重if语句,一般用于实现区间判断 特点 可以作为表达式,嵌套在其他语句中使用,可以放在任何地方, BEGIN END中或BEGIN END外面 可以作为独立的语句去使用,只能放在BEGIN END中 如果when中的值满足或条件成立,则执行对应的then后面的语句,并且结束case; 如果都不满足,则执行else中的语句或值 else可以省略,如果else省略了,并且所有的when条件都不满足,则返回null 案例1234567891011#根据传入的成绩来显示等级create procedure test_case(IN score INT)begin case when score&gt;=90 and score&lt;=100 then select &#x27;A&#x27;; when score&gt;=80 then select &#x27;B&#x27;; when score&gt;=60 then select &#x27;C&#x27;; else select &#x27;D&#x27;; end case;end $call test_case(95)$ if结构功能: 实现多重分支 语法: 12345if 条件1 then 语句1;elseif 条件2 then 语句2;...[else 语句n;]end if; 应用位置: begin end中 12345678910#根据传入的成绩来显示等级create function test_if(score int) returns charbegin if score&gt;=90 and score&lt;=100 then return &#x27;A&#x27;; elseif score&gt;=80 then return &#x27;B&#x27;; elseif score&gt;=60 then return &#x27;C&#x27;; else return &#x27;D&#x27;; end if;end $select test_if(86)$ 循环结构分类: while 先判断后执行 loop 没有条件的死循环 repeat 先执行后判断 循环控制: iterate类似于continue,继续,结束本次循环,继续下一次 leave 类似于break, 跳出,结束当前所在的循环 如果添加必须添加标签 while语法123[标签:] while 循环条件 do 循环体;end while [标签]; loop语法1234[标签:] loop 循环体;end loop [标签];#可以用来模拟简单的死循环 repeat语法1234[标签:] repeat 循环体;until 结束循环的条件end repeat [标签]; 案例12345678910111213141516171819202122232425262728293031323334353637383940#批量插入,根据次数插入到admin表中多条记录create procedure pro_while1(in insertCount int)begin declare i int default 1; while i&lt;=insertCount do insert into admin(username,`password`) values(&#x27;Rose&#x27;+i,&#x27;666&#x27;); set i=i+1; end while;end $call pro_while1(100)$#添加leave语句:批量插入,根据次数插入到admin表中多条记录,如果次数&gt;20则停止truncate table admin$drop procedure test_while1$create procedure test_while1(in insertCount int)begin declare i int default 1; a: while i&lt;=insertCount do insert into admin(username,`password`) values(concat(&#x27;xiaoming&#x27;,i),i); if i&gt;=20 then leave a; end if; set i=i+1; end while a;end $call test_while1(100)$#添加iterate语句: 批量插入,根据次数插入到admin表中多条记录,只插入偶数次truncate table admin$drop procedure test_while1$create procedure test_while1(in insertCount int)begin declare i int default 1; a: while i&lt;=insertCount do set i=i+1; if mod(i,2) != 0 then iterate a; end if; insert into admin(username,`password`) values(concat(&#x27;xiaoming&#x27;,i),i); end while a;end $call test_while1(100)$","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://yiiiqing.github.io/tags/Mysql/"}]},{"title":"数据库隔离级别","slug":"数据库隔离级别","date":"2021-04-30T08:35:23.000Z","updated":"2021-04-30T08:38:39.000Z","comments":true,"path":"2021/04/30/数据库隔离级别/","link":"","permalink":"http://yiiiqing.github.io/2021/04/30/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","excerpt":"","text":"数据库隔离级别1 事务事务只是一个改变，是一些的操作集合；用专业的术语去解释，就是一个程序的执行单元；事务本身并不包含这四个特性，我们需要通过某些手段，尽可能让这个执行单元满足这四个特性，那么，我们就可以称它是一个事务，或者说是一个正确的，完美的事务。 2 四特性 原子性：满足原子操作单元，对数据的操作，要么全部执行，要么全部不执行。 一致性：事务开始和完成时，数据都必须保持一致。 隔离性：事务之间相互独立，中间状态对外部不可见。 持久性：数据的修改是永久性的，即使系统出现任何故障都能够保持。 3 隔离级别3.1 并发情况下事务引发的问题 一般情况下，多个单元操作（事务，这里的事务，并不是完美的事务）并发执行，会出现这么几个问题： 脏读：A事务还未提交，B事务就读到了A操作的结果。（破坏了隔离性） 不可重复读：A事务在本次事务中，对自己未操作过数据，进行多次读取，结果出现不一致或记录不存在的情况。（破坏了一致性，重点是update和delete） 幻读：A事务在本次事务中，先读取了一遍数据，发现数据不存在，过了一会，又读取了一遍，发现又有数据了。（破坏了一致性，重点是insert） 3.2 解决（制定标准）为了权衡『隔离』和『并发』的矛盾，ISO定义了4个事务隔离级别，每个级别隔离程度不同，允许出现的副作用也不同。 未提交读（read-uncommitted）：最低级别，基本只保证持久性；会出现脏读，不可重复读，幻读的问题。 已提交读（read-committed）：语句级别；会出现不可重复读，幻读的问题。 可重复读（repeatable-read）：事务级别；只会出现幻读问题。 串行化（serializable）：最高级别，也就是事务与事务完全串行化执行，无并发可言，性能低；但不会出现任何问题。 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncommitted） 会 会 会 不可重复读（read-committed） - 会 会 可重复读（repeatable-read） - - 会 串行化（serializable） - - - 注意：这四个级别只是一个标准，各个数据库厂商，并不完全按照标准做的。 3.2 实现（InnoDB） 锁机制：阻止其他事务对数据进行操作， 各个隔离级别主要体现在读取数据时加的锁的释放时机。 RU：事务读取时不加锁 RC：事务读取时加行级共享锁（读到才加锁），一旦读完，立刻释放（并不是事务结束）。 RR：事务读取时加行级共享锁，直到事务结束时，才会释放。 SE：事务读取时加表级共享锁，直到事务结束时，才会释放。 其他还有一些细节不同，主要就是这些 MVCC机制：生成一个数据快照，并用这个快照来提供一定级别的一致性读取，也称为多版本数据控制。 实际就是『版本控制』加『读写分离』思想，主要用作于RC和RR级别。 这里面就太细了，主要涉及到事务原理和索引，面试问的很少.","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://yiiiqing.github.io/tags/Database/"},{"name":"ACID","slug":"ACID","permalink":"http://yiiiqing.github.io/tags/ACID/"},{"name":"Isolation","slug":"Isolation","permalink":"http://yiiiqing.github.io/tags/Isolation/"}]},{"title":"Shell获取环境变量以及设置默认值","slug":"Shell获取环境变量以及设置默认值","date":"2021-04-30T03:17:40.000Z","updated":"2021-04-30T04:45:12.000Z","comments":true,"path":"2021/04/30/Shell获取环境变量以及设置默认值/","link":"","permalink":"http://yiiiqing.github.io/2021/04/30/Shell%E8%8E%B7%E5%8F%96%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%BB%A5%E5%8F%8A%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E5%80%BC/","excerpt":"","text":"使用参数展开: ${参数：-word}如果参数的展开为unset或null。字被取代了。否则，参数被取代了。 1var=$&#123;DEPLOY_ENV:-default_value&#125; https://www.gnu.org/software/bash/manual/bash.html#Shell-Parameter-Expansion","categories":[],"tags":[]},{"title":"Shell常用时间戳的获取","slug":"Shell常用时间戳的获取","date":"2021-04-29T10:04:57.000Z","updated":"2021-04-29T10:08:59.000Z","comments":true,"path":"2021/04/29/Shell常用时间戳的获取/","link":"","permalink":"http://yiiiqing.github.io/2021/04/29/Shell%E5%B8%B8%E7%94%A8%E6%97%B6%E9%97%B4%E6%88%B3%E7%9A%84%E8%8E%B7%E5%8F%96/","excerpt":"","text":"1、获取当前日期+时间要获取当前日期+时间，返回如1970-01-01 00:00:00则使用如下代码： 1currentTime =`date &quot;+%Y-%m-%d %H:%M:%S&quot;` 输出2019-04-29 09:49:48也可以使用简写： 1currentTime =`date &quot;+%F %T&quot;` 格式可以根据需要修改，如只获取日期： 1currentTime =`date &quot;+%Y-%m-%d&quot;` 只获取时间： 1currentTime =`date &quot;+%H:%M:%S&quot;` 2、获取1970-01-01 00:00:00到当前时间的秒数获取当前时间的秒数如1556503057： 1cur_sec=`date &#x27;+%s&#x27;` 输出:1556503057 3、获取1970-01-01 00:00:00到当前时间的纳秒 1cur_ns=`date &#x27;+%N&#x27;` 输出：903987355 4、获取当前时间的纳秒级时间戳 1cur_timestamp=$((`date &#x27;+%s&#x27;`*1000+`date &#x27;+%N&#x27;`/1000000)) 输出:1556503676106 5、获取某个时间的秒数 1date -d &quot;2010-10-18 00:00:00&quot; +%s 输出:1287331200 6、将时间戳转换为时间 1date -d @1287331200 输出:Mon Oct 18 00:00:00 CST 2010如果想将其转换为形如2010-10-18 00:00:00的格式则使用如下方式： 1date -d &quot;1970-01-01 UTC 1287331200 seconds&quot; &quot;+%F %T&quot; 7、format格式说明表如下格式 说明%% %的转义%a 当地星期几的缩写，例如Sun、日%A 当地星期几的全称，例如Sunday、星期二%b 当地月份的缩写，例如Jan、12月%B 当地月份的全称，例如January、十二月%c 当地日期和时间，例如Thu Mar 3 23:05:25 2005，2018年12月18日 星期二 15时46分23秒%C 输出世纪，例如现在是2%d 当前月份的第几天，例如18（2018-12-18）%D 日期，格式与%m%d%y，年为两位数，例如12/18/18%e 当前月份的第几天，例如08（2018-12-08）%F 完整格式的日期，与%Y-%m-%d相同，例如2018-12-18%g 年份中的后两位数，例如18%G 年%h 与%b一样%H 小时（00…23）,即24小时制%I 小时（01…12），即12小时制%j 一年中的第几天（001…366）%k 小时（1…23）%l 小时（1…12）%m 月份（01…12）%M 分钟（01…59）%n 新行%N 纳秒（000000000…999999999）%p 当地上午或下午，例如PM、下午%P 当地上午或下午（小写），例如pm、下午%q 第几季度（1…4）%r 当地12小时制的时间格式，例如下午 04时06分24秒%R 24小时制的时分（%H:%M），例如16:07%s 从1970-01-01 00:00:00 UTC到现在的秒数%S 当前分钟的秒数（00…59）%T 等价%H:%M:%S，时分秒%u 从星期一开始数，一周中的第几天（1…7）%U 从星期日开始数，一年中的第几周（00…53）%V ISO周数，从周一开始数（01…53）%w 从周日开始数，一周中的第几天（0…6）%W 从星期一开始数，一年中的第几周（00…53）%x 当地日期，例如2018年12月18日%X 当地时间，例如16时16分17秒%y 年份的后两位数（00…99）%Y 年份%z 时区，+hhmm，例如东八区+0800%? 时区，+hh::mm，例如东八区+08:00%:? 时区，+hh::mm:ss，例如东八区+08:00:00%Z 时区的缩写，例如东八区CST 原文链接：https://blog.csdn.net/df0128/article/details/89669834","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://yiiiqing.github.io/tags/Shell/"}]},{"title":"计算两个经纬度之间的距离","slug":"计算两个经纬度之间的距离","date":"2021-04-26T08:49:01.000Z","updated":"2021-06-23T14:51:13.000Z","comments":true,"path":"2021/04/26/计算两个经纬度之间的距离/","link":"","permalink":"http://yiiiqing.github.io/2021/04/26/%E8%AE%A1%E7%AE%97%E4%B8%A4%E4%B8%AA%E7%BB%8F%E7%BA%AC%E5%BA%A6%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB/","excerpt":"","text":"js123456789101112131415161718192021222324252627282930const EARCH_RADIUS = 6378.137; // 地球半径/** * 将角度换算成弧度 * @param &#123;number&#125; d * @returns */function rad(d)&#123; return d * Math.PI / 180.0;&#125;/** * 获取两个经纬度之间的距离 * @param &#123;number&#125; lat1 * @param &#123;number&#125; lng1 * @param &#123;number&#125; lat2 * @param &#123;number&#125; lng2 * @returns &#123;number&#125; 单位是千米 */function getDistance(lat1,lng1,lat2,lng2)&#123; let radLat1 = rad(lat1) let radLat2 = rad(lat2) let a = radLat1 - radLat2; let b = rad(lng1) - rad(lng2); let s = 2 * Math.asin(Math.sqrt(Math.pow(Math.sin(a/2),2) + Math.cos(radLat1) * Math.cos(radLat2) * Math.pow(Math.sin(b/2),2) )); s = s * EARCH_RADIUS; return s;&#125; java123456789101112131415161718192021222324252627private static final double EARTH_RADIUS = 6378.137;// 地球半径,单位千米//将角度换算成弧度private static double rad(double d) &#123; return d * Math.PI / 180.0;&#125;/*** 用来比较是否在规定考勤范围* @param lat1第一个纬度* @param lng1第一个经度* @param lat2第二个纬度* @param lng2第二个经度* @return 两个经纬度的距离（km）*/public static double getDistance(double lat1, double lng1, double lat2,double lng2) &#123; double radLat1 = rad(lat1); double radLat2 = rad(lat2); double a = radLat1 - radLat2; double b = rad(lng1) - rad(lng2); double s = 2 * Math.asin(Math.sqrt(Math.pow(Math.sin(a / 2), 2) + Math.cos(radLat1) * Math.cos(radLat2) * Math.pow(Math.sin(b / 2), 2))); s = s * EARTH_RADIUS; //此处加上double类型转换是因为对于在几百的距离差值之前计算为0，无法达到预期效果 s = (double)Math.round(s * 10000) / 10000; s = s * 10000/ 10000; return s;&#125;","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/tags/JavaScript/"}]},{"title":"Nginx学习手册","slug":"Nginx学习手册","date":"2021-04-21T07:04:21.000Z","updated":"2021-06-23T14:50:57.000Z","comments":true,"path":"2021/04/21/Nginx学习手册/","link":"","permalink":"http://yiiiqing.github.io/2021/04/21/Nginx%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/","excerpt":"","text":"Nginx学习手册概述 Nginx (engine x) 是一个高性能的HTTP和反向代理服务器,特点是占有内存少,并发能力强. Nginx可以作为静态页面的web服务器,同时还支持CGI协议的动态语言,比如perl,php等. 但是不支持java. java程序智能通过与tomcat配合完成 Nginx专为性能优化开发,性能是其最重要的考量,实现上非常注重效率,能经受高负载的考验,报告表明能支持50000个并发连接数 正向代理如果把局域网外的Internet想象成一个巨大的资源库,则局域网中的客户端要访问Internet,则需要通过代理服务器来访问,这种代理服务就称为正向代理 反向代理反向代理,其实客户端对代理是无感知的.因为客户端不需要任何配置就可以访问,我们只需要将请求发送到反向代理服务器,由反向代理服务器去选择目标服务器获取数据后,再返回客户端,此时反向代理服务器和目标服务器对外就是一个服务器,暴露的是代理服务器地址,隐藏了真实服务器IP地址 负载均衡单个服务器解决不了性能问题, 所以我们增加服务器的数量,然后将请求分发到各个服务器上,将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上,将负载分发到不同的服务器,也就是我们所说的负载均衡. 动静分离为了加快网页的解析速度,可以把动态页面和静态页面由不同的服务器来解析,加快解析速度.降低原来单个服务器的压力 安装(centOS8) 在nginx官网下载安装包上传至服务器 安装依赖 pcre: yum -y install gcc gcc-c++ autoconf make 安装openssl,zlib: yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 一键安装: yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel 解压nginx包 进入解压之后的包中执行./configure make &amp;&amp; make install 检查/usr/local是否有nginx文件夹,有则表明安装成功 在nginx文件夹里,有sbin文件夹,进入文件夹,执行./nginx 查看进程ps -ef | grep nginx 访问80端口,可以查看到网页 常用命令前提: 进入到目录中 cd /usr/local/nginx/sbin 查看版本号./nginx -v 启动nginx./nginx 关闭nginx./nginx -s stop 重新加载nginx一般用于修改了nginx.conf配置文件后,无需重启服务器,重新加载 ./nginx -s reload nginx配置文件 配置文件位置 /usr/local/nginx/conf/nginx.conf 配置文件组成 全局块 从配置文件开始到events块之间的内容,主要会设置一些影响nginx服务器整体运行的配置指令,主要包括 配置运行nginx服务器的用户(组) 允许生成的worker process数 worker_processes越大,可以支持的并发处理量也就越多 进程PID存放路径 日志存放路径,类型 配置文件的引入 events块 主要影响nginx服务器与用户的网络连接 常用的设置包括是否开启对多work process下的网络连接进行序列化,是否允许同时接受多个网络连接,选取哪种时间驱动模型来处理连接请求,每个work process可以同时支持的最大连接数等 events &#123; worker_connections 1024; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 * http块 * 配置最频繁的部分 * 代理,缓存,日志等绝大多数功能和第三方模块配置 * 分为http全局块和server块 * http全局块 * 指令包括文件引入,MIME-TYPE定义,日志自定义,连接超时时间,单链接请求数上限等 * server块 * 这块和虚拟主机有密切的关系. 虚拟主机从用户角度看,和一太独立的硬件主机是完全一样的, 该技术的产生是为了节省互联网服务器硬件成本 * 每个http块可以包括多个server块,每个server块就相当于一个虚拟主机 * 每个server块也分为全局server块,以及可以同时包含多个location块 * 全局server块 * 最常见的配置是本虚拟机的监听配置和本虚拟主机的名称或IP配置 * location块 * 一个server可以配置多个location块 * 这块的作用是基于nginx服务器接受到的请求字符串,对虚拟主机名称之外的字符串进行匹配,对特定的请求进行处理. * 地址定向,数据缓存,应答控制还有诸多第三方模块的配置也在这里 ## 配置实例### 反向代理#### 案例一##### 实现效果打开浏览器,在地址栏输入地址www.123.com,跳转到linux系统tomcat主页面##### 实现1. 服务器安装并启动tomcat, 在bin目录中,./startup.sh启动2. 对外开放访问的端口: 1. ```firewall-com --add-port=8080/tcp --permanent``` 2. ```firewall-cmd -reload``` 3. 查看已开放的端口号: ```firewall-cmd --list-all```3. 将www.123.com加入hosts,对应80端口4. 在nginx中进行反向代理配置 ```conf server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; proxy_pass http://127.0.0.1:8080; index index.html index.htm; &#125; 访问可以看到已经生效 案例二实现效果访问http://127.0.0.1:9001/edu/ 直接跳转到127.0.0.1:8080/ 访问http://127.0.0.1:9001/vod/ 直接跳转到127.0.0.1:8082/ 实现 安装两个tomcat,在server.xml中修改启动端口号和connector中端口号即可 反向代理配置 ~ 表示使用正则表达式 1234567891011server &#123; listen 9001; server_name localhost; location ~ /edu/ &#123; proxy_pass http://localhost:8001; &#125; location ~ /vod/ &#123; proxy_pass http://localhost:8002; &#125;&#125; 开放对外访问的端口号 重启或重新加载nginx location指令说明 该指令用于匹配URL 语法: 123location [ = | ~ | ~* | ^~] uri &#123;&#125; 说明 = 用于不含正则表达式的uri前,要求请求字符串于uri严格匹配,如果匹配成功,就停止继续向下搜索并立即处理该请求 ~ 用于表示uri包含正则表达式,并且区分大小写 ~* 用于表示uri包含正则表达式,并且不区分大小写 ^~ 用于不含正则表达式的uri前,要求nginx服务器找到表示uri和请求字符串匹配度最高的location之后,立即使用此location处理请求,而不在用location块中的正则uri和请求字符串做匹配 注意: 如果uri包含正则表达式,则必须要有或者*标识 负载均衡实现效果浏览器输入地址http:xxx/edu/a.html, 负载均衡效果,平均请求到8080和8081中 实现 准备两台tomcat服务器,一台8080,一台8081 在两台tomcaat里面的webapps目录中,创建名称为edu的文件夹,在文件夹中创建a.html文件 在nginx配置文件中配置负载均衡 12345678910111213141516171819upstream myserver&#123; server localhost:8080; server localhost:8081;&#125;server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; proxy_pass http://myserver; index index.html index.htm; &#125; ...&#125; nginx分配服务器策略 轮训 每个请求按时间顺序逐一分配到不同的后端服务器,如果后端服务器down掉,能自动剔除 weight 权重 weight代表权重,默认为1,权重越高,分配的客户端越多 1234upstream myserver&#123; server localhost:8080 weight=10; server localhost:8081 weight=10;&#125; ip_hash 每个请求按访问的ip的hash结果分配,这样每个访客固定访问一个后端服务器 可以解决session的问题. 12345upstream myserver&#123; ip_hash server localhost:8080; server localhost:8081;&#125; fair 第三方 按照后端服务的响应时间来分配,响应时间短的优先分配 12345upstream myserver&#123; server localhost:8080; server localhost:8081; fair&#125; 动静分离动静分离简单来说就是把动态跟静态请求分开,从目前实现角度来讲大致分为两种 纯粹把静态文件独立成单独的域名,放在单独的服务器上,也是目前主流推崇的方案 动态和静态文件混合在一起发布,通过nginx来分开 通过location设置不同的后缀名来实现不同的请求转发. 通过expires参数设置,可以设置浏览器缓存过期时间,减少与服务器之间的请求和流量. 比如这里设置3d,表示3天之内访问这个URL,发送一个请求,比对服务器该文件最后更新时间有没有变化. 没有变化则不会从服务器抓取,返回状态码304 如果有修改,则直接从服务器重新下载,返回状态码200. 配置 在linux中准备静态资源 image文件夹中有一张图片 www文件夹中有一个网页 在nginx配置文件中进行 123456789101112131415161718server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /www/ &#123; root /data/; index index.html index.htm; &#125; location /image/ &#123; root /data/; autoindex on; &#125; ...&#125; 打开网页xxx/image/可以看到 高可用步骤 需要两台nginx服务器 可以使用docker开两个端口 docker run --privileged -itd -p mycentos:1.5 /usr/sbin/init 在docker的centos上使用yum安装nginx 使用whereis nginx查看目录 修改index.html以区分服务器 在/usr/share/nginx中修改 &lt;h1&gt;Welcome to &lt;strong&gt;MASTER&lt;strong&gt;nginx&lt;/strong&gt; on Red Hat Enterprise Linux!&lt;/h1&gt; 1234567891011121314151617181920 5. yum安装的nginx配置文件在/etc/nginx中 &gt; 以下是Nginx的默认路径： &gt; (1) Nginx配置路径：/etc/nginx/ &gt; (2) PID目录：/var/run/nginx.pid &gt; (3) 错误日志：/var/log/nginx/error.log &gt; (4) 访问日志：/var/log/nginx/access.log &gt; (5) 默认站点目录：/usr/share/nginx/html &gt; &gt; 事实上，只需知道Nginx配置路径，其他路径均可在`/etc/nginx/nginx.conf` 以及`/etc/nginx/conf.d/default.conf` 中查询到。 6. 使用```systemctl start nginx```启动,```systemctl status nginx```,```systemctl restart nginx``` 2. 需要keepalived 1. ```yum install keepalived -y``` 2. 安装之后,在etc里面生成目录keepalived,有文件keepalived.conf配置文件 ! Configuration File for keepalived global_defs { smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_script chk__http_port { script &quot;/usr/local/src/nginx_check.sh&quot; interval 2 #(check sh) weight 2 }vrrp_instance VI_1 { state MASTER interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.17.0.200 &#125; } 1234567891011121314153. 配置文件中的脚本,检测nginx是否运行 1. 如果没有nginx,keepalived服务关闭 ```bash #!/bin/bash A=`ps -C nginx -no-header | wx -l` if [ $A -eq 0];then /usr/local/nginx/sbin/nginx sleep 2 if [`ps -C nginx --no-header | wc -l` -eq 0 ];then killall keepalived fi fi 查看是否已经绑定虚拟ip: ip a 启动 systeml start nginx systeml start keepalived 进入测试docker使用curl命令测试虚拟ipcurl 172.17.0.200 发现是MASTER 模拟关闭主节点: 关闭keepalived: systemctl stop keepalived 进入测试docker使用curl命令测试虚拟ipcurl 172.17.0.200 发现变成了BACKUP 成功! keepalive配置文件 global_defs 全局 主要关注router_id 后面加主机名 vrrp_script 脚本 脚本运行 script 脚本路径 intervel 间隔时间 weight -20 权重 vrrp_instance VI_1 虚拟ip state 主机名 interface 网卡 virtual_touter_id 标识,主备机的virtual router id必须相同 priority 主备机取不同的优先级,主机值较大,备份机较小 advert_int 1 心跳时间间隔 authentication 权限校验方式 virtual_ipaddress VRRP H 虚拟地址(重要) nginx原理master&amp;worker使用ps -ef | grep nginx可以看到 一个master可以有多个worker worker如何工作的 当客户端发送请求到nginx服务器,首先到master master发送信号到worker 然后各个worker采用争抢的方式争抢请求 好处 可以使用nginx -s reload热部署 对于每个worker进程来说,独立的进程,不需要加锁,所以省掉了锁带来的开销 worker互相不影响,一个退出了其他还在工作,服务不会中断,master会启动新的worker进程 需要多少个worker?nginx和redis类似都采用了io多路复用机制.每个worker都是一个独立的进程,但每个进程里只有一个主线程,通过异步非阻塞方式来处理请求,即使是千万个请求也不在话下. 每个worker可以把一个cpu的性能发挥到极致.所以,worker数和服务器的cpu数相等是最为适宜的.设置少了会浪费cpu,设置多了会造成cpu频繁切换上下文带来损耗 worker_connection 连接数 发送一个请求,占用了worker的几个连接数呢? 2或者4.和客户端相连的两个(发和收),访问静态资源时候是两个.如果使用tomcat访问数据库,还要与tomcat多两个连接,所以一共四个 nginx有一个master,四个worker,每个worker最大连接数1024,支持的最大并发数是多少? 普通静态资源: worker_connections * worker_processes / 2 如果是http作为反向代理来说: worker_connections * worker_processes / 4","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yiiiqing.github.io/tags/Nginx/"}]},{"title":"JavaScript-比较两个对象值是否相等","slug":"JavaScript-比较两个对象值是否相等","date":"2021-03-30T11:12:38.000Z","updated":"2021-03-30T11:13:36.000Z","comments":true,"path":"2021/03/30/JavaScript-比较两个对象值是否相等/","link":"","permalink":"http://yiiiqing.github.io/2021/03/30/JavaScript-%E6%AF%94%E8%BE%83%E4%B8%A4%E4%B8%AA%E5%AF%B9%E8%B1%A1%E5%80%BC%E6%98%AF%E5%90%A6%E7%9B%B8%E7%AD%89/","excerpt":"","text":"12345678910111213141516171819202122232425/* * @param x &#123;Object&#125; 对象1 * @param y &#123;Object&#125; 对象2 * @return &#123;Boolean&#125; true 为相等，false 为不等 */export const deepEqual = (x, y) =&gt; &#123; // 指向同一内存时 if (x === y) &#123; return true; &#125; else if ((typeof x == &quot;object&quot; &amp;&amp; x != null) &amp;&amp; (typeof y == &quot;object&quot; &amp;&amp; y != null)) &#123; if (Object.keys(x).length !== Object.keys(y).length) &#123; return false; &#125; for (var prop in x) &#123; if (y.hasOwnProperty(prop)) &#123; if (!deepEqual(x[prop], y[prop])) return false; &#125; else &#123; return false; &#125; &#125; return true; &#125; else &#123; return false; &#125;&#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/tags/JavaScript/"}]},{"title":"CAP理论","slug":"CAP理论","date":"2021-03-26T02:35:00.000Z","updated":"2021-06-23T14:50:24.000Z","comments":true,"path":"2021/03/26/CAP理论/","link":"","permalink":"http://yiiiqing.github.io/2021/03/26/CAP%E7%90%86%E8%AE%BA/","excerpt":"","text":"CAP理论CAP C: Consistency 强一致性 一致性指“all nodes see the same data at the same time”，即所有节点在同一时间的数据完全一致。 一致性是因为多个数据拷贝下并发读写才有的问题，因此理解时一定要注意结合考虑多个数据拷贝下并发读写的场景。 A: Availability 可用性 可用性指“Reads and writes always succeed”，即服务在正常响应时间内一直可用。 好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。可用性通常情况下可用性和分布式数据冗余，负载均衡等有着很大的关联。 P: Partition tolerance 分区容错性 分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。 CAP理论关注粒度是数据 CAP图最多只能同时较好的满足两个 CAP理论核心: 一个分布式系统不可能同时很好的满足一致性,可用性和分区容错性这三个需求. 因此,根据CAP原理将NoSQL数据库分成了满足CA原则,满足CP原则和满足AP原则三大类: CA: 单点集群,满足一致性,可用性的系统,通常在可扩展性上不太强大 CP: 满足一致性,分区容忍性的系统,通常性能不是特别高 AP: 满足可用性,分区容忍性的系统,通常可能对一致性要求低一点 通过 CAP 理论，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？ CA without P：如果不要求 P（不允许分区），则 C（强一致性）和 A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此 CA 的系统更多的是允许分区后各子系统依然保持 CA。 CP without A：如果不要求 A（可用），相当于每个请求都需要在 Server 之间强一致，而 P（分区）会导致同步时间无限延长，如此 CP 也是可以保证的。很多传统的数据库分布式事务都属于这种模式。 AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的 NoSQL 都属于此类。 对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到 N 个 9，即保证 P 和 A，舍弃 C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。 对于涉及到钱财这样不能有一丝让步的场景，C 必须保证。网络发生故障宁可停止服务，这是保证 CA，舍弃 P。貌似这几年国内银行业发生了不下 10 起事故，但影响面不大，报道也不多，广大群众知道的少。还有一种是保证 CP，舍弃 A。例如网络故障事只读不写。 孰优孰略，没有定论，只能根据场景定夺，适合的才是最好的。 参考文章: https://zhuanlan.zhihu.com/p/33999708","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"CAP","slug":"CAP","permalink":"http://yiiiqing.github.io/tags/CAP/"}]},{"title":"Sequelize设置时间默认值和获取格式","slug":"Sequelize设置时间默认值和获取格式","date":"2021-03-23T06:23:26.000Z","updated":"2021-03-23T06:23:43.000Z","comments":true,"path":"2021/03/23/Sequelize设置时间默认值和获取格式/","link":"","permalink":"http://yiiiqing.github.io/2021/03/23/Sequelize%E8%AE%BE%E7%BD%AE%E6%97%B6%E9%97%B4%E9%BB%98%E8%AE%A4%E5%80%BC%E5%92%8C%E8%8E%B7%E5%8F%96%E6%A0%BC%E5%BC%8F/","excerpt":"","text":"1234567timestamp: &#123; type: DataTypes.DATE, allowNull: false, defaultValue: sequelize.literal(&#x27;CURRENT_TIMESTAMP&#x27;), get() &#123; return moment(this.getDataValue(&#x27;timestamp&#x27;)).format(&#x27;YYYY-MM-DD HH:mm:ss&#x27;); &#125;","categories":[],"tags":[]},{"title":"centos8安装zookeeper","slug":"centos8安装zookeeper","date":"2021-03-23T03:56:52.000Z","updated":"2021-03-24T03:27:03.000Z","comments":true,"path":"2021/03/23/centos8安装zookeeper/","link":"","permalink":"http://yiiiqing.github.io/2021/03/23/centos8%E5%AE%89%E8%A3%85zookeeper/","excerpt":"","text":"CentOS8安装Zookeeper步骤在官网下载安装包https://downloads.apache.org/zookeeper/stable/ 注意要下载带bin的,不带bin的是源码包,不能使用 上传到centos系统中服务器使用scp命令,由于我是本地docker环境,直接使用docker命令 docker cp Downloads/apache-zookeeper-3.5.9-bin.tar.gz CONTAINER ID:PATH 解压1tar -zxvf apache-zookeeper-3.5.9-bin.tar.gz -C /usr/local/zookeeper/ 这里是解压到了/usr/local目录下(可能需要先创建目录) 修改名称为zookeeper-3.5.9 mv apache-zookeeper-3.5.9-bin/ zookeeper-3.5.9 创建数据和日志存放目录12mkdir /usr/local/zookeeper/zookeeper-3.5.9/logsmkdir /usr/local/zookeeper/zookeeper-3.5.9/data 打开目录1cd /usr/local/zookeeper/zookeeper-3.5.9/ 修改cfg文件 先备份 1234cd confcp zoo_sample.cfg zoo_sample.cfg.bakmv zoo_sample.cfg zoo.cfgvim zoo.cfg vim文件 1234567891011121314#ZK中的一个时间单元。ZK中所有时间都是以这个时间单元为基础，进行整数倍配置的。例如，session的最小超时时间是2*tickTimetickTime=2000#Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许F在 initLimit 时间内完成这个工作。通常情况下，我们不用太在意这个参数的设置。如果ZK集群的数据量确实很大了，F在启动的时候，从Leader上同步数据的时间也会相应变长，因此在这种情况下，有必要适当调大这个参数了initLimit=10#在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那里收到响应，那么就认为这个F已经不在线了。注意：不要把这个参数设置得过大，否则可能会掩盖一些问题syncLimit=5#存储快照文件snapshot的目录。默认情况下，事务日志也会存储在这里。建议同时配置参数dataLogDir, 事务日志的写性能直接影响zk性能dataDir=/usr/local/zookeeper/zookeeper-3.5.9/data#事务日志输出目录。尽量给事务日志的输出配置单独的磁盘或是挂载点，这将极大的提升ZK性能dataLogDir=/usr/local/zookeeper/zookeeper-3.5.9/logs#客户端连接server的端口，即对外服务端口，一般设置为2181吧clientPort=2181#第一个端口用于F和L之间的数据同步和其它通信，第二个端口用于Leader选举过程中投票通信，server.x这里的x是一个数字，与myid文件中的id是一致的server.1=127.0.0.1:2888:3888 在data目录下创建myid文件,写入对应ip的机器编号12cd /usr/local/zookeeper/zookeeper-3.5.9/datavim myid 配置zk的环境变量vim ~/.bash_profile 在后面添加 12345# Zookeeperexport ZOOKEEPER_HOME=/usr/local/zookeeper/zookeeper-3.5.9/PATH=$ZOOKEEPER_HOME/bin:$PATHexport PATH 使其生效 source ~/.bash_profile 启动1234# 启动zkServer.sh start# 关闭zkServer.sh stop 注意: 需要jdk环境 如果启动失败 可以进入logs文件查看原因 可以使用zkServer.sh start-foreground命令 配置自启动进入/etc/init.d目录下,创建脚本12345cd /etc/init.d/ touch zookeeperchmod +x zookeeper#编辑vim zookeeper 123456789101112#!/bin/bash#chkconfig:2345 20 90#description:zookeeper#processname:zookeeperJAVA_HOME=/usr/local/jdk/jdk1.8.0_281 #实测必须要加这一行,不然尽管配置了也找不到case $1 in start) su root /usr/local/zookeeper/zookeeper-3.5.9/bin/zkServer.sh start;; stop) su root /usr/local/zookeeper/zookeeper-3.5.9/bin/zkServer.sh stop;; status) su root /usr/local/zookeeper/zookeeper-3.5.9/bin/zkServer.sh status;; restart) su root /usr/local/zookeeper/zookeeper-3.5.9/bin/zkServer.sh restart;; *) echo &quot;require start|stop|status|restart&quot; ;;esac 注意需要配置JAVA_HOME, 尽管centos配置后依然找不到 注册到系统服务chkconfig --add zookeeper 删除: chkconfig --del zookeeper 添加到开机自启动chkconfig zookeeper on chkconfig zookeeper off 验证service zookeeper status 如果没有service指令,yum install initscripts 连接zkCli.sh -server 127.0.0.1:2181","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://yiiiqing.github.io/tags/Zookeeper/"},{"name":"CentOS","slug":"CentOS","permalink":"http://yiiiqing.github.io/tags/CentOS/"}]},{"title":"SpringBoot-热部署Devtools","slug":"SpringBoot-热部署Devtools","date":"2021-03-20T07:00:44.000Z","updated":"2021-03-22T05:28:06.000Z","comments":true,"path":"2021/03/20/SpringBoot-热部署Devtools/","link":"","permalink":"http://yiiiqing.github.io/2021/03/20/SpringBoot-%E7%83%AD%E9%83%A8%E7%BD%B2Devtools/","excerpt":"","text":"步骤 Adding devtools to your project 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; Adding plugin to your pom.xml 12345678910111213&lt;!--热启动插件--&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Enabling automatic build Update the value of win: ctrl+shift+Alt+/ and search for the registry Mac: option+command+shift+/ In registry, check restart IDEA","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"Devtools","slug":"Devtools","permalink":"http://yiiiqing.github.io/tags/Devtools/"}]},{"title":"SpringCloud版本选型","slug":"SpringCloud版本选型","date":"2021-03-19T03:08:40.000Z","updated":"2021-03-19T03:17:06.000Z","comments":true,"path":"2021/03/19/SpringCloud版本选型/","link":"","permalink":"http://yiiiqing.github.io/2021/03/19/SpringCloud%E7%89%88%E6%9C%AC%E9%80%89%E5%9E%8B/","excerpt":"","text":"根据相关网站选型https://spring.io/projects/spring-cloud https://start.spring.io/actuator/info https://docs.spring.io/spring-cloud/docs/current/reference/html/ 原则 之用boot,直接用最新 同时用boot和cloud,需要照顾cloud,由cloud来决定boot版本 个人使用 服务 版本 cloud Hoxton.SR1 boot 2.2.2.RELEASE cloud alibaba 2.1.0.RELEASE Java 8 Maven 3.5+ Mysql 5.7+","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://yiiiqing.github.io/tags/SpringCloud/"}]},{"title":"Redis-redis.config","slug":"Redis-redis-config","date":"2021-03-18T08:05:35.000Z","updated":"2021-03-18T08:13:58.000Z","comments":true,"path":"2021/03/18/Redis-redis-config/","link":"","permalink":"http://yiiiqing.github.io/2021/03/18/Redis-redis-config/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426# Redis配置文件样例# Note on units: when memory size is needed, it is possible to specifiy# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same.# Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程# 启用守护进程后，Redis会把pid写到一个pidfile中，在/var/run/redis.piddaemonize no# 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定pidfile /var/run/redis.pid# 指定Redis监听端口，默认端口为6379# 如果指定0端口，表示Redis不监听TCP连接port 6379# 绑定的主机地址# 你可以绑定单一接口，如果没有绑定，所有接口都会监听到来的连接# bind 127.0.0.1# Specify the path for the unix socket that will be used to listen for# incoming connections. There is no default, so Redis will not listen# on a unix socket when not specified.## unixsocket /tmp/redis.sock# unixsocketperm 755# 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能timeout 0# 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose# debug (很多信息, 对开发／测试比较有用)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel verbose# 日志记录方式，默认为标准输出，如果配置为redis为守护进程方式运行，而这里又配置为标准输出，则日志将会发送给/dev/nulllogfile stdout# To enable logging to the system logger, just set &#x27;syslog-enabled&#x27; to yes,# and optionally update the other syslog parameters to suit your needs.# syslog-enabled no# Specify the syslog identity.# syslog-ident redis# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.# syslog-facility local0# 设置数据库的数量，默认数据库为0，可以使用select &lt;dbid&gt;命令在连接上指定数据库id# dbid是从0到‘databases’-1的数目databases 16################################ SNAPSHOTTING ################################## 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合# Save the DB on disk:## save &lt;seconds&gt; &lt;changes&gt;## Will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## 满足以下条件将会同步数据:# 900秒（15分钟）内有1个更改# 300秒（5分钟）内有10个更改# 60秒内有10000个更改# Note: 可以把所有“save”行注释掉，这样就取消同步操作了save 900 1save 300 10save 60 10000# 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大rdbcompression yes# 指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb# 工作目录.# 指定本地数据库存放目录，文件名由上一个dbfilename配置项指定# # Also the Append Only File will be created inside this directory.# # 注意，这里只能指定一个目录，不能指定文件名dir ./################################# REPLICATION ################################## 主从复制。使用slaveof从 Redis服务器复制一个Redis实例。注意，该配置仅限于当前slave有效# so for example it is possible to configure the slave to save the DB with a# different interval, or to listen to another port, and so on.# 设置当本机为slav服务时，设置master服务的ip地址及端口，在Redis启动时，它会自动从master进行数据同步# slaveof &lt;masterip&gt; &lt;masterport&gt;# 当master服务设置了密码保护时，slav服务连接master的密码# 下文的“requirepass”配置项可以指定密码# masterauth &lt;master-password&gt;# When a slave lost the connection with the master, or when the replication# is still in progress, the slave can act in two different ways:## 1) if slave-serve-stale-data is set to &#x27;yes&#x27; (the default) the slave will# still reply to client requests, possibly with out of data data, or the# data set may just be empty if this is the first synchronization.## 2) if slave-serve-stale data is set to &#x27;no&#x27; the slave will reply with# an error &quot;SYNC with master in progress&quot; to all the kind of commands# but to INFO and SLAVEOF.#slave-serve-stale-data yes# Slaves send PINGs to server in a predefined interval. It&#x27;s possible to change# this interval with the repl_ping_slave_period option. The default value is 10# seconds.## repl-ping-slave-period 10# The following option sets a timeout for both Bulk transfer I/O timeout and# master data or ping response timeout. The default value is 60 seconds.## It is important to make sure that this value is greater than the value# specified for repl-ping-slave-period otherwise a timeout will be detected# every time there is low traffic between the master and the slave.## repl-timeout 60################################## SECURITY #################################### Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.# 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过auth &lt;password&gt;命令提供密码，默认关闭# requirepass foobared# Command renaming.## It is possilbe to change the name of dangerous commands in a shared# environment. For instance the CONFIG command may be renamed into something# of hard to guess so that it will be still available for internal-use# tools but not available for general clients.## Example:## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52## It is also possilbe to completely kill a command renaming it into# an empty string:## rename-command CONFIG &quot;&quot;################################### LIMITS ##################################### 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，# 如果设置maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max Number of clients reached错误信息# maxclients 128# Don&#x27;t use more memory than the specified amount of bytes.# When the memory limit is reached Redis will try to remove keys with an# EXPIRE set. It will try to start freeing keys that are going to expire# in little time and preserve keys with a longer time to live.# Redis will also try to remove objects from free lists if possible.## If all this fails, Redis will start to reply with errors to commands# that will use more memory, like SET, LPUSH, and so on, and will continue# to reply to most read-only commands like GET.## WARNING: maxmemory can be a good idea mainly if you want to use Redis as a# &#x27;state&#x27; server or cache, not as a real DB. When Redis is used as a real# database the memory usage will grow over the weeks, it will be obvious if# it is going to use too much memory in the long run, and you&#x27;ll have the time# to upgrade. With maxmemory after the limit is reached you&#x27;ll start to get# errors for write operations, and this may even lead to DB inconsistency.# 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，# 当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。# Redis新的vm机制，会把Key存放内存，Value会存放在swap区# maxmemory &lt;bytes&gt;# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached? You can select among five behavior:# # volatile-lru -&gt; remove the key with an expire set using an LRU algorithm# allkeys-lru -&gt; remove any key accordingly to the LRU algorithm# volatile-random -&gt; remove a random key with an expire set# allkeys-&gt;random -&gt; remove a random key, any key# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)# noeviction -&gt; don&#x27;t expire at all, just return an error on write operations# # Note: with all the kind of policies, Redis will return an error on write# operations, when there are not suitable keys for eviction.## At the date of writing this commands are: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## The default is:## maxmemory-policy volatile-lru# LRU and minimal TTL algorithms are not precise algorithms but approximated# algorithms (in order to save memory), so you can select as well the sample# size to check. For instance for default Redis will check three keys and# pick the one that was used less recently, you can change the sample size# using the following configuration directive.## maxmemory-samples 3############################## APPEND ONLY MODE ################################ # Note that you can have both the async dumps and the append only file if you# like (you have to comment the &quot;save&quot; statements above to disable the dumps).# Still if append only mode is enabled Redis will load the data from the# log file at startup ignoring the dump.rdb file.# 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。# 因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no# IMPORTANT: Check the BGREWRITEAOF to check how to rewrite the append# log file in background when it gets too big.appendonly no# 指定更新日志文件名，默认为appendonly.aof# appendfilename appendonly.aof# The fsync() call tells the Operating System to actually write data on disk# instead to wait for more data in the output buffer. Some OS will really flush # data on disk, some other OS will just try to do it ASAP.# 指定更新日志条件，共有3个可选值：# no:表示等操作系统进行数据缓存同步到磁盘（快）# always:表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）# everysec:表示每秒同步一次（折衷，默认值）appendfsync everysec# appendfsync no# When the AOF fsync policy is set to always or everysec, and a background# saving process (a background save or AOF log background rewriting) is# performing a lot of I/O against the disk, in some Linux configurations# Redis may block too long on the fsync() call. Note that there is no fix for# this currently, as even performing fsync in a different thread will block# our synchronous write(2) call.## In order to mitigate this problem it&#x27;s possible to use the following option# that will prevent fsync() from being called in the main process while a# BGSAVE or BGREWRITEAOF is in progress.## This means that while another child is saving the durability of Redis is# the same as &quot;appendfsync none&quot;, that in pratical terms means that it is# possible to lost up to 30 seconds of log in the worst scenario (with the# default Linux settings).# # If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as# &quot;no&quot; that is the safest pick from the point of view of durability.no-appendfsync-on-rewrite no# Automatic rewrite of the append only file.# Redis is able to automatically rewrite the log file implicitly calling# BGREWRITEAOF when the AOF log size will growth by the specified percentage.# # This is how it works: Redis remembers the size of the AOF file after the# latest rewrite (or if no rewrite happened since the restart, the size of# the AOF at startup is used).## This base size is compared to the current size. If the current size is# bigger than the specified percentage, the rewrite is triggered. Also# you need to specify a minimal size for the AOF file to be rewritten, this# is useful to avoid rewriting the AOF file even if the percentage increase# is reached but it is still pretty small.## Specify a precentage of zero in order to disable the automatic AOF# rewrite feature.auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb################################## SLOW LOG #################################### The Redis Slow Log is a system to log queries that exceeded a specified# execution time. The execution time does not include the I/O operations# like talking with the client, sending the reply and so forth,# but just the time needed to actually execute the command (this is the only# stage of command execution where the thread is blocked and can not serve# other requests in the meantime).# # You can configure the slow log with two parameters: one tells Redis# what is the execution time, in microseconds, to exceed in order for the# command to get logged, and the other parameter is the length of the# slow log. When a new command is logged the oldest one is removed from the# queue of logged commands.# The following time is expressed in microseconds, so 1000000 is equivalent# to one second. Note that a negative number disables the slow log, while# a value of zero forces the logging of every command.slowlog-log-slower-than 10000# There is no limit to this length. Just be aware that it will consume memory.# You can reclaim memory used by the slow log with SLOWLOG RESET.slowlog-max-len 1024################################ VIRTUAL MEMORY ################################## WARNING! Virtual Memory is deprecated in Redis 2.4### The use of Virtual Memory is strongly discouraged.### WARNING! Virtual Memory is deprecated in Redis 2.4### The use of Virtual Memory is strongly discouraged.# Virtual Memory allows Redis to work with datasets bigger than the actual# amount of RAM needed to hold the whole dataset in memory.# In order to do so very used keys are taken in memory while the other keys# are swapped into a swap file, similarly to what operating systems do# with memory pages.# 指定是否启用虚拟内存机制，默认值为no，# VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中# 把vm-enabled设置为yes，根据需要设置好接下来的三个VM参数，就可以启动VM了vm-enabled no# vm-enabled yes# This is the path of the Redis swap file. As you can guess, swap files# can&#x27;t be shared by different Redis instances, so make sure to use a swap# file for every redis process you are running. Redis will complain if the# swap file is already in use.## Redis交换文件最好的存储是SSD（固态硬盘）# 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享# *** WARNING *** if you are using a shared hosting the default of putting# the swap file under /tmp is not secure. Create a dir with access granted# only to Redis user and configure Redis to create the swap file there.vm-swap-file /tmp/redis.swap# With vm-max-memory 0 the system will swap everything it can. Not a good# default, just specify the max amount of RAM you can in bytes, but it&#x27;s# better to leave some margin. For instance specify an amount of RAM# that&#x27;s more or less between 60 and 80% of your free RAM.# 将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多少，所有索引数据都是内存存储的（Redis的索引数据就是keys）# 也就是说当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认值为0vm-max-memory 0# Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的。# 建议如果存储很多小对象，page大小最后设置为32或64bytes；如果存储很大的对象，则可以使用更大的page，如果不确定，就使用默认值vm-page-size 32# 设置swap文件中的page数量由于页表（一种表示页面空闲或使用的bitmap）是存放在内存中的，在磁盘上每8个pages将消耗1byte的内存# swap空间总容量为 vm-page-size * vm-pages## With the default of 32-bytes memory pages and 134217728 pages Redis will# use a 4 GB swap file, that will use 16 MB of RAM for the page table.## It&#x27;s better to use the smallest acceptable value for your application,# but the default is large in order to work in most conditions.vm-pages 134217728# Max number of VM I/O threads running at the same time.# This threads are used to read/write data from/to swap file, since they# also encode and decode objects from disk to memory or the reverse, a bigger# number of threads can help with big objects even if they can&#x27;t help with# I/O itself as the physical device may not be able to couple with many# reads/writes operations at the same time.# 设置访问swap文件的I/O线程数，最后不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟，默认值为4vm-max-threads 4############################### ADVANCED CONFIG ################################ Hashes are encoded in a special way (much more memory efficient) when they# have at max a given numer of elements, and the biggest element does not# exceed a given threshold. You can configure this limits with the following# configuration directives.# 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法hash-max-zipmap-entries 512hash-max-zipmap-value 64# Similarly to hashes, small lists are also encoded in a special way in order# to save a lot of space. The special representation is only used when# you are under the following limits:list-max-ziplist-entries 512list-max-ziplist-value 64# Sets have a special encoding in just one case: when a set is composed# of just strings that happens to be integers in radix 10 in the range# of 64 bit signed integers.# The following configuration setting sets the limit in the size of the# set in order to use this special memory saving encoding.set-max-intset-entries 512# Similarly to hashes and lists, sorted sets are also specially encoded in# order to save a lot of space. This encoding is only used when the length and# elements of a sorted set are below the following limits:zset-max-ziplist-entries 128zset-max-ziplist-value 64# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in# order to help rehashing the main Redis hash table (the one mapping top-level# keys to values). The hash table implementation redis uses (see dict.c)# performs a lazy rehashing: the more operation you run into an hash table# that is rhashing, the more rehashing &quot;steps&quot; are performed, so if the# server is idle the rehashing is never complete and some more memory is used# by the hash table.# # The default is to use this millisecond 10 times every second in order to# active rehashing the main dictionaries, freeing memory when possible.## If unsure:# use &quot;activerehashing no&quot; if you have hard latency requirements and it is# not a good thing in your environment that Redis can reply form time to time# to queries with 2 milliseconds delay.# 指定是否激活重置哈希，默认为开启activerehashing yes################################## INCLUDES #################################### 指定包含其他的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各实例又拥有自己的特定配置文件# include /path/to/local.conf# include /path/to/other.conf","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yiiiqing.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yiiiqing.github.io/tags/Redis/"}]},{"title":"curl命令获取本机ip","slug":"curl命令获取本机ip","date":"2021-03-17T05:58:20.000Z","updated":"2021-03-17T06:00:01.000Z","comments":true,"path":"2021/03/17/curl命令获取本机ip/","link":"","permalink":"http://yiiiqing.github.io/2021/03/17/curl%E5%91%BD%E4%BB%A4%E8%8E%B7%E5%8F%96%E6%9C%AC%E6%9C%BAip/","excerpt":"","text":"curl获取本机外网ip1234567891011121314151617181920212223curl ifconfig.mecurl icanhazip.comcurl curlmyip.comcurl ip.appspot.comcurl ipinfo.io/ipcurl ipecho.net/plaincurl www.trackip.net/i #补充curl ip.sbcurl ip.6655.com/ip.aspxcurl whatismyip.akamai.comwget -qO - ifconfig.codig +short myip.opendns.com @resolver1.opendns.comcurl ident.mecurl v4.ident.mecurl v6.ident.mecurl inet-ip.info#返回IP和地区curl ip.6655.com/ip.aspx?area=1curl 1111.ip138.com/ic.aspcurl ip.cncurl cip.cc 原文链接：https://blog.csdn.net/longzhizhui926/article/details/83002685","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"curl","slug":"curl","permalink":"http://yiiiqing.github.io/tags/curl/"}]},{"title":"Java-静态代码块","slug":"Java-静态代码块","date":"2021-03-15T09:27:46.000Z","updated":"2021-03-15T09:30:17.000Z","comments":true,"path":"2021/03/15/Java-静态代码块/","link":"","permalink":"http://yiiiqing.github.io/2021/03/15/Java-%E9%9D%99%E6%80%81%E4%BB%A3%E7%A0%81%E5%9D%97/","excerpt":"","text":"静态变量和静态代码块执行顺序一个类中的初始化顺序类内容（静态变量、静态初始化块） =&gt; 实例内容（变量、初始化块、构造器） 两个具有继承关系类的初始化顺序父类的（静态变量、静态初始化块）=&gt; 子类的（静态变量、静态初始化块）=&gt; 父类的（变量、初始化块、构造器）=&gt; 子类的（变量、初始化块、构造器） 赋值初始化块可以对在它之后定义的变量赋值，但不能访问（如打印）。 变量最终值：一个变量，若显示初始化、初始化块对该变量赋值、构造方法对该变量赋值同时存在，则变量最终值如何确定： 1、按执行顺序 2、若对变量赋值的初始化块在变量定义前时：若变量显示初始化了则最终为显示初始化值，否则为初始化块的赋值。","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/tags/Java/"}]},{"title":"Docker报错","slug":"Docker报错","date":"2021-03-11T02:25:41.000Z","updated":"2021-04-23T10:20:45.000Z","comments":true,"path":"2021/03/11/Docker报错/","link":"","permalink":"http://yiiiqing.github.io/2021/03/11/Docker%E6%8A%A5%E9%94%99/","excerpt":"","text":"启动报错 12345678[root@VM-0-14-centos docker]# docker run hello-worldUnable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-world0e03bdcc26d7: Pull completeDigest: sha256:31b9c7d48790f0d8c50ab433d9c3b7e17666d6993084c002c2ff1ca09b96391dStatus: Downloaded newer image for hello-world:latestrunc: symbol lookup error: runc: undefined symbol: seccomp_api_getdocker: Error response from daemon: cannot start a stopped process: unknown. 解决方法: 更新libseccomp库, seccomp_api_set定义在2.4以上版本中 yum update libseccomp Docker挂载主机目录Docker访问出现cannot open directory: Permission denied 解决方法: 在挂载目录后多加一个--privileged=true参数 有时候输入socker的命令会报: 1Cannot connect to the Docker daemon at unix:///var/run/docker.sock. 原因: 上一次没有正常退出docker 解决方法: sudo service docker restart或sudo systemctl start docker (mac的话查看有没有启动,状态栏小鲸鱼有没有) 运行centos8,无法执行systemctl System has not been booted with systemd as init system (PID 1). Can&#39;t operat 解决方法:docker run --privileged -itd centos-yiqing:1.1 /usr/sbin/init 之后就可以使用docker exec -it xxx /bin/bash 通过apt-get安装yum 在使用Docker镜像文件时，某些镜像往往并没有安装yum命令，此时就无法通过yum安装其他软件。那么此时应该如何进行yum命令的安装呢？ 我们可以通过apt-get来先将yum命令进行安装，执行如下命令： apt-get install yum 但此时通常情况下并不会顺利安装，如果控制台输出如下信息： 1234Reading package lists... DoneBuilding dependency treeReading state information... DoneE: Unable to locate package yum 则说明安装出现问题，需要更新一下APT库。 更新APT库需要执行如下命令： 12apt-get updateapt-get upgrade 然后执行apt-get install yum即可 如果yum安装出现 There are no enabled repos 这是因为yum没有配置源 1234567删除rm -f /etc/yum.repos.d/CentOS-Base.repo 配置成阿里的源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo清除缓存yum clean all","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/tags/Docker/"},{"name":"报错","slug":"报错","permalink":"http://yiiiqing.github.io/tags/%E6%8A%A5%E9%94%99/"}]},{"title":"Docker基础","slug":"Docker基础","date":"2021-03-10T04:53:10.000Z","updated":"2021-03-18T09:48:24.000Z","comments":true,"path":"2021/03/10/Docker基础/","link":"","permalink":"http://yiiiqing.github.io/2021/03/10/Docker%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Docker基础介绍解决了运行环境和配置问题软件容器,方便做持续集成并有助于整体发布的容器虚拟化技术 与传统虚拟化方式的不同 传统虚拟化技术是虚拟出一套硬件之后,在其上运行一个完整的操作系统,在该系统上再运行所需应用进程 容器内的应用进程直接运行于宿主的内核,容器内没有自己的内核,而且也没有进行硬件虚拟.因此容器要比虚拟机更加方便 容器之间相互隔离,每个容器有自己的文件系统,容器之间进程不会互相影响,能区分计算资源 为什么比虚拟机快 docker有比虚拟机更少的抽象层. 由于docker不需要Hypervisor实现硬件资源虚拟化,运行在docker容器上的程序直接使用的都是实际物理机的硬件资源. 因此在cpu,内存利用率上docker将会在效率上有明显优势 docker利用的是宿主机的内核,而不需要GuestOS. 因此,当创建一个容器时,docker不需要和虚拟机一样重新加载一个操作系统内核. 创建一个虚拟机时,虚拟机软件需要加载GuestOS,整个新建过程是分钟级别的 三部分 镜像 Image 容器 Container 容器是用镜像创建的运行实例 每个容器都是相互隔离的 可以把容器看作是一个简易版的Linux环境 仓库 Repository 集中存放镜像的地方 分为公开仓库public和私有仓库private两种形式 最大的公开仓库是Docker Hub. 国内有阿里云,网易云 安装参考官网: https://docs.docker.com/engine/install/centos/ 使用阿里云镜像加速参考官网: https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 常用命令帮助命令docker version docker info docker --help 镜像命令docker images -q 显示id -a 列出全部 docker search Options: **–automated :**只列出 automated build类型的镜像； **–no-trunc :**显示完整的镜像描述； **-f &lt;过滤条件&gt;:**列出收藏数不小于指定值的镜像。(低版本是-s) docker search -f stars=10 java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176```docker pull``` : 拉取镜像* 默认latest```docker rmi```: 删除镜像* 默认latest* 删除单个: ```docker rmi -f hello-world```* 删除多个: ```docker rmi -f hello-world nginx```* 删除全部: ```docker rmi -f $(docker images -q)```### 容器命令有镜像才能创建容器#### 新建并启动容器```docker run [OPTIONS] IMAGE [COMMAND][ARG...]```常用选项1. --name: 指定名称2. -d: 后台运行容器,并返回容器ID,也即**启动守护式容器**3. **-i: 以交互模式运行容器,通常与-t同时使用**4. **-t: 为容器重新分配一个伪输入终端,通常与-i同时使用**5. -P: 随机端口映射6. -p: 指定端口映射,有以下格式 1. ip:hostPort:containerPort 2. ip::containerPort 3. hostPort:containerPort 4. containerPort#### 列出所有正在运行的容器```docker ps [OPTIONS]```常用选项* -a: 列出所有正在运行的容器+历史上运行过的* -l: 显示最近创建的容器* ~~-n: 显示最近n个创建的容器~~* -q: 静默模式,只显示容器编号* --no-trunc: 不截断输出#### 退出容器* exit: 容器停止退出* ctrl + P + Q: 容器不停止退出#### 启动容器* ```docker start CONTAINER ID/NAME```#### 重启容器* ```docker restart CONTAINER ID/NAME` ``#### 停止容器* ```docker stop CONTAINER ID/NAME```* 强制停止: ```docker kill CONTAINER ID/NAME```#### 删除已停止容器* ```docker rm CONTAINER ID```* 一次性删除多个容器 * ```docker rm -f $(docker ps -a -q)``` * ```docker ps -a -q | xargs docker rm```#### 守护进程启动* ```docker run -d CONTAINER NAME```* 使用```docker ps -a```查看,发现容器已经退出. 是因为**Docker容器后台运行,必须有一个前台进程**. * 容器运行的命令如果不是那些一直挂起的命令(比如top,tail),都是会自动退出 * 这是docker的机制 * **解决方案: 将要运行的程序用前台进程形式运行**#### 查看日志* ```docker logs -f -t --tail CONTAINER ID``` * -t: 加入时间戳 * -f: 跟随最新的日志打印 * --tail 数字: 显示最后多少条#### 查看容器内运行的进程```docker top CONTAINER ID```#### 查看容器内部细节```docker inspect CONTAINER ID```#### 与容器以命令行交互* ```docker exec -it CONTAINER ID bashShell``` (推荐) * 可以进入容器(bashShell 写 /bin/bash) * 也可以在外面执行获取结果* ```docker attach CONTAINER ID```* 区别: * attach 是直接进入容器启动命令的终端,不会启动新的进程 * exec 是在容器中打开新的终端,并且可以启动新的进程#### 从容器内拷贝文件到主机上* ```docker cp CONTAINER ID:CONTAINER PATH HOSTPATH```### 总结 [Docker.mmap](../../../Downloads/Docker.mmap) ***## 镜像* 镜像是一种轻量级的,可执行的独立软件包,用来打包软件运行环境和基于运行环境开发的软件.* UnionFS(联合文件系统) * 是一种分层,轻量级并且高性能的文件系统,它支持对文件系统的修改作为一次提交来一层层的叠加 * 一次同时加载多个文件系统,但从外面看来,只能看到一个文件系统* docker镜像 * bootfs (boot file system) 主要包含bootloader和kernl. * bootloader主要是引导加载kernel * Linux刚启动时会加载bootfs文件系统,在Docker镜像的最底层是bootfs. * 这一层与典型的Linux系统是一样的,包含boot加载器和内核.当boot加载完成后整个内核就都在内存中了,此时内存的使用权已由bootfs转交给内核,此时系统也会卸载bootfs * rootfs (root file system) * 在bootfs之上. * 包含就是Linux系统中的/dev,/proc,/bin,/etc等标准目录和文件. * rootfs就是各种不同的操作系统发行版,比如Ubuntu, CentOS* 好处:**共享资源**### 操作#### commit```docker commit```提交容器副本使之成为一个新的镜像```docker commit -m=&quot;描述&quot; -a=&quot;作者&quot; 容器ID 要创建的目标镜像名:[标签名]```***## 容器数据卷* 持久化* 容器之间希望可以共享数据* docker里面的RDB,AOF### 介绍* 卷就是目录或文件,存在于一个或多个容器中,由docker挂载到容器,但不属于联合文件系统,因此能够绕过Union File System提供一些用于持续存储或共享数据的特性* 设计目的就是数据持久化,完全独立于容器的生存周期,因此Docker不会在容器删除时删除其挂载的数据卷### 特点1. 数据卷可用在容器之间共享或重用数据2. 卷中的更改可以直接生效3. 数据卷中的更改不会包含在镜像的更新中4. 数据卷的生命周期一直持续到没有容器使用它为止### 添加#### 命令添加```docker run -it -v /宿主机绝对路径目录:/容器内目录 镜像名``````docker run -it -v /宿主机绝对路径目录:/容器内目录:ro 镜像名``` 容器内只读(ro:read only)#### dockerfile添加1. 编写```dockerfile# volume testFROM centosVOLUME [&quot;/dataVolumeContainer1&quot;,&quot;/dataVolumeContainer2&quot;]CMD echo &quot;finished,------success1&quot;CMD /bin/bash 指定dockerfile 构建 docker build -f /mydocker/DockerFile -t zyq/centos . 运行 docker run -it zyq/centos 数据卷容器介绍命名的容器挂载数据卷,其他容器通过挂载这个(父容器)实现数据共享,挂载数据卷的容器,称之为数据卷容器 命令docker run -t --volumes-from CONTAINER NAME IMAGE CONTAINER NAME: 继承自什么容器 IMAGE: 镜像名 子与父之间共享数据卷! 结论容器之间配置信息的传递,数据卷的生命周期一直持续到没有容器使用它为止 Dockerfile简介Dockerfile是用来构建Docker镜像的构建文件,是由一系列命令和参数构成的脚本 构建三步骤 编写Dockerfile文件 docker build docker run 构建过程解析基础知识 每条保留字指令都必须为大写字母且后面要跟随至少一个参数 指令按照从上到下,顺序执行 #表示注释 每条指令都会创建一个新的镜像层,并对镜像进行提交 执行流程 docker从基础镜像运行一个容器 执行一条指令并对容器作出修改 执行类似docker commit的操作提交一个新的镜像层 docker再基于刚提交的镜像运行一个新容器 执行dockerfile中的下一条指令直到所有指令都执行完成 总结从应用软件的角度来看,Dockerfile,Docker镜像于Docker容器分别代表软件的三个不同阶段 Dockerfile是软件的原材料 Docker镜像是软件的交付品 Docker容器则可以认为是软件的运行态 Dockerfile面向开发,Docker镜像成为交付标准,Docker容器则涉及部署与运维,三者缺一不可,合力充当Docker体系的基石. Dockerfile涉及的内容包括执行代码或文件,环境变量,依赖包,运行时环境,动态链接库,操作系统的发行版,服务进程和内核进程等等 Dockerfile体系结构FROM 基础镜像,当前新镜像是基于哪个镜像的 MAINTAINER 镜像维护者的姓名和邮箱地址 RUN 容器构建时需要运行的命令 EXPOSE 当前容器对外暴露出的端口 WORKDIR 指定在创建容器后,终端默认登录进来的工作目录,一个落脚点 ENV 用来在构建镜像过程中设置环境变量 ADD 将宿主机下的文件拷贝进镜像,且ADD命令会自动处理URL和解压tar压缩包 COPY 类似ADD,拷贝文件和目录到镜像中 将从构建上下文目录中&lt;源路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置 COPY src dest COPY [&quot;src&quot;, &quot;dest&quot;] VOLUME 容器数据卷,用于数据保存和持久化操作 CMD 指定一个容器启动时要运行的命令 Dockerfile中可以有多个CMD指令,但最后只有一个生效,CMD会被docker run之后的参数替换 ENTRYPOINT 指定一个容器启动时要运行的命令 ENTRYPOINT的目的和CMD一样,都是在指定容器启动程序和参数 docker run之后的参数会被当作参数传递给ENTRYPOINT,之后形成新的命令组合 ONBUILD 当构建一个被继承的Dockerfile是运行命令,父镜像在被子继承后父镜像的onbuild被触发 案例自定义镜像centos目的 设置登录后的默认路径 vim编辑器 查看网络配置ifconfig支持 步骤 编写文件 1234567891011121314FROM centosMAINTAINER yiqing&lt;y.zhang@live.com&gt;ENV MYPATH /usr/localWORKDIR $MYPATHRUN yum -y install vimRUN yum -y install net-toolsEXPOSE 80CMD echo $MYPATHCMD echo &quot;success------ok&quot;CMD /bin/bash 构建 -f指定dockerfile文件 docker build -t 新镜像名:TAG docker build -f /mydocker/dockerfile2 -t mycentos:1.3 . 运行 docker run -it mycentos:1.3 自定义tomcat Dockerfile 1234567891011121314151617181920212223242526272829FROM centosMAINTAINER yiqing&lt;y.zhang@live.com&gt;#把宿主机当前上下文的c.txt拷贝到容器/usr/local路径下COPY c.txt /usr/local/container.txt#把java与tomcat添加到容器中ADD jdk-8u281-linux-x64.tar.gz /usr/local/ADD apache-tomcat-10.0.2.tar.gz /usr/local/#安装vimRUN yum -y install vim#设置访问的落脚点ENV MYPATH /usr/localWORKDIR $MYPATH#配置java与tomcat环境变量ENV JAVA_HOME /usr/local/jdk1.8.0_281ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/apache-tomcat-10.0.2ENV CATALINA_BASE /usr/local/apache-tomcat-10.0.2ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin#容器运行时监听的端口EXPOSE 8080#启动时运行tomcatCMD /usr/local/apache-tomcat-10.0.2/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-10.0.2/bin/logs/catalina.out 构建 统一目录下如果名字为Dockerfile,自动去找 docker build -t yiqingtomcat10 运行 12345docker run -d -p 9080:8080 --name mytomcat10 \\-v /mydockerfile/tomcat/test:/usr/local/apache-tomcat-10.0.2/webapps/test \\-v /mydockerfile/tomcat/tomcat10logs/:/usr/local/apache-tomcat-10.0.2/logs \\--privileged=true \\yiqingtomcat10 安装服务Mysql docker pull mysql 运行 123456docker run -p 3306:3306 --name mysql \\-v /mydockerfile/mysql/conf:/etc/mysql/conf.d \\-v /mydockerfile/mysql/logs:/logs \\-v /mydockerfile/mysql/data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=123456 \\-d mysql 交互 docker exec -it mysql /bin/bash 登录mysql mysql -uroot -p 备份mysql docker exec mysql sh -c &#39;exec mysqldump --all-databases -uroot -p &quot;123456&quot;&#39; &gt; /yiqing/all-databases.sql Redis docker pull redis docker run -p 6379:6379 --name redis \\ -v /mydockerfile/redis/data:/data \\ -v /mydockerfile/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \\ -d redis redis-server /usr/local/etc/redis/redis.conf \\ --appendonly yes 123456789101112131415161718192021222324253. 创建redis.conf文件(略)4. 连接: ```docker exec -it redis redis-cli```## 上传镜像到阿里云### 从容器创建一个新的镜像```docker commit [OPTIONS] CONTAINER ID [REPOSITORY[:TAG]]```示例: ```docker commit -a yiqing -m &quot;new centos with vim and ifconfig&quot; c8855ee794d3 mycentos:1.4```### 推送到阿里云1. 登录阿里云容器镜像服务2. 创建镜像仓库3. 推送 ```bash sudo docker login --username=[xxx] registry.cn-shanghai.aliyuncs.com sudo docker tag [ImageId] registry.cn-shanghai.aliyuncs.com/yiqing/personal:[镜像版本号] sudo docker push registry.cn-shanghai.aliyuncs.com/yiqing/personal:[镜像版本号]","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/tags/Docker/"}]},{"title":"Linux-Shell编程","slug":"Linux-Shell编程","date":"2021-03-06T07:21:31.000Z","updated":"2021-03-15T09:45:36.000Z","comments":true,"path":"2021/03/06/Linux-Shell编程/","link":"","permalink":"http://yiiiqing.github.io/2021/03/06/Linux-Shell%E7%BC%96%E7%A8%8B/","excerpt":"","text":"Linux Shell编程Shellshell是一个命令行解释器, 它为用户提供了一个向Linux内核发送请求以便运行程序的界面系统级程序,用户可以用Shell来启动,挂起,停止甚至编写程序 编写格式要求 脚本以#!/bin/bash开头 脚本需要有可执行权限 执行方式 输入脚本的绝对路径或相对路径 首先要赋予脚本+x权限: chmod 744 myShell.sh 执行脚本 sh + 脚本直接执行 Shell变量介绍 分为两种: 系统变量: $HOME, $PWD, $SHELL, $USER 用户自定义变量 显示当前shell中所有变量: set 12echo &quot;PATH=$PATH&quot;echo &quot;USER=$USER&quot; 定义语法 定义变量: 变量=值 撤销变量: unset 变量 声明静态变量: readonly 变量. 注意: 不能unset 123456789#A=100#echo &quot;A=$A&quot;#unset A#echo &quot;A=$A&quot;readonly A=99echo &quot;A=$A&quot;unset Aecho &quot;A=$A&quot; 规则 变量名称可以由字母,数字和下划线组成,但是不能以数字开头 等号两侧不能有空格 变量名称一般习惯为大写 将命令的返回值赋给变量 A=`ls -la` 反引号,运行里面的命令,并把结果赋值给变量A A=$(ls-la) 等价于反引号 注释 单行: # 多行: 以 :&lt;&lt;!开头,!结尾 设置环境变量在/etc/profile文件中加入 12TOMCAT_HOME=/opt/apache-tomcat-10.0.2export TOMCAT_HOME 使用echo查看 注意要使用source /etc/profile重新加载 位置参数变量当我们执行脚本时,如果希望获取到命令行的参数信息,就可以使用到位置参数变量 语法 选项 描述 $n n为数字,$0代表命令本身,$1-$9代表第1到9个参数,10以上的参数需要用大括号包含: ${10} $* 代表命令行中所有的参数,$8把所有的参数看成一个整体 $@ 代表命令行中所有的参数,吧每个参数区分对待 $# 代表命令行中所有参数的个数 预定义变量就是shell设计者事先定义好的变量,可直接在shell脚本中使用 语法 选项 描述 $$ 当前进程的进程号(PID) $! 后台运行的最后一个进程的进程号(PID) $? 最后一次执行的命令的返回状态.如果这个变量的值为0,证明上一个命令正确执行;如果这个变量的值为非0(具体哪个数由命令自己决定),则证明上一个命令执行不正确了 运算符语法 $((运算式)) $[运算式](推荐) expr m + n 注意expr运算符间要有空格 ```expr m - n ```` expr \\*,/,% 乘,除,取余 条件判断语法 [ condition ] 注意:condition前后要有空格 非空返回true,可使用$?验证(0为true,&gt;1为false) 实例: [ yiqing ] 返回true [] 返回false [ condition ] &amp;&amp; OK || echo notok 条件满足执行后面的语句 常用判断条件 两个整数的比较 = 字符串比较 -lt 小于 -le 小于等于 -eq 等于 -gt 大于 -ge 大于等于 -ne 不等于 按照文件权限进行判断 -r 有读权限 -w 有写权限 -x 有执行权限 按照文件类型进行判断 -f 文件存在且是一个常规的文件 -e 文件存在 -d 文件存在且是一个目录 12345678910111213141516171819#!/bin/bash#1.if [ &quot;ok&quot; = &quot;ok&quot; ]then echo &quot;equal&quot;fi#2.if [ 23 -gt 22 ]then echo &quot;大于&quot;fi#3: /root/shell/aaa.txt 目录中的文件是否存在if [ -e /root/shell/aaa.txt ]then echo &quot;存在&quot;fi 流程控制if语法 if [ 条件判断式 ];then 程序 fi 1234562. ```shell if [ 条件判断式 ] then 程序 elif [ 条件判断式 ] 注意 [ 条件判断式 ], 中括号和条件判断式之间必须有空格 if 和后面的中括号之间也要有空格 推荐第二种方式 示例1234567if [ $1 -ge 60 ]then echo &quot;及格了&quot;elif [ $1 -lt 60 ]then echo &quot;不及格&quot;fi case语法123456789101112case $变量名 in &quot;值1&quot;) 如果变量的值等于值1, 执行程序1 ;; &quot;值2&quot;) 如果变量的值等于值2, 执行程序2 ;; ...省略其他分支 *) 如果变量的值都不是以上的值, 执行此程序 ;;esac 示例123456789101112131415#!/bin/bash# 参数是1,输出周一,是2,输出周二,其他情况输出othercase $1 in &quot;1&quot;) echo &quot;周一&quot; ;; &quot;2&quot;) echo &quot;周二&quot; ;; *) echo &quot;other&quot; ;;esac for语法 for 变量 in 值1 值2 值3... do 程序 done 1234567891011121314151617181920212223241. 示例: ```shell #!/bin/bash 及格了 [root@VM-0-14-centos shell]# ./testIf.sh 61 及格了 [root@VM-0-14-centos shell]# ./testIf.sh 22 不及格 [root@VM-0-14-centos shell]# vim testIf.sh #!/bin/bash #打印命令行输入的参数 #使用$* for i in &quot;$*&quot; do echo &quot;the number is $i&quot; done #使用$@ for j in &quot;$@&quot; do echo &quot;the number is $j&quot; done 2. 结果为: 12345[root@VM-0-14-centos shell]# ./testFor.sh 10 20 30the number is 10 20 30the number is 10the number is 20the number is 30 for((初始值;循环控制条件;变量变化)) do 程序 done 1234567891011121314151. 示例: ```bash #!/bin/bash #从1加到100的值输出显示 #定义一个变量 SUM=0 for((i=1;i&lt;=100;i++)) do SUM=$[$SUM+$i] done echo &quot;SUM=$SUM&quot; 2. 结果 12[root@VM-0-14-centos shell]# ./testFor2.shSUM=5050 while语法1234while [ 条件判断式 ] #注意while和条件判断式与中括号之间要有空格 do 程序 done 示例123456789101112#!/bin/bash#从命令行输入一个参数n,统计从1+..+n的值SUM=0i=0while [ $i -le $1 ]do SUM=$[$SUM+$i] i=$[$i+1]doneecho &quot;SUM=$SUM&quot; 读取控制台输入read语法 read [选项] [参数] 选项: -p 指定读取值时的提示符 -t 指定读取值时等待的时间(秒), 如果没有在指定的时间内输入, 就不再等待了… 示例1234567891011#!/bin/bash#1.读取控制台输入一个num的值read -p &quot;请输入一个数num1=&quot; NUM1echo &quot;你输入的值是 num1=$NUM1&quot;#2.读取控制台输入一个num的值,十秒内输入read -t 10 -p &quot;请输入一个数num2=&quot; NUM2echo &quot;你输入的值是 num2=$NUM2&quot; 函数shell有系统函数,也可以自定义函数. 系统函数basename 返回完整路径最后/的部分,常用于获取文件名 basename [pathname] [suffix] basename [string] [suffix] suffix为后缀,如果suffix被指定了, basename会将pathname或string中的suffix去掉 示例 [root@VM-0-14-centos shell]# basename /home/aaa.txt aaa.txt [root@VM-0-14-centos shell]# basename /home/aaa.txt .txt aaa 123456789101112#### dirname* 返回完整路径最后/的前面的部分,常用于返回路径部分* ```dirname 文件绝对路径```* 示例 * ```bash root@VM-0-14-centos shell]# dirname /home/aaa.txt /home 自定义函数 语法 [ function ] funname[()] &#123; Action; [return int;] &#125; 123456789101112131415161718192021 * 调用直接写函数名: funname [值]* 示例 * 计算两个参数的和(read) * ```shell #!/bin/bash function getSum()&#123; SUM=$[$n1+$n2] echo &quot;和=$SUM&quot; &#125; read -p &quot;请输入第一个n1&quot; n1 read -p &quot;请输入第一个n2&quot; n2 #调用getSum getSum $n1 $n2 综合案例需求 每天凌晨2.10备份数据库到 /data/backup/db 备份开始和备份结束能够给出相应的提示信息 备份后的文件要求以备份时间为文件名,并打包成.tar.gz的形式 在备份的同时,检查是否有10天前备份的数据库文件,如果有就将其删除 代码在/usr/sbin下面创建脚本 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bash#完成数据库的定时备份#备份的路径BACKUP=/data/backup/db#当前的时间作为文件名#+和后面不能有空格DATETIME=$(date +%Y_%m_%d_%H%M%S)#可以输出变量调试echo $DATETIMEecho &quot;==========开始备份=========&quot;echo &quot;==========备份的路径是 $BACKUP/$DATETIME.tar.gz&quot;#主机HOST=localhost#用户名DB_USER=root#密码DB_PWD=root#备份数据库名DATABASE=test#创建备份的路径#如果备份的路径文件夹存在,就使用,否则就创建[ ! -d &quot;$BACKUP/$DATETIME&quot; ] &amp;&amp; mkdir -p &quot;$BACKUP/$DATETIME&quot;#执行mysql的备份数据库的指令mysqldump -u$&#123;DB_USER&#125; -p$&#123;DB_PWD&#125; --host=$HOST $DATABASE | gzip &gt; $BACKUP/$DATETIME/$DATETIME.sql.gz#打包备份文件cd $BACKUPtar -zcvf $DATETIME.tar.gz $DATETIME#删除临时目录rm -rf $BACKUP/$DATETIME#删除十天前的备份文件find $BACKUP -mtime +10 -name &quot;*.tar.gz&quot; -exec rm -rf &#123;&#125; \\;echo &quot;==========备份成功==========&quot;&quot; 添加到定时任务中 crontab -e 写入 10 2 * * * /usr/sbin/backup/mysql_db_backup.sh","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://yiiiqing.github.io/tags/Shell/"}]},{"title":"JavaScript-字符串转数组","slug":"JavaScript-字符串转数组","date":"2021-03-04T07:17:30.000Z","updated":"2021-03-04T07:19:30.000Z","comments":true,"path":"2021/03/04/JavaScript-字符串转数组/","link":"","permalink":"http://yiiiqing.github.io/2021/03/04/JavaScript-%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%95%B0%E7%BB%84/","excerpt":"","text":"字符串转数组直接JSON.parse() 12let a = &quot;[1,2,3,3,3]&quot;console.log(JSON.parse(a))","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"字符串","slug":"字符串","permalink":"http://yiiiqing.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"Linux-配置JavaEE环境","slug":"Linux-配置JavaEE环境","date":"2021-03-03T03:05:07.000Z","updated":"2021-06-23T14:53:20.000Z","comments":true,"path":"2021/03/03/Linux-配置JavaEE环境/","link":"","permalink":"http://yiiiqing.github.io/2021/03/03/Linux-%E9%85%8D%E7%BD%AEJavaEE%E7%8E%AF%E5%A2%83/","excerpt":"","text":"JDK步骤 先将jdk压缩包上传到/opt目录下,使用scp命令 mac下上传命令为scp -P 22 /Users/yiqingzhang/Documents/packages/jdk-8u281-linux-x64.tar.gz root@106.55.165.4:/opt 解压缩到/opt: tar -zxvf jdk-8u281-linux-x64.tar.gz 配置环境变量的配置文件: vim /etc/profile JAVA_HOME=/opt/jdk1.8.0_281 PATH=/opt/jdk1.8.0_281/bin:$PATH(注意:表示拼接后面的,$PATH表示原来的PATH变量) export JAVA_HOME PATH 输出变量 需要注销用户,环境变量才能生效(或source /etc/profile) tomcat 先将压缩包上传到/opt目录下 mac: scp -P 22 /Users/yiqingzhang/Documents/packages/apache-tomcat-10.0.2.tar.gz root@106.55.165.4:/opt 解压缩 tar -zxvf apache-tomcat-10.0.2.tar.gz 启动 cd到tomcat的bin目录下执行 ./start.sh 注意: 如果防火墙阻挡了端口8080 查看firewall的端口: firewall-cmd --zone=public --list-ports 查看防火墙状态: systemctl status firewalld 如果关闭了防火墙,启动防火墙的命令是: systemctl start firewalld 开放防火墙端口: firewall-cmd --zone=public --add-port=8080/tcp --permanent(重要) 重新加载防火墙: firewall-cmd --reload 查看端口是否开放: netstat -nlp","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"配置 - Java","slug":"配置-Java","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE-Java/"}]},{"title":"Markdown页面内部跳转","slug":"Markdown页面内部跳转","date":"2021-03-02T02:39:50.000Z","updated":"2021-03-02T02:42:32.000Z","comments":true,"path":"2021/03/02/Markdown页面内部跳转/","link":"","permalink":"http://yiiiqing.github.io/2021/03/02/Markdown%E9%A1%B5%E9%9D%A2%E5%86%85%E9%83%A8%E8%B7%B3%E8%BD%AC/","excerpt":"","text":"Markdown 实现页面内部跳转先定义要跳转的锚点 锚点 &lt;span id = &quot;anchor&quot;&gt;锚点&lt;/span&gt; 注: id是您随意取的,当然必须是唯一的. 跳转锚点 [锚点](#anchor) 注: []内是要填转的按钮显示的文字,小括号内#后面是跟的id值.因为跳转是根据id跳的.","categories":[{"name":"Markdown","slug":"Markdown","permalink":"http://yiiiqing.github.io/categories/Markdown/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://yiiiqing.github.io/tags/Markdown/"}]},{"title":"Java-字符串分割","slug":"Java-字符串分割","date":"2021-03-01T07:54:05.000Z","updated":"2021-03-01T07:56:49.000Z","comments":true,"path":"2021/03/01/Java-字符串分割/","link":"","permalink":"http://yiiiqing.github.io/2021/03/01/Java-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%86%E5%89%B2/","excerpt":"","text":"使用split(string)方法 注意: 指定分割.需要转义”\\\\.”","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"字符串","slug":"字符串","permalink":"http://yiiiqing.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"JavaScript-判空","slug":"JavaScript-判空","date":"2021-02-26T03:14:56.000Z","updated":"2021-02-26T03:19:52.000Z","comments":true,"path":"2021/02/26/JavaScript-判空/","link":"","permalink":"http://yiiiqing.github.io/2021/02/26/JavaScript-%E5%88%A4%E7%A9%BA/","excerpt":"","text":"今天项目中发现一个问题本来想判断字符串为空字符串 object[key] == &quot;&quot; 结果发现当值为数字0的时候此条判断也为 true 应改为```object[key] === “” 删除空值的方法12345678910/** * trim object * @param &#123;object&#125; object */function trimObj(object) &#123; for (let key in object) &#123; if (object[key] === null || object[key] === &#x27;null&#x27; || typeof object[key] == &#x27;undefined&#x27; || object[key] === &quot;&quot;) delete object[key]; &#125; return object;&#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[]},{"title":"JS判空","slug":"JS判空","date":"2021-02-26T03:14:29.000Z","updated":"2021-02-26T03:14:29.000Z","comments":true,"path":"2021/02/26/JS判空/","link":"","permalink":"http://yiiiqing.github.io/2021/02/26/JS%E5%88%A4%E7%A9%BA/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"SpringBoot-RabbitMQ","slug":"SpringBoot-RabbitMQ","date":"2021-02-23T06:41:18.000Z","updated":"2021-06-23T14:56:13.000Z","comments":true,"path":"2021/02/23/SpringBoot-RabbitMQ/","link":"","permalink":"http://yiiiqing.github.io/2021/02/23/SpringBoot-RabbitMQ/","excerpt":"","text":"参考文章: https://blog.csdn.net/qq_35387940/article/details/100514134?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-3&amp;spm=1001.2101.3001.4242","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"},{"name":"中间件","slug":"Java/中间件","permalink":"http://yiiiqing.github.io/categories/Java/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yiiiqing.github.io/tags/RabbitMQ/"}]},{"title":"SpringBoot项目返回maven project版本号","slug":"SpringBoot项目返回maven-project版本号","date":"2021-02-20T07:54:11.000Z","updated":"2021-02-20T08:06:58.000Z","comments":true,"path":"2021/02/20/SpringBoot项目返回maven-project版本号/","link":"","permalink":"http://yiiiqing.github.io/2021/02/20/SpringBoot%E9%A1%B9%E7%9B%AE%E8%BF%94%E5%9B%9Emaven-project%E7%89%88%E6%9C%AC%E5%8F%B7/","excerpt":"","text":"方法一(推荐) 在application.properties中添加 1version=@project.version@ 双@@是为了避免和Spring语法冲突 使用@Value注解方式直接获取 方法二Properties代码加载 123final Properties properties = new Properties();properties.load(this.getClass().getClassLoader().getResourceAsStream(&quot;application.properties&quot;));return properties.getProperty(&quot;version&quot;);","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"Linux学习手册","slug":"Linux学习手册","date":"2021-02-18T08:26:08.000Z","updated":"2021-03-03T03:25:03.000Z","comments":true,"path":"2021/02/18/Linux学习手册/","link":"","permalink":"http://yiiiqing.github.io/2021/02/18/Linux%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/","excerpt":"","text":"Linux学习流程 linux环境下基本操作命令 文件操作命令rm mkdir chmod chown 编辑工具使用 vi vim linux用户管理 useradd userdel usermod linux各种配置 环境变量配置 网络配置 服务配置 linux下如何搭建对应语言的开发环境 能编写shell脚本, 对linux服务器进行维护 能进行安全设置,防止攻击,保障服务器正常运行,能对系统调优 深入理解linux系统,对内核有研究,熟练掌握大型网站应用架构组成,并熟悉各个环节的部署和维护方法 学习方法 不需要掌握所有的Linux指令,要学会,要学会查询手册和百度 先 know how, 再 know why 计算机是一门”做中学”的学科 适当囫囵吞枣 重点是实操 Linux 基础总结 目录中有且只有一个根目录 各个目录存放的内容规划好的,不要乱放文件 linux以文件形式管理设备,在linux中,一切皆为文件 脑海中应该有一个linux目录树 目录加粗标识重要,删除线标识不要动的目录 bin 是Binary的缩写,存放经常使用的命令 sbin s就是super user的意思,这里存放的是系统管理员使用的系统管理程序 home 存放普通用户的主目录,在Linux中每个用户都有一个自己的目录,一般该目录名是以用户的帐号名命名的 root 该目录为系统管理员,也称作超级权限者的用户主目录 lib 系统开机所需要的最基本的动态连接共享库,作用类似windows的ddl文件. 几乎所有的应用程序都需要用到这些共享库 lost+found 这个目录一般情况是空的,当系统非法关机后,这里就存放了一些文件 etc 所有的系统管理所需要的配置文件和子目录 my.conf usr 非常重要的目录,用户的很多应用程序和文件都放在这个目录下 类似windows下的program files boot 存放的是启动Linux时使用的一些核心文件.包括一些连接文件以及镜像文件 proc 这个目录是一个虚拟的目录,他是系统内存的映射,存放这个目录来获取系统信息 srv service的缩写,存放一些服务启动后需要提取的数据 sys 这是linux2.6内核的一个很大的变化. 安装了2.6内核中新出现的一个文件系统sysfs tmp 存放临时文件 dev 类似window设备管理器,把所有的硬件用文件的形式存储 media linux系统会自动识别一些设备,例如u盘,光驱等.当识别后,linux会把识别的设备挂载到这个目录下 mnt 系统提供该目录是为了让用户临时挂载别的文件系统的. 可以将外部的存储挂载在/mnt上,进入该目录可以查看里面的内容了 opt 这是给主机额外安装软件所摆放的目录.默认为空 /usr/local 晚装软件的安装目录. 一般通过编译源码的方式安装的程序 var 存放者不断在扩充的东西. 习惯将经常被修改的目录放在这个目录下 例如日志 selinux[security-enhanced linux] SELinux是一种安全子系统,它能控制程序只能访问特定 文件 开关机&amp;登录指令关机&amp;重启注意: 在关机或重启之前,都应该先执行sync指令把内存的数据写入磁盘,防止数据丢失 12345678shutdownshutdown -h now #立即关机shutdown -h 1 #一分钟后关机shutdown -r now #现在重新启动halt #关机,作用同上reboot #现在重新启动sync #把内存的数据同步到磁盘 用户登录&amp;注销 登录时尽量不使用root用户登录.使用普通用户登录,需要权限时使用su - username来切换为管理员身份 提示符下输入logout即可注销 图形界面无效,运行级别3有效 用户管理用户添加用户12useradd usernameuseradd -d xxx username #指定home目录 指定密码1passwd username 删除用户12userdel username #保留home目录userdel -r username #删除用户以及home目录 是否保留home目录? 一般情况下保留 查询用户信息id username 切换用户切换: su - username,权限高切换到权限低不需要密码 需要返回原来用户: exit 用户组增加groupadd groupname 删除groupdel groupname 增加一个用户同时指定组useradd -g groupname username 修改用户组usermod -g groupname username 用户和用户组的配置文件 /etc/passwd文件 用户的配置文件,记录用户的各种信息 格式: 用户名:用户标识号:组标识号:注释性描述:主目录:登录Shell /etc/shadow文件 口令的配置文件 登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志 /etc/group文件 组配置文件 组名:口令:组标识号:组内用户列表 实用指令运行级别 级别 状态 0 关机 1 单用户(找回丢失密码) 2 多用户无网络服务 3 多用户有网络服务 4 保留 5 图形页面 6 重启 常用级别为3和5 配置文件: /etc/inittab 切换到指定运行级别init [012356] 帮助指令对某个指令不熟悉时候,使用帮助指令来了解这个指令的使用 man [命令] help [命令] 文件目录类pwd 显示当前工作目录的绝对路径 ls ls [选项] [目录或文件] 常用选项 -a 显示所有文件和目录,包括隐藏文件 -l 以列表的方式显示信息 -al 以列表方式显示所有文件和目录 cd change directory 切换目录 cd [选项] 常用选项 cd ~ 或者 cd : 回到自己的home目录 cd.. 回到当前目录的上一级目录 mkdir make directory创建目录 mkdir -p [目录] 可以一次创建多级目录 rmdir remove direcotry 删除空目录 rm -rf 删除非空目录 touch 创建空文件 可以一次创建多个 cp 拷贝文件到具体目录 cp [选项] source dest 常用选项 -r 递归复制整个文件夹 rm rm [选项] 要删除的文件或目录 常用选项 -r 递归删除整个文件夹 -f 强制删除不提示 mv 移动或者重命名文件或目录 重命名: mv oldNameFile new NameFile 移动: mv /temp/movefile /targerFolder cat 查看文件内容(只读) cat [选项] 文件 常用选项 -n 显示行号 常和more一起使用,分页显示,空格翻页 cat -n file | more more more指令是一个基于vi编辑器的文本过滤器,它以全屏幕的方式按页显示文本文件的内容 若干快捷键 space 翻页 Enter 向下翻一行 q 立刻离开more Ctrl+F 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行行号 :f 输出文件名和当前行行号 less 分屏查看文件内容, 与more相似,但是更强大 less显示内容时,不是一次加载整个文件后才显示,而是根据显示需要加载内容,对于大型文件有很高的效率 若干快捷键 space 翻页 pagedown 翻页 pageup 上一页 /字串 向下搜寻字串 n: 向下查找 N:向上查找 ?字串 向上搜寻字串 n: 向下查找 N:向上查找 q 离开less &gt; 和 &gt;&gt; **&gt; **输出重定向: 会将原来的文件内容覆盖 &gt;&gt; 追加: 不会覆盖原文件内容,而是追加到文件的尾部 语法 ls -l &gt; 文件 列表的内容写入文件中(常用) ls -al &gt; 文件 列表的内容追加到文件的结尾 cat 文件1 &gt; 文件2 将文件1的内容覆盖到文件2 echo 内容 &gt;&gt; 文件 echo 输出内容到控制台 echo [选项] 输出内容 echo $PATH head 显示文件开头部分内容,默认前十行 head 文件 head -n 5 文件 指定显示前5行 tail 显示文件尾部的内容,默认后10行 tail 文件 tail -n 5 文件: 查看文件后5行内容 tail -f 文件: 实时跟踪文档的所有更新 ln 软链接,也叫符号连接,存放了链接其他文件的路径 语法 ln -s [原文件或目录] [软连接名]: 给原文件创建一个软链接 注意: 删除的时候直接rm -rf, 但是不要带后面斜杠 使用pwd指令查看目录时,仍然看到的是软链接的目录 history 查看已经执行过的历史指令 语法 history 显示所有的 history 10: 显示最近的10个 !+编号直接调用某指令: !178 时间日期类date 显示当前日期 语法 date [格式] 显示当前时间 date +%Y 显示当前年 date +%m 显示当前月份 date +%d 显示当前日 date “+%Y-%M-%d %H:%M:%S” 显示当前年月日时分秒 设置当前日期 date -s 字符串时间 cal 查看日历 语法 cal [选项] 不加选项显示本月日历 cal 2020 显示2020年的日历 搜索查找类find 从指定目录向下递归遍历各个子目录,将满足条件的文件或目录显示 语法 find [搜索范围] [选项] 常用选项 -name&lt;查询方式&gt; 按照指定的文件名查找模式查找文件 可以使用通配符: find / -name *.txt -user&lt;用户名&gt; 查找属于指定用户名所有文件 -size&lt;文件大小&gt; 按照指定的文件大小查找文件 find / -size +20M 大于 find / -size -20M 小于 find / -size 20M 等于 locate 快速定位文件路径. 利用事先建立的系统中所有文件名称及路径的locate数据库事先快速定位给定的文件. locate指令无需遍历整个文件系统,查询速度较快.为了保证查询结果的准确度,管理员必须定期更新locate数据库 语法 locate 搜索文件 注意 第一次运行前,,必须使用updatedb指令创建locate数据库 grep 和 管道符| grep过滤查找 管道符 | 标识将前一个命令的处理结果输出传递给后面的命令处理 语法 grep [选项] 查找内容 源文件 常用选项 -n 显示匹配行及行号 -i 忽略字母大小写 cat hello.txt | grep -ni y 压缩解压缩gzip/gunzip gzip 压缩,只能压缩为*.gz文件 压缩后原文件不保留 gunzip 解压缩 zip/unzip 压缩: zip [选项] xxx.zip 将要压缩的内容 zip -r mypackage /home(压缩home文件夹为mypackage) 解压缩: unzip [选项] 将要解压缩的内容 常用选项 -r 递归压缩 -d 指定解压后文件的存放目录 tar 打包指令 语法 tar [选项] xxx.tar.gz 打包的内容 (打包目录,压缩后的文件格式为.tar.gz) 常用选项 -c 产生.tar打包文件 -v 显示详细信息 -f 指定压缩后的文件名 -z 打包同时压缩 -x 解包.tar文件 常用: (zcvf zxvf) 两种: 压缩 zcvf 解压缩 zxvf tar -zcvf a.tar.gz a1.txt a2.txt (将a1和a2打包为a.tar.gz) tar -zxvf a.tar.gz (将a.tar.gz解压到当前目录) tar -zxvf a.tar.gz -C /opt/ (将a.tar.gz解压到opt目录,opt目录要存在, -C代表change) 组管理和权限管理文件/目录所有者 一般为文件的创建者 查看文件的所有者 ls -ahl 修改文件所有者 chown [指令] userName fileName chown userName:groupName filaName修改的同时修改文件所属组 常用指令 -R 递归修改其下所有文件和目录 查看文件/目录所在组 ls -ahl 修改文件所在组 chgrp groupName fileName 其他组 除了文件的所有者和所在组的用户外, 系统的其他用户都是文件的其他组 改变用户所在组 usermod -g groupName userName 权限管理文件基本属性 在 Linux 中第一个字符代表这个文件是目录、文件或链接文件等等。 当为 d 则是目录 当为 - 则是文件； 若是 l 则表示为链接文档(link file)； 若是 b 则表示为装置文件里面的可供储存的接口设备(可随机存取装置)； 若是 c 则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。 rwx权限详解 r: read. w: write, x: execute rwx作用到文件 r代表可读:可以读取,查看 w代表可写: 可以修改,但是不代表可以删除文件,删除一个文件的前提条件是对该文件所在的目录有写权限,才能删除该文件 x代表可以被执行 rwx作用到目录 r代表可读: 可以读取, ls查看目录 w代表可写: 可以修改,目录内创建/删除/重命名目录 x代表可执行:可以进入该目录 修改权限chmod 第一种方式: + - = 变更权限 u: 所有者 g: 所有组 o:其他人 a: 所有人(u,g,o的总和) 语法 chmod u=rwx,g=rx,o=x fileName/DictionaryName chmod o+w fileName/DictionaryName chmod a-x fileName/DictionaryName 示例 给abc文件的所有者读写执行权限,给所在组读执行权限,给其他组读执行权限chmod u=rwx,g=rx,o=rx abc 给abc文件的所有者除去执行的权限,增加组写权限chmod u=rwx,g=rx,o=rx abc 给abc文件的所有用户添加读的权限chmod a+r abc 第二种方式: 通过数字变更 r=4 w=2 x=1 rwx=4+2+1=7 语法 chmod u=rwx,g=rx,o=x fileName/DictionaryName相当于chmod 751 fileName/DictionaryName crond任务调度 任务调度: 指系统在某个时间执行的特定的命令或程序 任务调度分类: 系统工作: 有些重要的工作必须周而复始地执行 个别用户工作: 希望执行某些程序,如对数据库的备份 crontab 语法 crontab [选项] 常用选项 -e 编辑crontab定时任务 -l 查询crontab任务 -r 删除当前用户所有的crontab任务 步骤 cron -e */1 * * * * ls -l /etc &gt;&gt; /tmp/to.txt 保存后退出 在每一分钟都会调用ls -l /etc &gt;&gt; /tmp/to.txt 参数说明(具体详见cron表达式) 第一个*: 一小时中的第几分钟 0-59 第二个*:一天中第几小时 0-23 第三个*: 一个月当中的第几天 1-31 第四个*: 一年当中的第几月 1-12 第五个*: 一周当中的星期几 0-7(0和7都是星期日) 示例 每隔一分钟,将当前的日期信息,追加到/tmp/mydate文件中 先编写一个文件 /home/mytask1.sh 写入date &gt;&gt; /tmp/mydate 给mytask1.sh一个可执行权限chmod 744 mytask1.sh crontab -e 写入 */1 * * * * /home/mytask1.sh 每天凌晨2:00将mysql数据库testdb,备份到文件中mydb.bak 先编写一个文件/home/mytask2.sh 写入 /usr/local/mysql/bin/mysqldump -u root -proot testdb &gt; /tmp/mydb.bak 给mytask2.sh一个可执行权限chmod 744 mytask2.sh crontab -e 写入 0 2 * * * /home/mytask2.sh 磁盘分区和挂载分区方式mbr分区 最多支持四个主分区 系统只能安装在主分区 扩展分区要占一个主分区 MBR最大只支持2TB,但具有最好的兼容性 gtp分区 支持无限多个主分区(但操作系统可能限制,如windows下最多128个) 最大支持18EB的最大容量 (EB=1024PB, PB=1024TB) Windows7 64位之后支持gtp Linux分区 Linux 无论有几个分区,分给哪一个目录使用,它归根到底就只有一个跟目录,一个独立且唯一的文件结构. Linux中每个分区都是用来组成整个文件系统的一部分 Linux 采用了一种叫”载入”的处理方法,它的整个文件系统中包含了一整套的文件和目录,且将一个分区和一个目录联系起来. 这时要载入的一个分区将使它的存储空间在一个目录下获得 如何增加磁盘 虚拟机添加磁盘 分区fdish /dev/sdb 格式化mkfs -t ext4 /dev/sdb1 ext4是分区类型 挂载(指令: mount 设备名 挂载目录)(卸载: umount 设备名或者挂载目录) 先创建一个目录 /home/newdisk 挂载mount /dev/sdb1 /home/newdisk(卸载 umount /dev/sdb1 或者 umount /newdisk) 设置自动挂载(重启系统,仍然挂载) vim etc/fstab 写入 /dev/sdb1 /home/newdisk ext4 defaults 0 0 磁盘情况查询查询系统整体磁盘使用情况 语法 df [选项] 常用选项 -h -l -lh 查询指定目录的磁盘占用情况 语法 du [选项] 常用选项 -s 指定目录大小汇总 -h 带人类可读性大小 -a 含文件 –max-depth=1 子目录深度 -c 列出明细的同时,增加汇总值 示例 查询opt目录占用情况,深度为1 du -ach --max-depth=1 /opt 统计目录下文件个数 ls -l /home | grep &quot;^-&quot; | wx -l 统计目录以及目录下目录个数 ls -lR /home | grep &quot;^d&quot; | wx -l 树状结构显示 tree 目录 未安装指令使用yum install tree安装 网络配置查看网络连接ping 目的主机 配置自动获取 每次启动自动获取的ip不一样, 不适用于服务器 指定固定ip (推荐) 直接修改配置文件来指定IP,并可以连接到外网 编辑 vi /etc/sysconfig/network-scripts/ifcfg-eth0 修改IPADDR GATEWAY 指定网关 DNS1 dns和网关保持一致即可 BOOTPROTO=static 表示以静态方式获取ip ONBOOT=yes 启动boot配置成yes 重启网络服务或者系统生效 service netword restart reboot 进程管理基本介绍 linux中,每个执行的程序都成为一个进程.每一个进程都分配一个ID号 每一个进程都会对应一个父进程,而这个父进程可以复制多个子进程.例如www服务器 每个进程都可能以两种方式存在的. 前台与后台 前台进程是用户目前的屏幕上可以进行操作的. 后台进程则是实际在操作,但由于屏幕上无法看到的进程,通常使用后台方式执行 一般系统的服务都是以后台进程的方式存在,而且都会常驻在系统中.直到关机 显示系统执行的进程ps命令 用来查看目前系统中,进程的执行状况 选项: -a 显示当前终端的所有进程信息 -u 以用户的形式显示进程信息 -x 显示后台进程运行的参数 示例 ps -aux信息全面 ps -aux | grep xxx 将结果交给grep过滤 ps -ef | more PID 进程号 PPID 父进程ID 指令说明 System V展示风格 USER: 用户名称 PID: 进程号 %CPU: 进程占用CPU的百分比 %MEM: 进程占用物理内存的百分比 VSZ: 进程占用的虚拟内存大小(单位KB) RSS: 进程占用的物理内存大小(单位KB) TT: 终端名称,缩写. STAT: 进程状态 S: 睡眠 s: 表示该进程是会话的先导进程 N: 表示进程拥有比普通优先级更低的优先级 R: 正在运行 D: 短期等待 Z: 僵死进程 T: 被跟踪或者被停止等等 STARTED: 进程的启动时间 TIME: CPU时间,即进程和私用CPU的总时间 COMMAND: 启动进程所用的命令和参数,如果过长会被截断显示 kill和killall 停止进程 语法 kill [选项] 进程号 killall 进程名称 (通过进程名称杀死进程,支持通配符,在系统引负载过大变得很慢的时候很有用) 常用选项 -9: 表示强迫进程立即停止 示例 踢出用户 ps -aux | grep sshd查看 kill pid pstree 以树状的形式来展示进程信息 语法 pstree [选项] 常用选项 -p: 显示进程的pid -u: 显示进程的所属用户 服务管理服务本质就是进程,但是是运行在后台的,通常都会监听某个端口,等待其他程序的请求,比如mysql,sshd,防火墙.因此我们又成为守护进程,是非常重要的知识点 管理指令service 服务名 [start | stop | restart | reload | status] 在CentOS7.0之后不再使用service,而是systemctl 查看防火墙状态: systemctl status firewalld.service (CentOS8) 启动防火墙: systemctl start firewalld.service 注意: 关闭或者启用防火墙后,立即生效 这种方式只是临时生效, 当重启系统后,还是回归之前对服务的配置 如果希望设置某个服务自启动或关闭永久生效,需要使用chkconfig指令 查看服务名systemctl list-unit-files ls -l /usr/lib/systemd/ ls -l /etc/init.d/(CentOS8测试无效) 查看服务运行级别运行级别 如果不小心将默认的运行级别设置成0或者7,怎么处理? 进入单用户模式,修改成正常的! chkconfig&amp;systemctl 可以给每个运行级别设置自启动/关闭 语法: 旧版系统 查看服务: chkconfig --list | grep xxx chkconfig 服务名 --list chkconfig --level 5 服务名 on/off 新版CentOS systemctl list-units --type=service systemctl list-dependencies 动态监控进程top 与ps命令相似.他们都用来显示正在执行的进程. 不同之处在于top在执行一段时间可以更新正在运行的进程 语法 top [选项] 选项 选项 功能 -d秒数 指定top命令每隔几秒更新.默认是3秒 -i 使top不显示任何闲置或者僵死进程 -p 通过指定监控进程ID来仅仅监控某个进程的状态 交互操作说明 操作 功能 P 以CPU使用率排序,默认就是此项 M 以内存的使用率排序 N 以PID排序 q 退出top 查看系统网络情况netstat 语法 netstat [选项] 常用选项 -an 按一定顺序排列输出 -p 显示哪个进程在调用 示例 查看系统所有的网络服务 netstat -anp RPM包的管理 一种用于互联网下载包的打包及安装工具. 包含在某些Linux分发版中 生成具有.RPM拓展名的文件. RPM是RedHat Package Manager的缩写 公认的业内标准, suse,redhat,centos都有采用 查询指令 语法: rpm [选项] 示例 查询已安装的rpm列表: rpm -qa | grep xx,rpm -qa | more 查询软件包是否安装: rpm -q firefox 查询软件包信息: rpm -qi file 查询软件包中的文件: rpm -ql firefox 查询文件所属的软件包: rpm -qf /etc/password(使用文件全路径名) 卸载rpm -e 包名 注意: 如果其他软件包依赖于要删除的软件包,卸载会产生错误信息 强制删除: 增加参数 –nodeps 但是一般不推荐这么做,因为依赖与该软件包的程序可能无法运行 安装rpm -ivh 包名 i=install安装 v=verbose提示 h=hash进度条 yum yum是一个Shell前端软件包管理器. 基于RPM包管理. 能够从指定的服务器自动下载RPM包并且安装,可以自动处理依赖性关系,并且一次安装所有依赖的安装包 使用前提: 联网 基本指令 查询yum服务器是否有需要安装的软件 yum list | grep xx 安装指定的yum包 yum install xxx","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/tags/Linux/"}]},{"title":"Ant风格路径表达式","slug":"Ant风格路径表达式","date":"2021-02-03T09:56:04.000Z","updated":"2021-02-03T09:56:44.000Z","comments":true,"path":"2021/02/03/Ant风格路径表达式/","link":"","permalink":"http://yiiiqing.github.io/2021/02/03/Ant%E9%A3%8E%E6%A0%BC%E8%B7%AF%E5%BE%84%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"ANT通配符有三种： 通配符 说明 ? 匹配任何单字符 * 匹配0或者任意数量的字符 ** 匹配0或者更多的目录 例子： URL路径 说明 /app/*.x 匹配(Matches)所有在app路径下的.x文件 /app/p?ttern 匹配(Matches) /app/pattern 和 /app/pXttern,但是不包括/app/pttern /**/example 匹配(Matches) /app/example, /app/foo/example, 和 /example /app/*/dir/file. 匹配(Matches) /app/dir/file.jsp, /app/foo/dir/file.html,/app/foo/bar/dir/file.pdf, 和 /app/dir/file.java /*/.jsp 匹配(Matches)任何的.jsp 文件 最长匹配原则(has more characters)URL请求/app/dir/file.jsp，现在存在两个路径匹配模式/*/.jsp和/app/dir/.jsp，那么会根据模式/app/dir/.jsp来匹配 链接：https://www.jianshu.com/p/189847a7d1c7","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"Ant","slug":"Ant","permalink":"http://yiiiqing.github.io/tags/Ant/"}]},{"title":"SpringBoot启动过程","slug":"SpringBoot启动过程","date":"2021-02-02T11:08:55.000Z","updated":"2021-02-02T11:09:49.000Z","comments":true,"path":"2021/02/02/SpringBoot启动过程/","link":"","permalink":"http://yiiiqing.github.io/2021/02/02/SpringBoot%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/","excerpt":"","text":"启动过程转载: https://www.yuque.com/atguigu/springboot/tmvr0e SpringBoot启动过程 创建 SpringApplication 保存一些信息。 判定当前应用的类型。ClassUtils。Servlet bootstrappers**：初始启动引导器（List**）：去spring.factories文件中找 org.springframework.boot.Bootstrapper 找 ApplicationContextInitializer；去spring.factories**找** ApplicationContextInitializer List&lt;ApplicationContextInitializer&lt;?&gt;&gt; initializers 找 ApplicationListener ；应用监听器。去spring.factories**找** ApplicationListener List&lt;ApplicationListener&lt;?&gt;&gt; listeners 运行 SpringApplication StopWatch 记录应用的启动时间 创建引导上下文（Context环境）**createBootstrapContext()** 获取到所有之前的 bootstrappers 挨个执行 intitialize() 来完成对引导启动器上下文环境设置 让当前应用进入headless模式。java.awt.headless 获取所有 RunListener**（运行监听器）【为了方便所有Listener进行事件感知】** getSpringFactoriesInstances 去spring.factories**找** SpringApplicationRunListener. 遍历 SpringApplicationRunListener 调用 starting 方法； 相当于通知所有感兴趣系统正在启动过程的人，项目正在 starting。 保存命令行参数；ApplicationArguments 准备环境 prepareEnvironment（）; 返回或者创建基础环境信息对象。StandardServletEnvironment 配置环境信息对象。 读取所有的配置源的配置属性值。 绑定环境信息 监听器调用 listener.environmentPrepared()；通知所有的监听器当前环境准备完成 创建IOC容器（createApplicationContext（）） 根据项目类型（Servlet）创建容器， 当前会创建 AnnotationConfigServletWebServerApplicationContext 准备ApplicationContext IOC容器的基本信息 prepareContext() 保存环境信息 IOC容器的后置处理流程。 应用初始化器；applyInitializers； 遍历所有的 ApplicationContextInitializer 。调用 initialize.。来对ioc容器进行初始化扩展功能 遍历所有的 listener 调用 contextPrepared。EventPublishRunListenr；通知所有的监听器contextPrepared 所有的监听器 调用 contextLoaded。通知所有的监听器 contextLoaded； 刷新IOC容器。refreshContext 创建容器中的所有组件（Spring注解） 容器刷新完成后工作？afterRefresh 所有监听 器 调用 listeners.started(context); 通知所有的监听器 started 调用所有runners；callRunners() 获取容器中的 ApplicationRunner 获取容器中的 CommandLineRunner 合并所有runner并且按照@Order进行排序 遍历所有的runner。调用 run 方法 如果以上有异常， 调用Listener 的 failed 调用所有监听器的 running 方法 listeners.running(context); 通知所有的监听器 running running如果有问题。继续通知 failed 。**调用所有 Listener 的** failed；**通知所有的监听器** failed","categories":[],"tags":[]},{"title":"SpringBoot-Actuator","slug":"SpringBoot-Actuator","date":"2021-02-01T06:42:34.000Z","updated":"2021-02-01T08:38:36.000Z","comments":true,"path":"2021/02/01/SpringBoot-Actuator/","link":"","permalink":"http://yiiiqing.github.io/2021/02/01/SpringBoot-Actuator/","excerpt":"","text":"SpringBoot Actuator简介Actuator是SpringBoot抽取出来的指标监控模块 使用步骤 引入场景 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 访问 http://localhost:8080/actuator 配置 因为默认的http配置仅仅暴露少数endpoints, 想看到其他信息需要我们配置 在application.properties中加入 全部开启 1234# management 是所有actuator的配置management.endpoints.enabled-by-default=true# web方式暴露所有端点management.endpoints.web.exposure.include=* 手动开启 12management.endpoint.health.show-details=alwaysmanagement.endpoint.health.enabled=true 访问其他监控模块数据 http://localhost:8080/actuator/beans http://localhost:8080/actuator/configprops http://localhost:8080/actuator/metrics http://localhost:8080/actuator/metrics/jvm.gc.pause http://localhost:8080/actuator/endpointName/detailPath 等等… 数据格式为json: 可以使用安装了json解析插件的chrome浏览器或者火狐浏览器查看 EndPoint最常使用的端点 ID 描述 auditevents 暴露当前应用程序的审核事件信息。需要一个AuditEventRepository组件。 beans 显示应用程序中所有Spring Bean的完整列表。 caches 暴露可用的缓存。 conditions 显示自动配置的所有条件信息，包括匹配或不匹配的原因。 configprops 显示所有@ConfigurationProperties。 env 暴露Spring的属性ConfigurableEnvironment flyway 显示已应用的所有Flyway数据库迁移。 需要一个或多个Flyway组件。 health 显示应用程序运行状况信息。 httptrace 显示HTTP跟踪信息（默认情况下，最近100个HTTP请求-响应）。需要一个HttpTraceRepository组件。 info 显示应用程序信息。 integrationgraph 显示Spring integrationgraph 。需要依赖spring-integration-core。 loggers 显示和修改应用程序中日志的配置。 liquibase 显示已应用的所有Liquibase数据库迁移。需要一个或多个Liquibase组件。 metrics 显示当前应用程序的“指标”信息。 mappings 显示所有@RequestMapping路径列表。 scheduledtasks 显示应用程序中的计划任务。 sessions 允许从Spring Session支持的会话存储中检索和删除用户会话。需要使用Spring Session的基于Servlet的Web应用程序。 shutdown 使应用程序正常关闭。默认禁用。 startup 显示由ApplicationStartup收集的启动步骤数据。需要使用SpringApplication进行配置BufferingApplicationStartup。 threaddump 执行线程转储。 如果您的应用程序是Web应用程序（Spring MVC，Spring WebFlux或Jersey），则可以使用以下附加端点： ID 描述 heapdump 返回hprof堆转储文件。 jolokia 通过HTTP暴露JMX bean（需要引入Jolokia，不适用于WebFlux）。需要引入依赖jolokia-core。 logfile 返回日志文件的内容（如果已设置logging.file.name或logging.file.path属性）。支持使用HTTPRange标头来检索部分日志文件的内容。 prometheus 以Prometheus服务器可以抓取的格式公开指标。需要依赖micrometer-registry-prometheus。 最常用的Endpoint Health：监控状况 Metrics：运行时指标 Loggers：日志记录 健康监控 常用于应用健康检查 配置显示详细信息management.endpoint.health.show-details=always 访问http://localhost:8080/actuator/health Metrics 提供详细的、层级的、空间指标信息，这些信息可以被pull（主动推送）或者push（被动获取）方式得到 定制Endpoint定制health信息 在项目中建一个package名为health用于配置 新建一个类继承AbstractHealthIndicator,并重写方法doHealthCheck 12345678910111213141516171819202122232425262728293031@Componentpublic class MyComHealthIndicator extends AbstractHealthIndicator &#123; /** * 真实的检查方法 * @param builder * @throws Exception */ @Override protected void doHealthCheck(Health.Builder builder) throws Exception &#123; //mongodb。 获取连接进行测试 Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); // 检查完成 if(1 == 2)&#123;// builder.up(); //健康 builder.status(Status.UP); map.put(&quot;count&quot;,1); map.put(&quot;ms&quot;,100); &#125;else &#123;// builder.down(); builder.status(Status.OUT_OF_SERVICE); map.put(&quot;err&quot;,&quot;连接超时&quot;); map.put(&quot;ms&quot;,3000); &#125; builder.withDetail(&quot;code&quot;,100) .withDetails(map); &#125;&#125; 在localhost:8080/actuator/health访问可以看到我们定制的信息 自定义info 编写配置文件 12info.app:saas-taginfo.version:1.0.0 直接访问http://localhost:8080/actuator/info 自定义 123456789101112131415161718192021package com.famesmart.actuator.info;import org.springframework.boot.actuate.info.Info;import org.springframework.boot.actuate.info.InfoContributor;import org.springframework.stereotype.Component;import java.util.Collections;/** * @Author Yiqing Zhang * @Date 2021-02-01 3:25 p.m. * @Version 1.0 */@Componentpublic class AppInfoInfoContributor implements InfoContributor &#123; @Override public void contribute(Info.Builder builder) &#123; builder.withDetail(&quot;msg&quot;,&quot;Hello&quot;) .withDetails(Collections.singletonMap(&quot;world&quot;,&quot;123&quot;)); &#125;&#125; 显示的是所有信息结合 定制Metrics增加我们自定义的Metrics 12345678910111213141516class MyService&#123; Counter counter; public MyService(MeterRegistry meterRegistry)&#123; counter = meterRegistry.counter(&quot;myservice.method.running.counter&quot;); &#125; public void hello() &#123; counter.increment(); &#125;&#125;//也可以使用下面的方式@BeanMeterBinder queueSize(Queue queue) &#123; return (registry) -&gt; Gauge.builder(&quot;queueSize&quot;, queue::size).register(registry);&#125; 定制EndPoint 自定义类 123456789101112131415161718192021222324252627282930package com.famesmart.actuator.endpoint;import org.springframework.boot.actuate.endpoint.annotation.Endpoint;import org.springframework.boot.actuate.endpoint.annotation.ReadOperation;import org.springframework.boot.actuate.endpoint.annotation.WriteOperation;import org.springframework.stereotype.Component;import java.util.Collections;import java.util.Map;/** * @Author Yiqing Zhang * @Date 2021-02-01 4:04 p.m. * @Version 1.0 */@Component@Endpoint(id=&quot;myService&quot;)public class MyServiceEndPoint &#123; @ReadOperation public Map getDockerInfo()&#123; // 端点的读操作 return Collections.singletonMap(&quot;dockerInfo&quot;,&quot;docker started...&quot;); &#125; @WriteOperation public void stopDocker()&#123; System.out.println(&quot;docker stopped...&quot;); &#125;&#125; 访问我们自定义id的链接 可视化页面 新建一个spring-boot项目作为server 在pom引入 12345&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt;&lt;/dependency&gt; 其他服务作为客户端 在pom中引入 12345&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt;&lt;/dependency&gt; 配置 注意这个client.url写步骤1中的服务的地址 12spring.boot.admin.client.url=http://localhost:8888spring.application.name=saas-tag 启动server,打开网页","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"Actuator","slug":"Actuator","permalink":"http://yiiiqing.github.io/tags/Actuator/"}]},{"title":"SpringBoot-拦截器Interceptor","slug":"SpringBoot-拦截器Interceptor","date":"2021-01-22T03:09:46.000Z","updated":"2021-01-30T13:00:52.000Z","comments":true,"path":"2021/01/22/SpringBoot-拦截器Interceptor/","link":"","permalink":"http://yiiiqing.github.io/2021/01/22/SpringBoot-%E6%8B%A6%E6%88%AA%E5%99%A8Interceptor/","excerpt":"","text":"步骤和Filter区别 Filter是Servlet定义的原生组件.好处是脱离spring应用也能使用 Interceptor是Spring定义的接口.可以使用Spring的自动装配功能 自定义拦截器实现HandlerInterceptor接口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 登录检查 * 1、配置好拦截器要拦截哪些请求 * 2、把这些配置放在容器中 */@Slf4jpublic class LoginInterceptor implements HandlerInterceptor &#123; /** * 目标方法执行之前 * @param request * @param response * @param handler * @return * @throws Exception */ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String requestURI = request.getRequestURI(); log.info(&quot;preHandle拦截的请求路径是&#123;&#125;&quot;,requestURI); //登录检查逻辑 HttpSession session = request.getSession(); Object loginUser = session.getAttribute(&quot;loginUser&quot;); if(loginUser != null)&#123; //放行 return true; &#125; //拦截住。未登录。跳转到登录页 request.setAttribute(&quot;msg&quot;,&quot;请先登录&quot;);// re.sendRedirect(&quot;/&quot;); request.getRequestDispatcher(&quot;/&quot;).forward(request,response); return false; &#125; /** * 目标方法执行完成以后 * @param request * @param response * @param handler * @param modelAndView * @throws Exception */ @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; log.info(&quot;postHandle执行&#123;&#125;&quot;,modelAndView); &#125; /** * 页面渲染以后 * @param request * @param response * @param handler * @param ex * @throws Exception */ @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; log.info(&quot;afterCompletion执行异常&#123;&#125;&quot;,ex); &#125;&#125; 配置拦截器123456789101112131415/** * 1、编写一个拦截器实现HandlerInterceptor接口 * 2、拦截器注册到容器中（实现WebMvcConfigurer的addInterceptors） * 3、指定拦截规则【如果是拦截所有，静态资源也会被拦截】 */@Configurationpublic class AdminWebConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LoginInterceptor()) .addPathPatterns(&quot;/**&quot;) //所有请求都被拦截包括静态资源 .excludePathPatterns(&quot;/&quot;,&quot;/login&quot;,&quot;/css/**&quot;,&quot;/fonts/**&quot;,&quot;/images/**&quot;,&quot;/js/**&quot;); //放行的请求 &#125;&#125; 拦截器原理1、根据当前请求，找到HandlerExecutionChain【可以处理请求的handler以及handler的所有 拦截器】 2、先来顺序执行 所有拦截器的 preHandle方法 1、如果当前拦截器prehandler返回为true。则执行下一个拦截器的preHandle 2、如果当前拦截器返回为false。直接 倒序执行所有已经执行了的拦截器的 afterCompletion； 3、如果任何一个拦截器返回false。直接跳出不执行目标方法 4、所有拦截器都返回True。执行目标方法 5、倒序执行所有拦截器的postHandle方法。 6、前面的步骤有任何异常都会直接倒序触发 afterCompletion 7、页面成功渲染完成以后，也会倒序触发 afterCompletion 原文链接: https://www.yuque.com/atguigu/springboot/vgzmgh#B0ajH","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Interceptor","slug":"Interceptor","permalink":"http://yiiiqing.github.io/tags/Interceptor/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"NodeJS-express添加返回拦截器response interceptor","slug":"NodeJS-express添加返回拦截器response-interceptor","date":"2021-01-14T10:06:54.000Z","updated":"2021-01-30T04:06:27.000Z","comments":true,"path":"2021/01/14/NodeJS-express添加返回拦截器response-interceptor/","link":"","permalink":"http://yiiiqing.github.io/2021/01/14/NodeJS-express%E6%B7%BB%E5%8A%A0%E8%BF%94%E5%9B%9E%E6%8B%A6%E6%88%AA%E5%99%A8response-interceptor/","excerpt":"","text":"Express返回拦截器有时候需要在express返回结果之前,自定义一些内容.所以可以定义一个全局处理器 方法编写一个处理中间件改写express自己的方法(res.write, res.end等等) 示例一:123456789101112131415161718192021222324function modifyResponseBody(req, res, next) &#123; var oldWrite = res.write, oldEnd = res.end; var chunks = []; res.write = function(chunk) &#123; chunks.push(chunk); return oldWrite.apply(res, arguments); &#125;; res.end = function(chunk) &#123; if (chunk) chunks.push(chunk); var body = Buffer.concat(chunks).toString(&#x27;utf8&#x27;); console.log(req.path, body); oldEnd.apply(res, arguments); &#125;; next();&#125;module.exports = &#123; modifyResponseBody &#125;; 示例二:123456789101112function modifyResponseBody(req, res, next) &#123; var oldSend = res.send; res.send = function(data)&#123; // arguments[0] (or `data`) contains the response body arguments[0] = &quot;modified : &quot; + arguments[0]; oldSend.apply(res, arguments); &#125; next();&#125;module.exports = &#123; modifyResponseBody &#125;; 然后在项目根文件引用1app.use(modifyResponseBody); NOTE 如果使用了路由,需要引用在路由前面","categories":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/categories/Node-js/"}],"tags":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/tags/Node-js/"},{"name":"Interceptor","slug":"Interceptor","permalink":"http://yiiiqing.github.io/tags/Interceptor/"},{"name":"express","slug":"express","permalink":"http://yiiiqing.github.io/tags/express/"}]},{"title":".gitignore无效解决方法","slug":"gitignore无效解决方法","date":"2021-01-11T03:37:08.000Z","updated":"2021-01-11T03:41:47.000Z","comments":true,"path":"2021/01/11/gitignore无效解决方法/","link":"","permalink":"http://yiiiqing.github.io/2021/01/11/gitignore%E6%97%A0%E6%95%88%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"项目根目录新建.gitignore 1234.idealog/target/test/ 如果没有生效,原因是,gitignore智能忽略原来没有被track的文件,如果某些文件已经被纳入了版本管理中，则修改 .gitignore 是无效的。解决方法是先把本地缓存删除，然后再提交。 解决方法将本地缓存删除,然后再提交 1234git rm -r --cached .git add .git commit -m &quot;update .gitignore&quot;git push -u origin maste","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yiiiqing.github.io/tags/git/"}]},{"title":"SpringBoot-导出excel","slug":"SpringBoot-导出excel","date":"2021-01-08T09:58:05.000Z","updated":"2021-01-08T09:59:21.000Z","comments":true,"path":"2021/01/08/SpringBoot-导出excel/","link":"","permalink":"http://yiiiqing.github.io/2021/01/08/SpringBoot-%E5%AF%BC%E5%87%BAexcel/","excerpt":"","text":"步骤 引入依赖 12345678910111213&lt;!--excel--&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.poi/poi --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;4.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.poi/poi-ooxml --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;4.1.2&lt;/version&gt;&lt;/dependency&gt; 编写工具类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.famesmart.facearcface.uitls;import org.apache.poi.ss.usermodel.Cell;import org.apache.poi.ss.usermodel.Row;import org.apache.poi.ss.usermodel.Sheet;import org.apache.poi.ss.usermodel.Workbook;import org.apache.poi.xssf.usermodel.XSSFWorkbook;import java.io.File;import java.io.FileOutputStream;import java.util.List;import java.util.Map;import java.util.Set;/** * @Author Yiqing Zhang * @Date 2021-01-08 5:37 p.m. * @Version 1.0 */public class ExcelUtil &#123; public static void writeExcel(List&lt;Map&lt;String,Object&gt;&gt; dataList, String filePath) throws Exception &#123; //创建文件 File path = new File(filePath); if (!path.exists()) &#123; path.mkdirs(); &#125; String fileName = System.currentTimeMillis() + &quot;.xlsx&quot;; File file = new File(path, fileName); //创建一个excel对象 Workbook workbook = new XSSFWorkbook(); //创建第一个工作簿 Sheet sheet = workbook.createSheet(&quot;dbName&quot;); //将数据库字段（map的key）写入第一行 Map&lt;String, Object&gt; firstRowMap = dataList.get(0); Set&lt;String&gt; keySet = firstRowMap.keySet(); Object[] keyArr = keySet.toArray(); Row row0 = sheet.createRow(0); for (int i = 0; i &lt; keyArr.length; i++) &#123; //创建单元格并写入数据 Cell cell = row0.createCell(i); cell.setCellValue(keyArr[i].toString()); &#125; //将数据写入其他行 for (int i = 0; i &lt; dataList.size(); i++) &#123; //控制有多少行 Map&lt;String, Object&gt; rowMap = dataList.get(i); Row row = sheet.createRow(i + 1); for (int j = 0; j &lt; rowMap.size(); j++) &#123; Cell cell = row.createCell(j); Object o = rowMap.get((String) keyArr[j]); //除掉空值,也可以写入对应类型,此处直接写入string cell.setCellValue(null==o?&quot;&quot;:o.toString()); &#125; &#125; //输出文件 FileOutputStream fos = new FileOutputStream(file); workbook.write(fos); &#125;&#125;","categories":[],"tags":[]},{"title":"form表单提交RestFul","slug":"form表单提交RestFul","date":"2021-01-08T02:26:55.000Z","updated":"2021-01-08T02:49:01.000Z","comments":true,"path":"2021/01/08/form表单提交RestFul/","link":"","permalink":"http://yiiiqing.github.io/2021/01/08/form%E8%A1%A8%E5%8D%95%E6%8F%90%E4%BA%A4RestFul/","excerpt":"","text":"HTML表单html表单提交只有两种够选项: get和post 如何使用RestFul风格? 方法添加一个隐藏的参数_method 1&lt;input type=&quot;hidden&quot; name=&quot;_method&quot; value=&quot;PUT&quot;&gt; This can be done automatically in frameworks through the HTML creation helper method. 在常见的后台框架中,都会有转换的支持 比如在SpringBoot中 有一个核心Filter: hiddenHttpMethoddFilter 用法: 表单method=post, 隐藏域_method=put 原理: 请求是否正常,并且是POST 如果是,获取_method的值,转换为大写 兼容PUT,DELETE,PATCH requestWrapper(重写了getMethod方法,返回的是传入的值)包装原生request 过滤器链放行的是requestWrapper,以后的方法调用getMethod是调用的requestWrapper的 配置spring.mvc.hiddenmethod.filter的enabled为true即可生效 示例: 1234&lt;form action=&quot;/user&quot; method=&quot;post&quot;&gt; &lt;input name=&quot;_method&quot; type=&quot;hidden&quot; value=&quot;PUT&quot;/&gt; &lt;input value=&quot;REST-PUT&quot; type=&quot;submit&quot;/&gt;&lt;/form&gt;","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"RestFul","slug":"RestFul","permalink":"http://yiiiqing.github.io/tags/RestFul/"}]},{"title":"SpringBoot-获取项目根路径","slug":"SpringBoot-获取项目根路径","date":"2021-01-07T06:17:33.000Z","updated":"2021-01-07T06:19:41.000Z","comments":true,"path":"2021/01/07/SpringBoot-获取项目根路径/","link":"","permalink":"http://yiiiqing.github.io/2021/01/07/SpringBoot-%E8%8E%B7%E5%8F%96%E9%A1%B9%E7%9B%AE%E6%A0%B9%E8%B7%AF%E5%BE%84/","excerpt":"","text":"获取项目根路径 123456789101112131415161718192021222324/*** 获取项目根路径* * @return*/private static String getResourceBasePath() &#123; // 获取跟目录 File path = null; try &#123; path = new File(ResourceUtils.getURL(&quot;classpath:&quot;).getPath()); &#125; catch (FileNotFoundException e) &#123; // nothing to do &#125; if (path == null || !path.exists()) &#123; path = new File(&quot;&quot;); &#125; String pathStr = path.getAbsolutePath(); // 如果是在eclipse中运行，则和target同级目录,如果是jar部署到服务器，则默认和jar包同级 // pathStr = pathStr.replace(&quot;\\\\target\\\\classes&quot;, &quot;&quot;); pathStr = pathStr.replace(&quot;/target/classes&quot;, &quot;&quot;); return pathStr;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"Java-maven配置阿里镜像源","slug":"Java-maven配置阿里镜像源","date":"2021-01-06T01:50:12.000Z","updated":"2021-01-06T01:54:14.000Z","comments":true,"path":"2021/01/06/Java-maven配置阿里镜像源/","link":"","permalink":"http://yiiiqing.github.io/2021/01/06/Java-maven%E9%85%8D%E7%BD%AE%E9%98%BF%E9%87%8C%E9%95%9C%E5%83%8F%E6%BA%90/","excerpt":"","text":"将下面加入到项目的pom.xml中 12345678910111213141516171819202122232425262728&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;aliyun nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;aliyun nexus&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://yiiiqing.github.io/tags/maven/"}]},{"title":"Java-byte[]和String互转长度不符问题","slug":"Java-byte-和String互转长度不符问题","date":"2021-01-05T07:41:49.000Z","updated":"2021-01-06T01:51:21.000Z","comments":true,"path":"2021/01/05/Java-byte-和String互转长度不符问题/","link":"","permalink":"http://yiiiqing.github.io/2021/01/05/Java-byte-%E5%92%8CString%E4%BA%92%E8%BD%AC%E9%95%BF%E5%BA%A6%E4%B8%8D%E7%AC%A6%E9%97%AE%E9%A2%98/","excerpt":"","text":"其实就是编码格式的问题 这样转化就不会出错 123456789SecureRandom srandom = new SecureRandom();byte[] iv = new byte[128/8];srandom.nextBytes(iv); String ivs = new String(iv, &quot;ISO8859-1&quot;);iv = ivs.getBytes(&quot;ISO8859-1&quot;);System.out.println(iv.length);System.exit(1);IvParameterSpec ivspec = new IvParameterSpec(iv);","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"String","slug":"String","permalink":"http://yiiiqing.github.io/tags/String/"},{"name":"byte[]","slug":"byte","permalink":"http://yiiiqing.github.io/tags/byte/"}]},{"title":"tsconfig.json","slug":"tsconfig-json","date":"2021-01-04T11:17:24.000Z","updated":"2021-06-23T14:52:28.000Z","comments":true,"path":"2021/01/04/tsconfig-json/","link":"","permalink":"http://yiiiqing.github.io/2021/01/04/tsconfig-json/","excerpt":"","text":"123456789101112131415161718&#123; &quot;compilerOptions&quot;: &#123; &quot;experimentalDecorators&quot;: true, &quot;outDir&quot;: &quot;../dist&quot;, &quot;module&quot;: &quot;umd&quot;, &quot;target&quot;: &quot;es2016&quot;, &quot;sourceMap&quot;: true, &quot;noImplicitAny&quot;: true, &quot;strictNullChecks&quot;: true, &quot;removeComments&quot;: false, &quot;moduleResolution&quot;: &quot;node&quot; &#125;, &quot;exclude&quot;: [ &quot;node_modules&quot;, &quot;bower_components&quot;, &quot;dist&quot; ] &#125;","categories":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/categories/Node-js/"}],"tags":[{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"TypeScript","slug":"TypeScript","permalink":"http://yiiiqing.github.io/tags/TypeScript/"}]},{"title":"Java-ImageIO获取base64图片返回null","slug":"Java-ImageIO获取base64图片返回null","date":"2020-12-30T02:02:03.000Z","updated":"2020-12-30T02:08:04.000Z","comments":true,"path":"2020/12/30/Java-ImageIO获取base64图片返回null/","link":"","permalink":"http://yiiiqing.github.io/2020/12/30/Java-ImageIO%E8%8E%B7%E5%8F%96base64%E5%9B%BE%E7%89%87%E8%BF%94%E5%9B%9Enull/","excerpt":"","text":"今天项目中遇到一个问题, 将base64的图片转成ImageIO为null,但是在网页上转换是正确的 解决方法: 将base64前面的data:image/tif;base64,删掉 1base64str.split(&quot;,&quot;)[1]","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"base64","slug":"base64","permalink":"http://yiiiqing.github.io/tags/base64/"},{"name":"file","slug":"file","permalink":"http://yiiiqing.github.io/tags/file/"}]},{"title":"SpringBoot-static和@PostConstruct","slug":"SpringBoot-static和-PostConstruct","date":"2020-12-30T01:53:49.000Z","updated":"2020-12-30T01:56:06.000Z","comments":true,"path":"2020/12/30/SpringBoot-static和-PostConstruct/","link":"","permalink":"http://yiiiqing.github.io/2020/12/30/SpringBoot-static%E5%92%8C-PostConstruct/","excerpt":"","text":"static blocks are invoked when the class is being initialized, after it is loaded. The dependencies of your component haven’t been initialized yet. That is why you get a NullPointerException (Your dependencies are null) . Move your code to a method annotated with @PostConstruct. This will ensure that your code will run when all the dependencies of your component are initialized class被加载后,当class被初始化的时候static代码块会被调用。你的component组件的依赖还没有初始化。这就是为什么你的代码块会报空指针异常。（你的依赖都是null） 把你的代码移到一个@PostConstruct声明的方法块中，这样可以确保你的代码执行在所有组件都加载以后。","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"Maven-配置jdk编译版本和阿里仓库","slug":"Maven-配置jdk编译版本和阿里仓库","date":"2020-12-29T02:15:36.000Z","updated":"2020-12-29T02:37:33.000Z","comments":true,"path":"2020/12/29/Maven-配置jdk编译版本和阿里仓库/","link":"","permalink":"http://yiiiqing.github.io/2020/12/29/Maven-%E9%85%8D%E7%BD%AEjdk%E7%BC%96%E8%AF%91%E7%89%88%E6%9C%AC%E5%92%8C%E9%98%BF%E9%87%8C%E4%BB%93%E5%BA%93/","excerpt":"","text":"为了避免因为版本和不可说原因造成的问题,在maven配置中指定仓库地址和编译jdk版本 conf/.setting.xml 1234567891011121314151617181920212223&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://yiiiqing.github.io/tags/maven/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"镜像源","slug":"镜像源","permalink":"http://yiiiqing.github.io/tags/%E9%95%9C%E5%83%8F%E6%BA%90/"}]},{"title":"JavaScript excel导入","slug":"JavaScript-excel导入","date":"2020-12-26T03:46:15.000Z","updated":"2021-01-30T04:10:32.000Z","comments":true,"path":"2020/12/26/JavaScript-excel导入/","link":"","permalink":"http://yiiiqing.github.io/2020/12/26/JavaScript-excel%E5%AF%BC%E5%85%A5/","excerpt":"","text":"以下示例是基于koa+typescript的 1234567891011121314151617181920212223import XLSX from &#x27;xlsx&#x27;;import fs from &#x27;fs&#x27;;import path from &#x27;path&#x27;;export = &#123; import: async (ctx, next) =&gt; &#123; let file = ctx.req.file.filename; let &#123; projectCode &#125; = ctx.req.body; const xlsxFile = path.resolve(&#x27;./public&#x27;, file); async function readExcel() &#123; return new Promise((resolve, reject) =&gt; &#123; // read file let rawfile = fs.readFileSync(xlsxFile); file = XLSX.read(rawfile); // get json array let j_data = XLSX.utils.sheet_to_json(file.Sheets[file.SheetNames[0]]); // 移除自己添加的中文解释 j_data.shift(); resolve(j_data); &#125;); &#125; let data: any = await readExcel(); &#125;&#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"file","slug":"file","permalink":"http://yiiiqing.github.io/tags/file/"},{"name":"import","slug":"import","permalink":"http://yiiiqing.github.io/tags/import/"},{"name":"koa","slug":"koa","permalink":"http://yiiiqing.github.io/tags/koa/"}]},{"title":"Linux Ubuntu vi方向键ABCD的解决方法","slug":"Linux-Ubuntu-vi方向键ABCD的解决方法","date":"2020-12-25T05:13:29.000Z","updated":"2020-12-25T05:14:49.000Z","comments":true,"path":"2020/12/25/Linux-Ubuntu-vi方向键ABCD的解决方法/","link":"","permalink":"http://yiiiqing.github.io/2020/12/25/Linux-Ubuntu-vi%E6%96%B9%E5%90%91%E9%94%AEABCD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"方法1 命令行中执行： 12echo &quot;set nocp&quot;&gt;&gt;~/.vimrcsource ~/.vimrc 方法2如果能连上网，可以卸载原来的vim，重新安装vim 12sudo apt-get remove vim-commonsudo apt-get install vim","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"}],"tags":[{"name":"vi","slug":"vi","permalink":"http://yiiiqing.github.io/tags/vi/"}]},{"title":"Java-List存放Map,根据Map值排序","slug":"Java-List存放Map-根据Map值排序","date":"2020-12-23T07:08:55.000Z","updated":"2020-12-23T07:10:49.000Z","comments":true,"path":"2020/12/23/Java-List存放Map-根据Map值排序/","link":"","permalink":"http://yiiiqing.github.io/2020/12/23/Java-List%E5%AD%98%E6%94%BEMap-%E6%A0%B9%E6%8D%AEMap%E5%80%BC%E6%8E%92%E5%BA%8F/","excerpt":"","text":"方法: 利用Collections.sort方法,重写排序方法 123456789Collections.sort(list, new Comparator&lt;Map&lt;String, Object&gt;&gt;()&#123; public int compare(Map&lt;String, Object&gt; o1, Map&lt;String, Object&gt; o2) &#123; String name1 =(String)o1.get(&quot;id&quot;);//name1是从你list里面拿出来的一个 String name2= (String)o2.get(&quot;id&quot;); //name1是从你list里面拿出来的第二个name return name1.compareTo(name2); &#125; &#125;); 上面的实现方法是写了一个匿名内部类","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"排序","slug":"排序","permalink":"http://yiiiqing.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"Java String首字母大写","slug":"Java-String首字母大写","date":"2020-12-23T04:23:12.000Z","updated":"2020-12-23T05:09:17.000Z","comments":true,"path":"2020/12/23/Java-String首字母大写/","link":"","permalink":"http://yiiiqing.github.io/2020/12/23/Java-String%E9%A6%96%E5%AD%97%E6%AF%8D%E5%A4%A7%E5%86%99/","excerpt":"","text":"方法一: 将首字母截取1234public static String captureName(String name) &#123; name = name.substring(0, 1).toUpperCase() + name.substring(1); return name;&#125; 这种方法效率不高 方法二: ascii编码 前移1234567public static String captureName(String name) &#123; // name = name.substring(0, 1).toUpperCase() + name.substring(1); // return name; char[] cs=name.toCharArray(); cs[0]-=32; return String.valueOf(cs);&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"String","slug":"String","permalink":"http://yiiiqing.github.io/tags/String/"}]},{"title":"Mybatis-取值方法","slug":"Mybatis-取值方法","date":"2020-12-22T09:38:06.000Z","updated":"2020-12-23T05:09:11.000Z","comments":true,"path":"2020/12/22/Mybatis-取值方法/","link":"","permalink":"http://yiiiqing.github.io/2020/12/22/Mybatis-%E5%8F%96%E5%80%BC%E6%96%B9%E6%B3%95/","excerpt":"","text":"获取参数对于变量可以使用#&#123;param&#125; 方式进行拼接。mybatis 也支持$&#123;param&#125; 的方式。这两种方式的区别如下： #&#123;param&#125; 表示读取param参数的值，并将该值做字段的的值进行比较； $&#123;param&#125; 表示读取param的值，并将param值当成数据库表中的某个字段。 WHERE IN获取数组123456&lt;if test=&quot;ids != null&quot;&gt; WHERE id IN &lt;foreach collection=&quot;ids&quot; item=&quot;id&quot; index=&quot;index&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt; #&#123;id&#125; &lt;/foreach&gt;&lt;/if&gt;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yiiiqing.github.io/tags/Mybatis/"}]},{"title":"Node.js统一方法间错误处理","slug":"Node-js统一方法间错误处理","date":"2020-12-16T02:30:40.000Z","updated":"2020-12-16T02:42:29.000Z","comments":true,"path":"2020/12/16/Node-js统一方法间错误处理/","link":"","permalink":"http://yiiiqing.github.io/2020/12/16/Node-js%E7%BB%9F%E4%B8%80%E6%96%B9%E6%B3%95%E9%97%B4%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86/","excerpt":"","text":"service层解藕(Promise化)为了将service层解藕,我对项目进行了如下改造 将所有的方法的返回修改为promise 如果服务成功,返回resolve, 如果服务失败,返回reject 可以直接使用静态方法 12return Promise.resolve(msg)return Promise.reject(msg) 方法间使用async/await 统一错误格式因为可以自己定义错误信息,自由度高, 有的时候返回的错误是一个Error对象,有的时候可能是字符串 为了确保错误信息可以打印,可以进行判断 12345res.json(&#123; result: 1, msg: &#x27;失败!&#x27;, err: err &amp;&amp; err.message ? err.message : err&#125;); 错误处理方法 单独的一个服务,可以直接在promise的reject处理 1234567891011121314await service.functionA(param1,param2).then( () =&gt; &#123; res.json(&#123; result: 0, msg: &#x27;success!&#x27; &#125;); &#125;, err =&gt; &#123; res.json(&#123; result: 1, err: err &amp;&amp; err.message ? err.message : err &#125;); &#125;); 如果服务太多,可以统一使用try/catch 123456try&#123; await serviceA; await serviceB;&#125;catch(err)&#123; console.log(err)&#125;","categories":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/categories/Node-js/"}],"tags":[{"name":"Error","slug":"Error","permalink":"http://yiiiqing.github.io/tags/Error/"},{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/tags/Node-js/"}]},{"title":"JS 深拷贝","slug":"JS-深拷贝","date":"2020-12-15T09:06:04.000Z","updated":"2020-12-15T09:08:55.000Z","comments":true,"path":"2020/12/15/JS-深拷贝/","link":"","permalink":"http://yiiiqing.github.io/2020/12/15/JS-%E6%B7%B1%E6%8B%B7%E8%B4%9D/","excerpt":"","text":"深拷贝Object.assign1let a = Object.assign(&#123;&#125;,b)","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/tags/JavaScript/"}]},{"title":"SpringBoot-Controller接收参数","slug":"SpringBoot-Controller接收参数","date":"2020-12-15T02:07:01.000Z","updated":"2020-12-15T02:16:33.000Z","comments":true,"path":"2020/12/15/SpringBoot-Controller接收参数/","link":"","permalink":"http://yiiiqing.github.io/2020/12/15/SpringBoot-Controller%E6%8E%A5%E6%94%B6%E5%8F%82%E6%95%B0/","excerpt":"","text":"在springboot中使用注解接收参数获取参数的几种常用注解 @PathVariable: 如果是url/{param}这种restful风格的话,使用这种形式接收 123456@ApiOperation(&quot;根据id获取&quot;)@GetMapping(&quot;/&#123;id&#125;&quot;)public JsonResult&lt;Tag&gt; getTagById(@PathVariable(&quot;id&quot;) int id) &#123; Tag tag = tagService.getTagById(id); return new JsonResult&lt;&gt;(tag);&#125; @RequestParam: 获取多个参数的时候常用, 直接写参数名 @RequestBody: 与@RequestParam类似,将注解的所有参数转换为一个对象,比如DTO对象 12345@DeleteMapping(&quot;/resident&quot;)public JsonResult&lt;Integer&gt; deleteResidentTag(@ApiParam(name = &quot;residentTagDTO&quot;, value = &quot;居民tag实体&quot;, required = true) @RequestBody ResidentTagDTO residentTagDTO)&#123; int deleteResidentTag = residentTagService.deleteResidentTag(residentTagDTO); return new JsonResult&lt;&gt;(deleteResidentTag);&#125; 使用对象直接获取参数可以接收一个pojo来作为参数,然后通过get方法直接把需要的参数取出来即可 12345678/** * 添加用户2 * @param userInfo */@PostMapping(&quot;/createUser2&quot;)public void createUser2(UserInfo userInfo)&#123; userService.createUser(userInfo.getTel(),userInfo.getPassWord());&#125; 推荐: 使用Map接收参数也是使用@RequestBody注解,使用Map 可以使用在没有必要写一个DTO但是参数复杂的情况 123456@PostMapping(&quot;/createUserByMap&quot;)public void createUserByMap(@RequestBody Map&lt;String,Object&gt; reqMap)&#123; String tel = reqMap.get(&quot;tel&quot;).toString(); String pwd = reqMap.get(&quot;pwd&quot;).toString(); userService.createUser(tel,pwd);&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"MySQL-查询某天某个时间段的数据","slug":"MySQL-查询某天某个时间段的数据","date":"2020-12-14T08:13:17.000Z","updated":"2020-12-14T08:17:02.000Z","comments":true,"path":"2020/12/14/MySQL-查询某天某个时间段的数据/","link":"","permalink":"http://yiiiqing.github.io/2020/12/14/MySQL-%E6%9F%A5%E8%AF%A2%E6%9F%90%E5%A4%A9%E6%9F%90%E4%B8%AA%E6%97%B6%E9%97%B4%E6%AE%B5%E7%9A%84%E6%95%B0%E6%8D%AE/","excerpt":"","text":"查询每天某个时间段的数据早高峰1SELECT COUNT(*) AS count FROM table WHERE hour(created_at) BETWEEN 07 and 09 如果是凌晨需要转换 凌晨1SELECT COUNT(*) AS count FROM table WHERE hour(created_at) &gt;=22 or hour(created_at)&lt;= 6","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/tags/MySQL/"}]},{"title":"SpringBoot-CROS跨域","slug":"SpringBoot-CROS跨域","date":"2020-12-14T02:44:36.000Z","updated":"2020-12-14T02:47:58.000Z","comments":true,"path":"2020/12/14/SpringBoot-CROS跨域/","link":"","permalink":"http://yiiiqing.github.io/2020/12/14/SpringBoot-CROS%E8%B7%A8%E5%9F%9F/","excerpt":"","text":"解决springboot后端跨域的方法方法一配置mvc 1234567891011@Configurationpublic class MyWebMvcConfig implements WebMvcConfigurer &#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(&quot;/**&quot;) .allowedHeaders(&quot;*&quot;) .allowedMethods(&quot;*&quot;) .allowedOrigins(&quot;*&quot;); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"CROS","slug":"CROS","permalink":"http://yiiiqing.github.io/tags/CROS/"}]},{"title":"Mybatis selectKey","slug":"Mybatis-selectKey","date":"2020-12-10T04:42:19.000Z","updated":"2020-12-10T04:49:10.000Z","comments":true,"path":"2020/12/10/Mybatis-selectKey/","link":"","permalink":"http://yiiiqing.github.io/2020/12/10/Mybatis-selectKey/","excerpt":"","text":"原本项目的新增是使用的Mybatis默认的返回影响的条数 现在需要返回新增的信息回前端 于是使用了selectKey方法 1234567891011121314 &lt;!--新增信息，并拿到新增信息的表主键信息。 新增数据，得到主键的外层写法没什么特别，跟普通的insert一样。只不过里面加了selectKey--&gt;&lt;insert id=&quot;insertAndgetkey&quot; parameterType=&quot;com.soft.mybatis.model.User&quot;&gt; &lt;!--selectKey 会将 SELECT LAST_INSERT_ID()的结果放入到传入的model的主键里面， keyProperty 对应的model中的主键的属性名，这里是 user 中的id，因为它跟数据库的主键对应 order AFTER 表示 SELECT LAST_INSERT_ID() 在insert执行之后执行,多用与自增主键， BEFORE 表示 SELECT LAST_INSERT_ID() 在insert执行之前执行，这样的话就拿不到主键了， 这种适合那种主键不是自增的类型 resultType 主键类型 --&gt; &lt;selectKey keyProperty=&quot;id&quot; order=&quot;AFTER&quot; resultType=&quot;java.lang.Integer&quot;&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; insert into t_user (username,password,create_date) values(#&#123;username&#125;,#&#123;password&#125;,#&#123;createDate&#125;)&lt;/insert&gt; 使用方法见注释 但是按照原本的tagMapper.addTag(tag);仍然获取的是以前的条数1 原来是因为: 自增id直接映射到对象中了 直接使用getId()方法可以获取到id 所以直接简化了代码 12345@Overridepublic Tag addTag(Tag tag) &#123; tagMapper.addTag(tag); return tag;&#125; 传入的tag是没有id的; 返回的tag是已经有id的","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yiiiqing.github.io/tags/Mybatis/"}]},{"title":"bug-spring swagger3.0.0 post不显示reqeust body参数","slug":"bug-spring-swagger3-0-0-post不显示reqeust-body参数","date":"2020-12-10T03:26:21.000Z","updated":"2020-12-10T03:42:27.000Z","comments":true,"path":"2020/12/10/bug-spring-swagger3-0-0-post不显示reqeust-body参数/","link":"","permalink":"http://yiiiqing.github.io/2020/12/10/bug-spring-swagger3-0-0-post%E4%B8%8D%E6%98%BE%E7%A4%BAreqeust-body%E5%8F%82%E6%95%B0/","excerpt":"","text":"今天发现项目中swagger3.0.0版本的post方法的@ApiImplicitParam注解不生效, 经查询得知是swagger3.0.0 spring boot 启动器的bug 相关连接: https://stackoverflow.com/questions/38776088/spring-boot-swagger-swagger-ui-and-requestbody-has-data-type-string https://github.com/springfox/springfox/issues/1344 情况如下: 原本的接口注释为: 12345678910111213@ApiOperation(&quot;添加某tag至resident&quot;)@ApiImplicitParams(&#123; @ApiImplicitParam(name = &quot;residentId&quot;, value = &quot;居民id&quot;, dataTypeClass = Integer.class, paramType = &quot;body&quot;, example = &quot;44&quot;), @ApiImplicitParam(name = &quot;tagId&quot;, value = &quot;tag id&quot;, dataTypeClass = Integer.class, paramType = &quot;body&quot;, example = &quot;1&quot;)&#125;)@PostMapping(&quot;/resident&quot;)public JsonResult&lt;Integer&gt; addResidentTag(@RequestParam(&quot;residentId&quot;) int residentId, @RequestParam(&quot;tagId&quot;) int tagId) &#123; Resident resident = residentService.getResidentById(residentId); Tag tag = tagService.getTagById(tagId); int addResidentTag = residentTagService.addResidentTag(new ResidentTag(tag, resident)); return new JsonResult&lt;&gt;(addResidentTag);&#125; 上传参数为residentId和tagId,都是在body中,于是指定了参数body, 发现结果为空 尝试: 更改@RequestParam参数为@RequestBody: 不可取,因为@RequestBody参数是将上传的信息转化为对应的实体类的注解 修改paramType为form: 无效 在ApiOperation中添加consumes指定xml格式: 无效 于是决定新增dto类来使用RequestBody看看能不能解决 123456789101112@ApiModel(value = &quot;居民标签DTO模型&quot;)@Data@AllArgsConstructor@NoArgsConstructorpublic class ResidentTagDTO &#123; @ApiModelProperty(&quot;映射表id&quot;) private int id; @ApiModelProperty(&quot;居民id&quot;) private int residentId; @ApiModelProperty(&quot;标签id&quot;) private int tagId;&#125; 然后在Controller中修改参数为dto类,并且在该参数上加注解@ApiParam 123456789@ApiOperation( value = &quot;添加某tag至resident&quot;, consumes = &quot;application/json&quot;, notes = &quot;添加某tag到居民,这里只是单纯的添加关联,并没有进行重复检查和存在检查&quot;)@PostMapping(&quot;/resident&quot;)public JsonResult&lt;Integer&gt; addResidentTag( @ApiParam(name = &quot;residentTagDTO&quot;,value = &quot;添加tag至居民&quot;) @RequestBody ResidentTagDTO residentTagDTO) &#123; int addResidentTag = residentTagService.addResidentTag(residentTagDTO); return new JsonResult&lt;&gt;(addResidentTag);&#125; 这样的话结果是可以显示的","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Swagger","slug":"Swagger","permalink":"http://yiiiqing.github.io/tags/Swagger/"},{"name":"bug","slug":"bug","permalink":"http://yiiiqing.github.io/tags/bug/"}]},{"title":"SpringBoot-Redis","slug":"SpringBoot-Redis","date":"2020-12-10T01:59:51.000Z","updated":"2020-12-11T05:40:39.000Z","comments":true,"path":"2020/12/10/SpringBoot-Redis/","link":"","permalink":"http://yiiiqing.github.io/2020/12/10/SpringBoot-Redis/","excerpt":"","text":"在springboot中使用redis 在初始化时候在nosql选项中勾选redis,这样pom中会自动加载依赖 12345&lt;!--操作redis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 点进去后发现: 底层是spring-data-redis和lettuce(说明:在SpringBoot 2.X之后,原来使用的jedis被替换为了lettuce) jedis: 采用的是直连的方式,多线程操作的话,不安全. 想要避免的话,使用jedis pool连接池, 更像是BIO模式 lettuce: 采用netty, 实例可以在多个线程中共享,不存在线程不安全的情况,可以介绍线程数据, 更像是NIO模式 配置 在application.properties中配置 123# 配置redisspring.redis.host=127.0.0.1spring.redis.port=6379 测试 12345678910111213141516171819202122@Testvoid contextLoads() &#123; // redisTemplate 操作不同数据类型 // opsForValue 操作字符串 类似String // opsForList 操作List 类似List // opsForSet // opsForZSet // opsForHash // opsForGeo // opsForHyperLogLog // 除了基本的操作, 我们常用的方法都可以直接redisTemplete操作,比如事务和基本CRUD // 获取redis连接对象 RedisConnection connection = redisTemplate.getConnectionFactory().getConnection(); connection.flushDb(); connection.flushAll(); redisTemplate.opsForValue().set(&quot;mykey&quot;,&quot;一清&quot;); System.out.println(redisTemplate.opsForValue().get(&quot;mykey&quot;));&#125; 是可以打印出对象的 配置(自定义RedisTemplete)存入对象 新建一个配置类RedisConfig 1234567891011@Configurationpublic class RedisConfig &#123; // 编写我们自己的redisTemplate @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125; 编写一个pojo类 12345678@Component@AllArgsConstructor@NoArgsConstructor@Datapublic class User &#123; private String name; private int age;&#125; 测试 这里传入的对象被转化为了json ObjectMapper是来自Jackson包,可以序列化对象 1234567@Testpublic void test() throws JsonProcessingException &#123; User yiqing = new User(&quot;yiqing&quot;, 3); String jsonYiqing = new ObjectMapper().writeValueAsString(yiqing); redisTemplate.opsForValue().set(&quot;user&quot;,jsonYiqing); System.out.println(redisTemplate.opsForValue().get(&quot;user&quot;));&#125; 结果为&#123;&quot;name&quot;:&quot;yiqing&quot;,&quot;age&quot;:3&#125; 如果不转化为json,直接传入对象,将会报错 org.springframework.data.redis.serializer.SerializationException: Cannot serialize; nested exception is org.springframework.core.serializer.support.SerializationFailedException: Failed to serialize object using DefaultSerializer; nested exception is java.lang.IllegalArgumentException: DefaultSerializer requires a Serializable payload but received an object of type [zone.yiqing.pojo.User] 将User pojo加上序列化 123456789@Component@AllArgsConstructor@NoArgsConstructor@Data// 在企业中,所有的pojo都会序列化!public class User implements Serializable &#123; private String name; private int age;&#125; 测试 1234567@Testpublic void test() throws JsonProcessingException &#123; User yiqing = new User(&quot;yiqing&quot;, 3); // String jsonYiqing = new ObjectMapper().writeValueAsString(yiqing); redisTemplate.opsForValue().set(&quot;user&quot;,yiqing); System.out.println(redisTemplate.opsForValue().get(&quot;user&quot;));&#125; 结果为User(name=yiqing, age=3) 配置详情 基本固定,可以直接拿来使用1234567891011121314151617181920212223242526272829303132333435363738@Configurationpublic class RedisConfig &#123; /** * 编写自定义的 redisTemplate * 这是一个比较固定的模板 */ @Bean @SuppressWarnings(&quot;all&quot;) public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; // 为了开发方便，直接使用&lt;String, Object&gt; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); // Json 配置序列化 // 使用 jackson 解析任意的对象 Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;&gt;(Object.class); // 使用 objectMapper 进行转义 ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); // String 的序列化 StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // key 采用 String 的序列化方式 template.setKeySerializer(stringRedisSerializer); // Hash 的 key 采用 String 的序列化方式 template.setHashKeySerializer(stringRedisSerializer); // value 采用 jackson 的序列化方式 template.setValueSerializer(jackson2JsonRedisSerializer); // Hash 的 value 采用 jackson 的序列化方式 template.setHashValueSerializer(jackson2JsonRedisSerializer); // 把所有的配置 set 进 template template.afterPropertiesSet(); return template; &#125;&#125; 这样编写了key的序列化方式,将不会再有转义字符出现了 但是去获取这个对象或者中文字符串的时候还是会显示转义字符,解决方法: 在启动Redis客户端的时候加上-raw即可 redis-cli --raw -p 6379 编写Redis工具类(Redis Util)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561@Componentpublic final class RedisUtil &#123; @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; // =============================common============================ /** * 指定缓存失效时间 * @param key 键 * @param time 时间(秒) */ public boolean expire(String key, long time) &#123; try &#123; if (time &gt; 0) &#123; redisTemplate.expire(key, time, TimeUnit.SECONDS); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 根据key 获取过期时间 * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ public long getExpire(String key) &#123; return redisTemplate.getExpire(key, TimeUnit.SECONDS); &#125; /** * 判断key是否存在 * @param key 键 * @return true 存在 false不存在 */ public boolean hasKey(String key) &#123; try &#123; return redisTemplate.hasKey(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 删除缓存 * @param key 可以传一个值 或多个 */ @SuppressWarnings(&quot;unchecked&quot;) public void del(String... key) &#123; if (key != null &amp;&amp; key.length &gt; 0) &#123; if (key.length == 1) &#123; redisTemplate.delete(key[0]); &#125; else &#123; redisTemplate.delete(CollectionUtils.arrayToList(key)); &#125; &#125; &#125; // ============================String============================= /** * 普通缓存获取 * @param key 键 * @return 值 */ public Object get(String key) &#123; return key == null ? null : redisTemplate.opsForValue().get(key); &#125; /** * 普通缓存放入 * @param key 键 * @param value 值 * @return true成功 false失败 */ public boolean set(String key, Object value) &#123; try &#123; redisTemplate.opsForValue().set(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 普通缓存放入并设置时间 * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 * @return true成功 false 失败 */ public boolean set(String key, Object value, long time) &#123; try &#123; if (time &gt; 0) &#123; redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS); &#125; else &#123; set(key, value); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 递增 * @param key 键 * @param delta 要增加几(大于0) */ public long incr(String key, long delta) &#123; if (delta &lt; 0) &#123; throw new RuntimeException(&quot;递增因子必须大于0&quot;); &#125; return redisTemplate.opsForValue().increment(key, delta); &#125; /** * 递减 * @param key 键 * @param delta 要减少几(小于0) */ public long decr(String key, long delta) &#123; if (delta &lt; 0) &#123; throw new RuntimeException(&quot;递减因子必须大于0&quot;); &#125; return redisTemplate.opsForValue().increment(key, -delta); &#125; // ================================Map================================= /** * HashGet * @param key 键 不能为null * @param item 项 不能为null */ public Object hget(String key, String item) &#123; return redisTemplate.opsForHash().get(key, item); &#125; /** * 获取hashKey对应的所有键值 * @param key 键 * @return 对应的多个键值 */ public Map&lt;Object, Object&gt; hmget(String key) &#123; return redisTemplate.opsForHash().entries(key); &#125; /** * HashSet * @param key 键 * @param map 对应多个键值 */ public boolean hmset(String key, Map&lt;String, Object&gt; map) &#123; try &#123; redisTemplate.opsForHash().putAll(key, map); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * HashSet 并设置时间 * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) * @return true成功 false失败 */ public boolean hmset(String key, Map&lt;String, Object&gt; map, long time) &#123; try &#123; redisTemplate.opsForHash().putAll(key, map); if (time &gt; 0) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @return true 成功 false失败 */ public boolean hset(String key, String item, Object value) &#123; try &#123; redisTemplate.opsForHash().put(key, item, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 * @return true 成功 false失败 */ public boolean hset(String key, String item, Object value, long time) &#123; try &#123; redisTemplate.opsForHash().put(key, item, value); if (time &gt; 0) &#123; expire(key, time); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 删除hash表中的值 * * @param key 键 不能为null * @param item 项 可以使多个 不能为null */ public void hdel(String key, Object... item) &#123; redisTemplate.opsForHash().delete(key, item); &#125; /** * 判断hash表中是否有该项的值 * * @param key 键 不能为null * @param item 项 不能为null * @return true 存在 false不存在 */ public boolean hHasKey(String key, String item) &#123; return redisTemplate.opsForHash().hasKey(key, item); &#125; /** * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * * @param key 键 * @param item 项 * @param by 要增加几(大于0) */ public double hincr(String key, String item, double by) &#123; return redisTemplate.opsForHash().increment(key, item, by); &#125; /** * hash递减 * * @param key 键 * @param item 项 * @param by 要减少记(小于0) */ public double hdecr(String key, String item, double by) &#123; return redisTemplate.opsForHash().increment(key, item, -by); &#125; // ============================set============================= /** * 根据key获取Set中的所有值 * @param key 键 */ public Set&lt;Object&gt; sGet(String key) &#123; try &#123; return redisTemplate.opsForSet().members(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 根据value从一个set中查询,是否存在 * * @param key 键 * @param value 值 * @return true 存在 false不存在 */ public boolean sHasKey(String key, Object value) &#123; try &#123; return redisTemplate.opsForSet().isMember(key, value); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 将数据放入set缓存 * * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ public long sSet(String key, Object... values) &#123; try &#123; return redisTemplate.opsForSet().add(key, values); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 将set数据放入缓存 * * @param key 键 * @param time 时间(秒) * @param values 值 可以是多个 * @return 成功个数 */ public long sSetAndTime(String key, long time, Object... values) &#123; try &#123; Long count = redisTemplate.opsForSet().add(key, values); if (time &gt; 0) expire(key, time); return count; &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 获取set缓存的长度 * * @param key 键 */ public long sGetSetSize(String key) &#123; try &#123; return redisTemplate.opsForSet().size(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 移除值为value的 * * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ public long setRemove(String key, Object... values) &#123; try &#123; Long count = redisTemplate.opsForSet().remove(key, values); return count; &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; // ===============================list================================= /** * 获取list缓存的内容 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 */ public List&lt;Object&gt; lGet(String key, long start, long end) &#123; try &#123; return redisTemplate.opsForList().range(key, start, end); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 获取list缓存的长度 * * @param key 键 */ public long lGetListSize(String key) &#123; try &#123; return redisTemplate.opsForList().size(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125; /** * 通过索引 获取list中的值 * * @param key 键 * @param index 索引 index&gt;=0时， 0 表头，1 第二个元素，依次类推；index&lt;0时，-1，表尾，-2倒数第二个元素，依次类推 */ public Object lGetIndex(String key, long index) &#123; try &#123; return redisTemplate.opsForList().index(key, index); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 将list放入缓存 * * @param key 键 * @param value 值 */ public boolean lSet(String key, Object value) &#123; try &#123; redisTemplate.opsForList().rightPush(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 将list放入缓存 * @param key 键 * @param value 值 * @param time 时间(秒) */ public boolean lSet(String key, Object value, long time) &#123; try &#123; redisTemplate.opsForList().rightPush(key, value); if (time &gt; 0) expire(key, time); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 将list放入缓存 * * @param key 键 * @param value 值 * @return */ public boolean lSet(String key, List&lt;Object&gt; value) &#123; try &#123; redisTemplate.opsForList().rightPushAll(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ public boolean lSet(String key, List&lt;Object&gt; value, long time) &#123; try &#123; redisTemplate.opsForList().rightPushAll(key, value); if (time &gt; 0) expire(key, time); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 根据索引修改list中的某条数据 * * @param key 键 * @param index 索引 * @param value 值 * @return */ public boolean lUpdateIndex(String key, long index, Object value) &#123; try &#123; redisTemplate.opsForList().set(key, index, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 移除N个值为value * * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ public long lRemove(String key, long count, Object value) &#123; try &#123; Long remove = redisTemplate.opsForList().remove(key, count, value); return remove; &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; &#125;&#125; 后记: 所有的redis操作其实都很简单,不管什么语言,node或者php或者java. 重点在于理解redis的思想和数据结构的类型,使用场景等!","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"},{"name":"Redis","slug":"Java/Redis","permalink":"http://yiiiqing.github.io/categories/Java/Redis/"}],"tags":[{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"Redis","slug":"Redis","permalink":"http://yiiiqing.github.io/tags/Redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"utils","slug":"utils","permalink":"http://yiiiqing.github.io/tags/utils/"}]},{"title":"SpringBoot-定时任务","slug":"SpringBoot-定时任务","date":"2020-12-09T03:43:55.000Z","updated":"2021-03-17T06:55:07.000Z","comments":true,"path":"2020/12/09/SpringBoot-定时任务/","link":"","permalink":"http://yiiiqing.github.io/2020/12/09/SpringBoot-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/","excerpt":"","text":"步骤 在主启动类开启注解@EnableScheduling // 开启定时功能的注解 12345678910@SpringBootApplication@EnableAsync // 开启异步注解功能@EnableScheduling // 开启定时功能的注解public class Springboot08TestApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(Springboot08TestApplication.class, args); &#125;&#125; 在service上添加注解@Scheduled 123456789@Servicepublic class ScheduledService &#123; // 在一个特定的时间执行 // cron表达式 @Scheduled(cron = &quot;0 * * * * 0-7&quot;) public void hello()&#123; System.out.println(&quot;异步任务执行&quot;); &#125;&#125; 常用cron表达式 0 0 10,14,16 * * ? 每天上午10点，下午2点，4点0 0/30 9-17 * * ? 朝九晚五工作时间内每半小时0 0 12 ? * WED 表示每个星期三中午12点“0 0 12 * * ?” 每天中午12点触发“0 15 10 ? * *” 每天上午10:15触发“0 15 10 * * ?” 每天上午10:15触发“0 15 10 * * ? *” 每天上午10:15触发“0 15 10 * * ? 2005” 2005年的每天上午10:15触发“0 * 14 * * ?” 在每天下午2点到下午2:59期间的每1分钟触发“0 0/5 14 * * ?” 在每天下午2点到下午2:55期间的每5分钟触发“0 0/5 14,18 * * ?” 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发“0 0-5 14 * * ?” 在每天下午2点到下午2:05期间的每1分钟触发“0 10,44 14 ? 3 WED” 每年三月的星期三的下午2:10和2:44触发“0 15 10 ? * MON-FRI” 周一至周五的上午10:15触发“0 15 10 15 * ?” 每月15日上午10:15触发“0 15 10 L * ?” 每月最后一日的上午10:15触发“0 15 10 ? * 6L” 每月的最后一个星期五上午10:15触发“0 15 10 ? * 6L 2002-2005” 2002年至2005年的每月的最后一个星期五上午10:15触发“0 15 10 ? * 6#3” 每月的第三个星期五上午10:15触发 表达式占位说明 星号()：可用在所有字段中，表示对应时间域的每一个时刻，例如， 在分钟字段时，表示“每分钟”； 问号（?）：该字符只在日期和星期字段中使用，它通常指定为“无意义的值”，相当于点位符； 减号(-)：表达一个范围，如在小时字段中使用“10-12”，则表示从10到12点，即10,11,12； 逗号(,)：表达一个列表值，如在星期字段中使用“MON,WED,FRI”，则表示星期一，星期三和星期五； 斜杠(/)：x/y表达一个等步长序列，x为起始值，y为增量步长值。如在分钟字段中使用0/15，则表示为0,15,30和45秒，而5/15在分钟字段中表示5,20,35,50，你也可以使用\\/y，它等同于0/y；* L：该字符只在日期和星期字段中使用，代表“Last”的意思，但它在两个字段中意思不同。L在日期字段中，表示这个月份的最后一天，如一月的31号，非闰年二月的28号；如果L用在星期中，则表示星期六，等同于7。但是，如果L出现在星期字段里，而且在前面有一个数值X，则表示“这个月的最后X天”，例如，6L表示该月的最后星期五； W：该字符只能出现在日期字段里，是对前导日期的修饰，表示离该日期最近的工作日。例如15W表示离该月15号最近的工作日，如果该月15号是星期六，则匹配14号星期五；如果15日是星期日，则匹配16号星期一；如果15号是星期二，那结果就是15号星期二。但必须注意关联的匹配日期不能够跨月，如你指定1W，如果1号是星期六，结果匹配的是3号星期一，而非上个月最后的那天。W字符串只能指定单一日期，而不能指定日期范围； LW组合：在日期字段可以组合使用LW，它的意思是当月的最后一个工作日； 井号(#)：该字符只能在星期字段中使用，表示当月某个工作日。如6#3表示当月的第三个星期五(6表示星期五，#3表示当前的第三个)，而4#5表示当月的第五个星期三，假设当月没有第五个星期三，忽略不触发； C：该字符只在日期和星期字段中使用，代表“Calendar”的意思。它的意思是计划所关联的日期，如果日期没有被关联，则相当于日历中所有日期。例如5C在日期字段中就相当于日历5日以后的第一天。1C在星期字段中相当于星期日后的第一天。 Cron表达式对特殊字符的大小写不敏感，对代表星期的缩写英文大小写也不敏感。","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"schedule","slug":"schedule","permalink":"http://yiiiqing.github.io/tags/schedule/"},{"name":"cron","slug":"cron","permalink":"http://yiiiqing.github.io/tags/cron/"}]},{"title":"SpringBoot-异步任务","slug":"SpringBoot-异步任务","date":"2020-12-09T03:08:35.000Z","updated":"2020-12-09T03:12:20.000Z","comments":true,"path":"2020/12/09/SpringBoot-异步任务/","link":"","permalink":"http://yiiiqing.github.io/2020/12/09/SpringBoot-%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1/","excerpt":"","text":"在springboot中开启异步任务十分简单只需要两步 在主启动类中添加注解@EnableAsync 12345678@SpringBootApplication@EnableAsync // 开启异步注解功能public class Springboot08TestApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(Springboot08TestApplication.class, args); &#125;&#125; 在服务中使用注解@Async表示该任务为异步 12345678910111213@Servicepublic class AsyncService &#123; @Async // 告诉spring这是异步的方法 public void hello()&#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;doing&quot;); &#125;&#125; 这样的话,在controller中,程序遇见异步服务将直接执行下一步 1234567891011@RestControllerpublic class AsyncController &#123; @Autowired AsyncService asyncService; @RequestMapping(&quot;/hello&quot;) public String hello()&#123; asyncService.hello(); return &quot;ok&quot;; &#125;&#125; 结果是ok将会先行返回,三秒后doing才会被打印","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"async","slug":"async","permalink":"http://yiiiqing.github.io/tags/async/"}]},{"title":"SpringBoot-Swagger","slug":"SpringBoot-Swagger","date":"2020-12-08T08:18:57.000Z","updated":"2020-12-29T07:35:59.000Z","comments":true,"path":"2020/12/08/SpringBoot-Swagger/","link":"","permalink":"http://yiiiqing.github.io/2020/12/08/SpringBoot-Swagger/","excerpt":"","text":"在项目中使用Swagger 步骤 在pom引入jar包 3.0.0直接使用starter 123456&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-boot-starter --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt; 2.X.X版本 123456789101112&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger-ui --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger2 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt; 配置swagger 3.0.0 直接打开http://localhost:8080/swagger-ui/index.html即可 2.X.X: 在config包下面新建一个SwaggerConfig. 使用注解开启Swagger 12345@Configuration@EnableSwagger2 // 开启public class SwaggerConfig &#123;&#125; 配置1234567891011121314151617181920212223242526272829@Configurationpublic class SwaggerConfig &#123; // 配置了Swagger的Docket的bean实例 @Bean public Docket docket()&#123; return new Docket(DocumentationType.OAS_30) .apiInfo(apiInfo()) .groupName(&quot;yiqing&quot;) // 扫描包 .select() // RequestHandlerSelectors 配置要扫描接口的方式 // basePackage 指定要扫描的包 // withClassAnnotation: 扫描类上的注解 RestController.class // withMethodAnnotation: 扫描方法上的注解 GetMapping.class .apis(RequestHandlerSelectors.basePackage(&quot;com.famesmart.controller&quot;)) // 过滤什么路径 .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo()&#123; return new ApiInfoBuilder() .title(&quot;Tag系统api文档&quot;) .description(&quot;目前用于SaaS项目使用&quot;) .contact(new Contact(&quot;yiqing&quot;,&quot;www.famesmart.com&quot;,&quot;y.zhang@live.com&quot;)) .version(&quot;1.0.0&quot;) .build(); &#125;&#125; 配置多个分组协同开发: 配置多个docket实例,更改groupName即可 模型12345678910@Data@AllArgsConstructor@NoArgsConstructorpublic class Resident &#123; // 此项目没有修改resident的权利,遂只保留id @ApiModelProperty(&quot;居民id&quot;) private int id; @ApiModelProperty(&quot;居民tag列表&quot;) List&lt;Tag&gt; tags;&#125; 接口说明：Api用来指定一个controller中的各个接口的通用说明 ​ Operation:用来说明一个方法 ​ @ApiImplicitParams:用来包含多个包含多个 @ApiImplicitParam， ​ @ApiImplicitParam:用来说明一个请求参数 ​ 如果使用@Parameter来做说明，可以直接加到@RequestParam参数之前 ​ @ApiIgnore:用来忽略不必要显示的参数 12345@ApiOperation(&quot;添加某tag至resident&quot;)@ApiImplicitParams(&#123; @ApiImplicitParam(name = &quot;residentId&quot;, value = &quot;居民id&quot;, dataType = &quot;Integer&quot;, paramType = &quot;path&quot;, example = &quot;44&quot;), @ApiImplicitParam(name = &quot;tagId&quot;, value = &quot;tag id&quot;, dataType = &quot;Integer&quot;, paramType = &quot;path&quot;, example = &quot;1&quot;)&#125;) 可以直接在参数前面加@ApiParam(value=””,name=””)","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"Swagger","slug":"Swagger","permalink":"http://yiiiqing.github.io/tags/Swagger/"}]},{"title":"MySQL添加自增主键","slug":"MySQL添加自增主键","date":"2020-12-08T02:47:39.000Z","updated":"2020-12-08T02:48:27.000Z","comments":true,"path":"2020/12/08/MySQL添加自增主键/","link":"","permalink":"http://yiiiqing.github.io/2020/12/08/MySQL%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE/","excerpt":"","text":"记录一下 1alter table resident_tag add id int(11) PRIMARY KEY auto_increment","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/tags/MySQL/"}]},{"title":"SpringBoot-Mybatis整合","slug":"SpringBoot-Mybatis整合","date":"2020-12-04T09:46:01.000Z","updated":"2021-02-01T02:53:09.000Z","comments":true,"path":"2020/12/04/SpringBoot-Mybatis整合/","link":"","permalink":"http://yiiiqing.github.io/2020/12/04/SpringBoot-Mybatis%E6%95%B4%E5%90%88/","excerpt":"","text":"Mybatis两种整合方法1. 配置模式 导入依赖 1234567&lt;!--myBatis,注意是非spring-boot官方的依赖--&gt;&lt;!-- https://mvnrepository.com/artifact/org.mybatis.spring.boot/mybatis-spring-boot-starter --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt;&lt;/dependency&gt; 配置数据库连接信息 123456789spring.datasource.username=rootspring.datasource.password=zzzspring.datasource.url=jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver# 整合mybatismybatis.type-aliases-package=zone.yiqing.pojomybatis.mapper-locations=classpath:mybatis/mapper/*.xmlmybatis.configuration.map-underscore-to-camel-case=true 测试连接是否成功 1234567891011@SpringBootTestclass Springboot05MybatisApplicationTests &#123; @Autowired DataSource dataSource; @Test void contextLoads() throws Exception &#123; System.out.println(dataSource.getClass()); System.out.println(dataSource.getConnection()); &#125;&#125; 创建实体类 12345678@Data@NoArgsConstructor@AllArgsConstructorpublic class User &#123; private int id; private String name; private String pwd;&#125; 创建mapper目录以及mapper接口文件 12345678910111213@Mapper // 这个注解标识这个类是mybatis的mapper类@Repository // 将类的实现类交给spring管理public interface UserMapper &#123; List&lt;User&gt; queryUserList(); User queryUserById(int id); int addUser(User user); int updateUser(User user); int deleteUser(int id);&#125; 编写对应的Mapper.xml 注意: 写在resources下面 （resources/mybatis/mapper/UserMapper.xml） 123456789101112131415161718192021222324252627&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;zone.yiqing.mapper.UserMapper&quot;&gt; &lt;select id=&quot;queryUserList&quot; resultType=&quot;User&quot;&gt; select * from user &lt;/select&gt; &lt;select id=&quot;queryUserById&quot; resultType=&quot;User&quot;&gt; select * from user where id = #&#123;id&#125; &lt;/select&gt; &lt;insert id=&quot;addUser&quot; parameterType=&quot;User&quot;&gt; insert into user(id,name,pwd) values(#&#123;id&#125;,#&#123;name&#125;,#&#123;pwd&#125;) &lt;/insert&gt; &lt;update id=&quot;updateUser&quot; parameterType=&quot;User&quot;&gt; update user set name=#&#123;name&#125;,pwd=#&#123;pwd&#125; where id = #&#123;id&#125; &lt;/update&gt; &lt;delete id=&quot;deleteUser&quot; parameterType=&quot;int&quot;&gt; delete from user where id = #&#123;id&#125; &lt;/delete&gt;&lt;/mapper&gt; 如果有资源过滤问题注意配置maven资源过滤问题 编写controller 123456789101112@RestControllerpublic class UserController &#123; @Autowired private UserMapper userMapper; @GetMapping(&quot;/queryUserList&quot;) public List&lt;User&gt; queryUserList()&#123; List&lt;User&gt; userList = userMapper.queryUserList(); return userList; &#125;&#125; 2. 注解模式直接在mapper接口上添加注解 1234567@Mapperpublic interface CityMapper &#123; @Select(&quot;select * from city where id=#&#123;id&#125;&quot;) public City getById(Long id);&#125; 3. 混合模式123456789@Mapperpublic interface CityMapper &#123; @Select(&quot;select * from city where id=#&#123;id&#125;&quot;) public City getById(Long id); public void insert(City city);&#125; 最佳方法 引入mybatis-starter 配置application.yaml中，指定mapper-location位置即可 编写Mapper接口并标注@Mapper注解 简单方法直接注解方式 复杂方法编写mapper.xml进行绑定映射 @MapperScan(“com.atguigu.admin.mapper”) 简化，其他的接口就可以不用标注@Mapper注解 Mybatis-Plus pom引入starter 12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt;&lt;/dependency&gt; 自动配置原理 MybatisPlusAutoConfiguration. 其中MybatisPlusProperties配置项绑定了,所以mybatis-plus:xxx就是对mybatis-plus的定制 SqlSessionFactory自动配置.底层是我们自己配置 的的数据源 mapperLocations 自动配置. 默认值: classpath*:/mapper/*/.xml,即任意包的类路径下的所有mapper文件夹下的所有xml都是sql映射文件 约定大于配置 建议所有sql映射文件,都放在mapper下 容器中也自动配置好了SqlSessionTemplate @Mapper标注的接口也会被自动扫描 直接在主启动类上面标注@MapperScan(&quot;zone.yiqing.mapper&quot;)就可以批量扫描,就不用标注@Mapper了 优点 只需要我们的Mapper继承BaseMapper.简单CURD都有了 注意 实体类所有的属性都应该在数据库中 如果不在,使用@TableField(exist=flase)标注属性","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yiiiqing.github.io/tags/Mybatis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"Node.js websocket 加入心跳","slug":"Node-js-websocket-加入心跳","date":"2020-12-04T08:13:44.000Z","updated":"2020-12-04T08:33:44.000Z","comments":true,"path":"2020/12/04/Node-js-websocket-加入心跳/","link":"","permalink":"http://yiiiqing.github.io/2020/12/04/Node-js-websocket-%E5%8A%A0%E5%85%A5%E5%BF%83%E8%B7%B3/","excerpt":"","text":"今天项目中发现之前做的websocket总有隔一段时间后断开连接的情况, 原因是nginx服务器由于ws连接长时间无数据判定连接断开,如果更改ngnix参数可以改善, 但是为了优化这个问题,并且提高系统可靠性,采用了心跳机制 为什么需要心跳首先,长连接是建立在TCP协议上的 TCP连接状态TCP建立的连接是通过三次握手建立的,是一种逻辑上的连接, 如果链路已经断开,但是TCP层仍然认为连接还是存在的(ESTABLISHED), 所以应用层也同样感知不到链路不通的问题 TCP KeepAlive机制TCP自带KeepAlive机制 但是这个机制不是TCP协议规范中的,由操作系统实现, 如果操作系统不进行定期清除失活的连接,会导致网络性能下降, 开启KeepAlive机制后, 在一定时间(tcp_keepalive_tim参数)内,链路上如果没有数据传输,TCP层将会发送相应的KeepAlive探针以确定连接可用,探测失败后重试10(tcp_keepalive_probes)次,每次间隔时间75s(tcp_keepalive_intvl参数), 所有探测失败后,认为当前连接已经不可用.参数都是系统级别 调整参数可以改善连接问题,但是参数的调整切换机器后也要调整,十分不便利 如果有数据发送,但是物理链路不通,操作系统的链路状态还是ESTABLISHED,会走TCP重传机制,TCP超时重传的指数退避算法也相当耗时间. 因此,长连接的保活肯定依赖应用层的心跳来保证 应用层心跳好处能够及时发现链路故障问题,尽早建立新的连接,故障转移,可以重连,也可以请求其他服务器 尤其是服务器CPU重度使用,线程池爆满的情况下 Node.js示例使用方法参照官网说明: https://www.npmjs.com/package/ws How to detect and close broken connections?Sometimes the link between the server and the client can be interrupted in a way that keeps both the server and the client unaware of the broken state of the connection (e.g. when pulling the cord). In these cases ping messages can be used as a means to verify that the remote endpoint is still responsive. 123456789101112131415161718192021222324252627const WebSocket = require(&#x27;ws&#x27;); function noop() &#123;&#125; function heartbeat() &#123; this.isAlive = true;&#125; const wss = new WebSocket.Server(&#123; port: 8080 &#125;); wss.on(&#x27;connection&#x27;, function connection(ws) &#123; ws.isAlive = true; ws.on(&#x27;pong&#x27;, heartbeat);&#125;); const interval = setInterval(function ping() &#123; wss.clients.forEach(function each(ws) &#123; if (ws.isAlive === false) return ws.terminate(); ws.isAlive = false; ws.ping(noop); &#125;);&#125;, 30000); wss.on(&#x27;close&#x27;, function close() &#123; clearInterval(interval);&#125;);","categories":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/categories/Node-js/"}],"tags":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/tags/Node-js/"},{"name":"heartbeat","slug":"heartbeat","permalink":"http://yiiiqing.github.io/tags/heartbeat/"},{"name":"websocket","slug":"websocket","permalink":"http://yiiiqing.github.io/tags/websocket/"}]},{"title":"SpringBoot-Druid","slug":"SpringBoot-Druid","date":"2020-12-03T11:00:27.000Z","updated":"2020-12-07T10:05:11.000Z","comments":true,"path":"2020/12/03/SpringBoot-Druid/","link":"","permalink":"http://yiiiqing.github.io/2020/12/03/SpringBoot-Druid/","excerpt":"","text":"Druid简介Java程序很大一部分要操作数据库，为了提高性能操作数据库的时候，又不得不使用数据库连接池。 Druid 是阿里巴巴开源平台上一个数据库连接池实现，结合了 C3P0、DBCP 等 DB 池的优点，同时加入了日志监控。 Druid 可以很好的监控 DB 池连接和 SQL 的执行情况，天生就是针对监控而生的 DB 连接池。 Druid已经在阿里巴巴部署了超过600个应用，经过一年多生产环境大规模部署的严苛考验。 Spring Boot 2.0 以上默认使用 Hikari 数据源，可以说 Hikari 与 Driud 都是当前 Java Web 上最优秀的数据源，我们来重点介绍 Spring Boot 如何集成 Druid 数据源，如何实现数据库监控。 Github地址：https://github.com/alibaba/druid/ 使用 添加依赖 123456&lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; 切换数据源 在配置文件中指定type 1234567spring: datasource: username: root password: 123456 url: jdbc:mysql://localhost:3306/springboot?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.cj.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource # 自定义数据源 配置 12345678910111213141516171819202122232425262728293031# yaml配置文件# 配置数据库访问用户spring: datasource: username: root password: &#x27;101323&#x27; url: jdbc:mysql://localhost:3306/test?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.cj.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource # 自定义数据源 #Spring Boot 默认是不注入这些属性值的，需要自己绑定 #druid 数据源专有配置 initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true #配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入 #如果允许时报错 java.lang.ClassNotFoundException: org.apache.log4j.Priority #则导入 log4j 依赖即可，Maven 地址：https://mvnrepository.com/artifact/log4j/log4j filters: stat,wall,log4j maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 导入log4j 123456&lt;!-- https://mvnrepository.com/artifact/log4j/log4j --&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 为DruidDataSource绑定全局配置文件中的参数,再添加入容器,不使用SpringBoot的自动生成;需要自己添加DruidDataSource组件到容器中,同时绑定属性 配置数据源监控 配置过滤器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package zone.yiqing.config;import com.alibaba.druid.pool.DruidDataSource;import com.alibaba.druid.support.http.StatViewServlet;import com.alibaba.druid.support.http.WebStatFilter;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.boot.web.servlet.ServletRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.servlet.Filter;import javax.sql.DataSource;import java.util.HashMap;import java.util.Map;@Configurationpublic class DruidConfig &#123; @Bean @ConfigurationProperties(prefix = &quot;spring.datasource&quot;) public DataSource druidDataSource()&#123; return new DruidDataSource(); &#125; // 后台监控 // 因为SpringBoot内置了servlet,所以没有web.xml, 替代方法ServletRegistrationBean @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean&lt;StatViewServlet&gt; bean = new ServletRegistrationBean&lt;&gt;(new StatViewServlet(), &quot;/druid/*&quot;); // 后台需要有人登录,帐号密码配置 HashMap&lt;String, String&gt; initParameters = new HashMap&lt;&gt;(); // 增加配置 initParameters.put(&quot;loginUsername&quot;,&quot;admin&quot;); initParameters.put(&quot;loginPassword&quot;,&quot;123456&quot;); // 允许谁可以访问 initParameters.put(&quot;allow&quot;,&quot;&quot;); // 禁止谁能访问// initParameters.put(&quot;yiqing&quot;,&quot;192.168.1.12&quot;); bean.setInitParameters(initParameters);// 设置初始化参数 return bean; &#125; // filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean&lt;Filter&gt; bean = new FilterRegistrationBean&lt;&gt;(); bean.setFilter(new WebStatFilter()); // 可以过滤的请求 Map&lt;String,String&gt; initParameters = new HashMap&lt;&gt;(); // 这些东西不进行统计 initParameters.put(&quot;exclusions&quot;,&quot;*.js,*.css,/druid/*&quot;); bean.setInitParameters(initParameters); return bean; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"Druid","slug":"Druid","permalink":"http://yiiiqing.github.io/tags/Druid/"}]},{"title":"Node.js 'TypeError:is not a function'","slug":"Node-js-TypeError-is-not-a-function","date":"2020-11-27T02:29:44.000Z","updated":"2020-11-27T02:36:33.000Z","comments":true,"path":"2020/11/27/Node-js-TypeError-is-not-a-function/","link":"","permalink":"http://yiiiqing.github.io/2020/11/27/Node-js-TypeError-is-not-a-function/","excerpt":"","text":"今天项目中遇见一个问题, A文件module.exports了一个方法a B文件module.exports了一个方法b 然后我在B文件中引入了a方法运行,是可以的 但是一在A文件中引入b方法,就不可以运行,报错TypeError:is not a function google了一下 原来是循环依赖的问题 This happened to me many times because of circular dependency, check if you have 2 classes that are requiring each other, remove one of them from requiring the other and the issue should be solved 所以我将其中一个方法挪到了另一个文件里,就可以了 问题: https://stackoverflow.com/questions/33865068/typeerror-is-not-a-function-in-node-js","categories":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/categories/Node-js/"}],"tags":[{"name":"Error","slug":"Error","permalink":"http://yiiiqing.github.io/tags/Error/"}]},{"title":"SpringBoot-Thymeleaf","slug":"SpringBoot-Thymeleaf","date":"2020-11-25T03:25:18.000Z","updated":"2021-01-08T03:05:02.000Z","comments":true,"path":"2020/11/25/SpringBoot-Thymeleaf/","link":"","permalink":"http://yiiiqing.github.io/2020/11/25/SpringBoot-Thymeleaf/","excerpt":"","text":"在springboot中使用Thymeleaf模板 常用命名空间1234567xmlns:th=&quot;http://www.thymeleaf.org&quot;xmlns:sec=&quot;http://www.thymeleaf.org/extras/spring-security&quot;xmlns:shiro=&quot;http://www.pollix.at/thymeleaf/shiro&quot;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot; xmlns:sec=&quot;http://www.thymeleaf.org/extras/spring-security&quot; xmlns:shiro=&quot;http://www.pollix.at/thymeleaf/shiro&quot;&gt; 步骤 在pom中引入 1234&lt;dependency&gt; &lt;groupId&gt;org.thymeleaf&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-spring5&lt;/artifactId&gt;&lt;/dependency&gt; 在resources/templates下新建html文件(注意:这个路径是约定) 在文件中引入thymeleaf命名空间xmlns:th=&quot;http://www.thymeleaf.org&quot; 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;!--所有的html元素都可以被thymeleaf替换, th:元素名--&gt;&lt;h1 th:text=&quot;$&#123;msg&#125;&quot;&gt;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; Controller测试 12345678910// templetes 目录下的所有页面,智能通过controller跳转,这个需要模板引擎的支持@Controllerpublic class IndexController &#123; @RequestMapping(&quot;/test&quot;) public String index(Model model)&#123; model.addAttribute(&quot;msg&quot;,&quot;hello springboot&quot;); return &quot;test&quot;; &#125;&#125; 常用th标签 关键字 功能介绍 案例 th:id 替换id &lt;input th:id=&quot;&#39;xxx&#39; + $&#123;collect.id&#125;&quot;/&gt; th:text 文本替换 &lt;p th:text=&quot;$&#123;collect.description&#125;&quot;&gt;description&lt;/p&gt; th:utext 支持html的文本替换 &lt;p th:utext=&quot;$&#123;htmlcontent&#125;&quot;&gt;conten&lt;/p&gt; th:object 替换对象 &lt;div th:object=&quot;$&#123;session.user&#125;&quot;&gt; th:value 属性赋值 &lt;input th:value=&quot;$&#123;user.name&#125;&quot; /&gt; th:with 变量赋值运算 &lt;div th:with=&quot;isEven=$&#123;prodStat.count&#125;%2==0&quot;&gt;&lt;/div&gt; th:style 设置样式 th:style=&quot;&#39;display:&#39; + @&#123;($&#123;sitrue&#125; ? &#39;none&#39; : &#39;inline-block&#39;)&#125; + &#39;&#39;&quot; th:onclick 点击事件 th:onclick=&quot;&#39;getCollect()&#39;&quot; th:each 属性赋值 tr th:each=&quot;user,userStat:$&#123;users&#125;&quot;&gt; th:if 判断条件 &lt;a th:if=&quot;$&#123;userId == collect.userId&#125;&quot; &gt; th:unless 和th:if判断相反 &lt;a th:href=&quot;@&#123;/login&#125;&quot; th:unless=$&#123;session.user != null&#125;&gt;Login&lt;/a&gt; th:href 链接地址 &lt;a th:href=&quot;@&#123;/login&#125;&quot; th:unless=$&#123;session.user != null&#125;&gt;Login&lt;/a&gt; /&gt; th:switch 多路选择 配合th:case 使用 &lt;div th:switch=&quot;$&#123;user.role&#125;&quot;&gt; th:case th:switch的一个分支 &lt;p th:case=&quot;&#39;admin&#39;&quot;&gt;User is an administrator&lt;/p&gt; th:fragment 布局标签，定义一个代码片段，方便其它地方引用 &lt;div th:fragment=&quot;alert&quot;&gt; th:include 布局标签，替换内容到引入的文件 &lt;head th:include=&quot;layout :: htmlhead&quot; th:with=&quot;title=&#39;xx&#39;&quot;&gt;&lt;/head&gt; /&gt; th:replace 布局标签，替换整个标签到引入的文件 &lt;div th:replace=&quot;fragments/header :: title&quot;&gt;&lt;/div&gt; th:selected selected选择框 选中 th:selected=&quot;($&#123;xxx.id&#125; == $&#123;configObj.dd&#125;)&quot; th:src 图片类地址引入 &lt;img class=&quot;img-responsive&quot; alt=&quot;App Logo&quot; th:src=&quot;@&#123;/img/logo.png&#125;&quot; /&gt; th:inline 定义js脚本可以使用变量 &lt;script type=&quot;text/javascript&quot; th:inline=&quot;javascript&quot;&gt; th:action 表单提交的地址 &lt;form action=&quot;subscribe.html&quot; th:action=&quot;@&#123;/subscribe&#125;&quot;&gt; th:remove 删除某个属性 &lt;tr th:remove=&quot;all&quot;&gt; 1.all:删除包含标签和所有的孩子。2.body:不包含标记删除,但删除其所有的孩子。3.tag:包含标记的删除,但不删除它的孩子。4.all-but-first:删除所有包含标签的孩子,除了第一个。5.none:什么也不做。这个值是有用的动态评估。 th:attr 设置标签属性，多个属性可以用逗号分隔 比如th:attr=&quot;src=@&#123;/image/aa.jpg&#125;,title=#&#123;logo&#125;&quot;，此标签不太优雅，一般用的比较少。 示例1、赋值、字符串拼接12&lt;p th:text=&quot;$&#123;collect.description&#125;&quot;&gt;description&lt;/p&gt;&lt;span th:text=&quot;&#x27;Welcome to our application, &#x27; + $&#123;user.name&#125; + &#x27;!&#x27;&quot;&gt; 字符串拼接还有另外一种简洁的写法 1&lt;span th:text=&quot;|Welcome to our application, $&#123;user.name&#125;!|&quot;&gt; 2、条件判断 If/UnlessThymeleaf中使用th:if和th:unless属性进行条件判断，下面的例子中，&lt;a&gt;标签只有在th:if中条件成立时才显示： 12&lt;a th:if=&quot;$&#123;myself==&#x27;yes&#x27;&#125;&quot; &gt; &lt;/i&gt; &lt;/a&gt;&lt;a th:unless=$&#123;session.user != null&#125; th:href=&quot;@&#123;/login&#125;&quot; &gt;Login&lt;/a&gt; th:unless 于 th:if 恰好相反，只有表达式中的条件不成立，才会显示其内容。 也可以使用 (if) ? (then) : (else)这种语法来判断显示的内容 3、for 循环12345678910&lt;tr th:each=&quot;collect,iterStat : $&#123;collects&#125;&quot;&gt; &lt;th scope=&quot;row&quot; th:text=&quot;$&#123;collect.id&#125;&quot;&gt;1&lt;/th&gt; &lt;td &gt; &lt;img th:src=&quot;$&#123;collect.webLogo&#125;&quot;/&gt; &lt;/td&gt; &lt;td th:text=&quot;$&#123;collect.url&#125;&quot;&gt;Mark&lt;/td&gt; &lt;td th:text=&quot;$&#123;collect.title&#125;&quot;&gt;Otto&lt;/td&gt; &lt;td th:text=&quot;$&#123;collect.description&#125;&quot;&gt;@mdo&lt;/td&gt; &lt;td th:text=&quot;$&#123;terStat.index&#125;&quot;&gt;index&lt;/td&gt;&lt;/tr&gt; iterStat称作状态变量，属性有： index:当前迭代对象的 index（从0开始计算） count: 当前迭代对象的 index(从1开始计算) size:被迭代对象的大小 current:当前迭代变量 even/odd:布尔值，当前循环是否是偶数/奇数（从0开始计算） first:布尔值，当前循环是否是第一个 last:布尔值，当前循环是否是最后一个 4、URLURL 在 Web 应用模板中占据着十分重要的地位，需要特别注意的是 Thymeleaf 对于 URL 的处理是通过语法 @&#123;...&#125; 来处理的。如果需要 Thymeleaf 对 URL 进行渲染，那么务必使用 th:href，th:src 等属性，下面是一个例子 12345&lt;!-- Will produce &#x27;http://localhost:8080/standard/unread&#x27; (plus rewriting) --&gt; &lt;a th:href=&quot;@&#123;/standard/&#123;type&#125;(type=$&#123;type&#125;)&#125;&quot;&gt;view&lt;/a&gt;&lt;!-- Will produce &#x27;/gtvg/order/3/details&#x27; (plus rewriting) --&gt;&lt;a href=&quot;details.html&quot; th:href=&quot;@&#123;/order/&#123;orderId&#125;/details(orderId=$&#123;o.id&#125;)&#125;&quot;&gt;view&lt;/a&gt; 设置背景 1&lt;div th:style=&quot;&#x27;background:url(&#x27; + @&#123;/&lt;path-to-image&gt;&#125; + &#x27;);&#x27;&quot;&gt;&lt;/div&gt; 根据属性值改变背景 1&lt;div class=&quot;media-object resource-card-image&quot; th:style=&quot;&#x27;background:url(&#x27; + @&#123;($&#123;collect.webLogo&#125;==&#x27;&#x27; ? &#x27;img/favicon.png&#x27; : $&#123;collect.webLogo&#125;)&#125; + &#x27;)&#x27;&quot; &gt;&lt;/div&gt; 几点说明： 上例中 URL 最后的(orderId=$&#123;o.id&#125;)表示将括号内的内容作为 URL 参数处理，该语法避免使用字符串拼接，大大提高了可读性 @&#123;...&#125;表达式中可以通过&#123;orderId&#125;访问 Context 中的 orderId 变量 @&#123;/order&#125;是 Context 相关的相对路径，在渲染时会自动添加上当前 Web 应用的 Context 名字，假设 context 名字为 app，那么结果应该是 /app/order 5、内联 js内联文本：[[…]] 内联文本的表示方式，使用时，必须先用th:inline=&quot;text/javascript/none&quot;激活，th:inline可以在父级标签内使用，甚至作为 body 的标签。内联文本尽管比th:text的代码少，不利于原型显示。 12345678&lt;script th:inline=&quot;javascript&quot;&gt;/*&lt;![CDATA[*/...var username = /*[[$&#123;sesion.user.name&#125;]]*/ &#x27;Sebastian&#x27;;var size = /*[[$&#123;size&#125;]]*/ 0;.../*]]&gt;*/&lt;/script&gt; js 附加代码： 123/*[+var msg = &#x27;This is a working application&#x27;;+]*/ js 移除代码： 123/*[- */var msg = &#x27;This is a non-working template&#x27;;/* -]*/ 6、内嵌变量为了模板更加易用，Thymeleaf 还提供了一系列 Utility 对象（内置于 Context 中），可以通过 # 直接访问： dates ： java.util.Date的功能方法类。 calendars : 类似#dates，面向java.util.Calendar numbers : 格式化数字的功能方法类 strings : 字符串对象的功能类，contains,startWiths,prepending/appending等等。 objects: 对objects的功能类操作。 bools: 对布尔值求值的功能方法。 arrays：对数组的功能类方法。 lists: 对lists功能类方法 sets maps… 下面用一段代码来举例一些常用的方法： dates123456789101112131415161718/* * Format date with the specified pattern * Also works with arrays, lists or sets */$&#123;#dates.format(date, &#x27;dd/MMM/yyyy HH:mm&#x27;)&#125;$&#123;#dates.arrayFormat(datesArray, &#x27;dd/MMM/yyyy HH:mm&#x27;)&#125;$&#123;#dates.listFormat(datesList, &#x27;dd/MMM/yyyy HH:mm&#x27;)&#125;$&#123;#dates.setFormat(datesSet, &#x27;dd/MMM/yyyy HH:mm&#x27;)&#125;/* * Create a date (java.util.Date) object for the current date and time */$&#123;#dates.createNow()&#125;/* * Create a date (java.util.Date) object for the current date (time set to 00:00) */$&#123;#dates.createToday()&#125; strings12345678910111213141516171819202122232425262728293031323334/* * Check whether a String is empty (or null). Performs a trim() operation before check * Also works with arrays, lists or sets */$&#123;#strings.isEmpty(name)&#125;$&#123;#strings.arrayIsEmpty(nameArr)&#125;$&#123;#strings.listIsEmpty(nameList)&#125;$&#123;#strings.setIsEmpty(nameSet)&#125;/* * Check whether a String starts or ends with a fragment * Also works with arrays, lists or sets */$&#123;#strings.startsWith(name,&#x27;Don&#x27;)&#125; // also array*, list* and set*$&#123;#strings.endsWith(name,endingFragment)&#125; // also array*, list* and set*/* * Compute length * Also works with arrays, lists or sets */$&#123;#strings.length(str)&#125;/* * Null-safe comparison and concatenation */$&#123;#strings.equals(str)&#125;$&#123;#strings.equalsIgnoreCase(str)&#125;$&#123;#strings.concat(str)&#125;$&#123;#strings.concatReplaceNulls(str)&#125;/* * Random */$&#123;#strings.randomAlphanumeric(count)&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"Thymeleaf","slug":"Thymeleaf","permalink":"http://yiiiqing.github.io/tags/Thymeleaf/"}]},{"title":"koa导入导出excel","slug":"koa导入导出excel","date":"2020-11-24T03:05:10.000Z","updated":"2020-11-24T07:07:28.000Z","comments":true,"path":"2020/11/24/koa导入导出excel/","link":"","permalink":"http://yiiiqing.github.io/2020/11/24/koa%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BAexcel/","excerpt":"","text":"导出excel文件流因为使用了koa的model,所以我这里封装了一个通用的方法来导出 导出方法option: modelName: koa中的模型名 attributes: 需要导出的模型字段 where: 筛选条件(这里是根据了projectCode项目代码来筛选) titleArr: attributes对应的中文解释 fileName: 导出文件的名称 isTemplete: 是否为导入模板,如果传1,将会返回仅包含attributes栏和tittleArr栏的文件 12345678910111213141516171819202122232425262728293031323334353637/** * export specified model data to excel * @param options modelName:string,attributes:Array,where:object,titleArr:Arr,fileName:string */export function export2Excel(options: any) &#123; let &#123; modelName, attributes, where, titleArr, fileName, isTemplete &#125; = options; // 去除假值 attributes = attributes.filter(d=&gt;d) titleArr = titleArr.filter(d=&gt;d) return models[modelName] .findAll(&#123; attributes, where, &#125;) .then((results) =&gt; &#123; // 模板的话置空 results = isTemplete ? [] : JSON.parse(JSON.stringify(results)); if (results) &#123; let datas = isTemplete? [attributes]: [underscore.keys(results[0])]; datas.push(titleArr); for (let i in results) &#123; let result = results[i]; var value = underscore.values(result); value[0] = parseInt(i) + parseInt(&#x27;1&#x27;); datas.push(value); &#125; var buffer = xlsx.build([&#123; name: fileName, data: datas &#125;]); return buffer; &#125; else &#123; return &#123; result: 1, msg: &#x27;Failed&#x27;, &#125;; &#125; &#125;);&#125; 控制器1234567891011121314151617181920212223242526272829303132333435/** * 导出 * param: * comm_code * isTemplete: 1为获取模板 */deviceExport: async (ctx, next) =&gt; &#123; let &#123; projectCode , isTemplete &#125; = ctx.request.query; let options = &#123; modelName: &#x27;Device&#x27;, attributes: [ isTemplete?null:&#x27;id&#x27;, isTemplete?null:&#x27;device_guid&#x27;, &#x27;device_type&#x27;, &#x27;addr&#x27;, &#x27;ip&#x27;, &#x27;name&#x27;, ], where: projectCode ? &#123; projectCode &#125; : null, titleArr: [ isTemplete?null:&#x27;序号&#x27;, isTemplete?null:&#x27;设备唯一码&#x27;, &#x27;设备类型&#x27;, &#x27;设备地址&#x27;, &#x27;IP&#x27;, &#x27;设备名&#x27;, ], fileName: &#x27;devices&#x27;, isTemplete &#125;; let exportData = await export2Excel(options); ctx.set(&#x27;Content-Type&#x27;, &#x27;application/vnd.openxmlformats&#x27;); ctx.set(&#x27;Content-Disposition&#x27;, `attachment; filename=device.xlsx`); ctx.body = exportData;&#125;, 导入 导入相关包 123npm install koa-multer node-xlsx xlsx// 如果是typescript,还需要npm install @types/koa-multer @types/node-xlsx 文件中导入依赖 12import multer from &#x27;koa-multer&#x27;;import XLSX from &#x27;xlsx&#x27;; 配置文件存储 123456789101112131415import fs from &#x27;fs&#x27;import path from &#x27;path&#x27;if(!fs.existsSync(path.resolve(&#x27;./public&#x27;))) fs.mkdirSync(path.resolve(&#x27;./public&#x27;))let storage = multer.diskStorage(&#123; // 文件保存路径 destination: function (req, file, cb) &#123; cb(null, &#x27;./public&#x27;); &#125;, // 修改文件名 filename: function (req, file, cb) &#123; var fileFormat = file.originalname.split(&#x27;.&#x27;); cb(null, Date.now() + &#x27;.&#x27; + fileFormat[fileFormat.length - 1]); &#125;,&#125;); 加载配置 12//加载配置let upload = multer(&#123; storage: storage &#125;) 在路由中配置上传路由 有多种上传方式,但是single就够了 ‘file’是上传的字段名 1router.post(&#x27;/device/import&#x27;,upload.single(&#x27;file&#x27;),device_controller.import); 控制器 1234567891011121314151617181920212223242526import XLSX from &#x27;xlsx&#x27;; /** * @version 1.0 * @author yiqing * @description 导入设备 */import:async(ctx,next)=&gt;&#123; let file = ctx.req.file.filename; const xlsxFile = path.resolve(&#x27;./public&#x27;, file); async function readExcel() &#123; return new Promise((resolve, reject) =&gt; &#123; // read file let rawfile = fs.readFileSync(xlsxFile); file = XLSX.read(rawfile); // get json array let j_data = XLSX.utils.sheet_to_json(file.Sheets[file.SheetNames[0]]); // 移除自己添加的中文解释 j_data.shift() resolve(j_data); &#125;); &#125; let data:any = await readExcel(); // 删除文件 fs.unlinkSync(xlsxFile)&#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"koa","slug":"koa","permalink":"http://yiiiqing.github.io/tags/koa/"},{"name":"upload","slug":"upload","permalink":"http://yiiiqing.github.io/tags/upload/"},{"name":"download","slug":"download","permalink":"http://yiiiqing.github.io/tags/download/"}]},{"title":"SpringBoot-静态资源","slug":"SpringBoot-静态资源","date":"2020-11-23T08:06:15.000Z","updated":"2021-01-06T02:35:13.000Z","comments":true,"path":"2020/11/23/SpringBoot-静态资源/","link":"","permalink":"http://yiiiqing.github.io/2020/11/23/SpringBoot-%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90/","excerpt":"","text":"SpringBoot 静态资源处理两种方式 webjars 在webjars官网使用maven导入 输入路径localhost:8080/webjars/xxx访问 META-INF/resources/, resources/, static/, public/目录下 输入路径localhost:8080/直接访问 优先级: resources&gt;static(默认)&gt;public 原理如果有一个Controller定义的路由和静态资源同名,将交给Controller处理 静态映射 /** 请求进来先去找Controller(动态请求)看能不能处理. 如果不能处理,交给静态资源处理器. 静态资源能找到,返回静态资源 静态资源找不到,返回404 静态资源访问前缀(推荐)123spring: mvc: static-path-pattern: /resources/** 这样配置, 只有resources开头的请求才会访问静态资源 静态资源默认文件夹123spring: resources: static-locations: [classpath:/abc/]","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"SpringBoot-JSR303","slug":"SpringBoot-JSR303","date":"2020-11-20T06:08:34.000Z","updated":"2020-12-31T09:05:45.000Z","comments":true,"path":"2020/11/20/SpringBoot-JSR303/","link":"","permalink":"http://yiiiqing.github.io/2020/11/20/SpringBoot-JSR303/","excerpt":"","text":"JSR303校验JSR-303 是 JAVA EE 6 中的一项子规范 JAR: validation-api-1.0.0.GA.jar：JDK的接口; 校验规则核心就是正则表达式 123456789101112131415161718192021222324252627282930313233343536空检查 @Null 验证对象是否为null @NotNull 验证对象是否不为null, 无法查检长度为0的字符串 @NotBlank 检查约束字符串是不是Null还有被Trim的长度是否大于0,只对字符串,且会去掉前后空格. @NotEmpty 检查约束元素是否为NULL或者是EMPTY.Booelan检查 @AssertTrue 验证 Boolean 对象是否为 true @AssertFalse 验证 Boolean 对象是否为 false长度检查 @Size(min=, max=) 验证对象（Array,Collection,Map,String）长度是否在给定的范围之内 @Length(min=, max=) Validates that the annotated string is between min and max included.日期检查 @Past 验证 Date 和 Calendar 对象是否在当前时间之前，验证成立的话被注释的元素一定是一个过去的日期 @Future 验证 Date 和 Calendar 对象是否在当前时间之后 ，验证成立的话被注释的元素一定是一个将来的日期 @Pattern 验证 String 对象是否符合正则表达式的规则，被注释的元素符合制定的正则表达式，regexp:正则表达式 flags: 指定 Pattern.Flag 的数组，表示正则表达式的相关选项。数值检查 建议使用在Stirng,Integer类型，不建议使用在int类型上，因为表单值为“”时无法转换为int，但可以转换为Stirng为”“,Integer为null @Min 验证 Number 和 String 对象是否大等于指定的值 @Max 验证 Number 和 String 对象是否小等于指定的值 @DecimalMax 被标注的值必须不大于约束中指定的最大值. 这个约束的参数是一个通过BigDecimal定义的最大值的字符串表示.小数存在精度 @DecimalMin 被标注的值必须不小于约束中指定的最小值. 这个约束的参数是一个通过BigDecimal定义的最小值的字符串表示.小数存在精度 @Digits 验证 Number 和 String 的构成是否合法 @Digits(integer=,fraction=) 验证字符串是否是符合指定格式的数字，interger指定整数精度，fraction指定小数精度。 @Range(min=, max=) 被指定的元素必须在合适的范围内 @Range(min=10000,max=50000,message=”range.bean.wage”) @Valid 递归的对关联对象进行校验, 如果关联对象是个集合或者数组,那么对其中的元素进行递归校验,如果是一个map,则对其中的值部分进行校验.(是否进行递归验证) @CreditCardNumber信用卡验证 @Email 验证是否是邮件地址，如果为null,不进行验证，算通过验证。 @ScriptAssert(lang= ,script=, alias=) @URL(protocol=,host=, port=,regexp=, flags=) 在SpringBoot中使用JSR303校验 在pom.xml中导入包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;&lt;/dependency&gt; 在实体类加上@Validated注解 1234567891011@Validatedpublic class Person &#123; @Email // 将会校验name是否为email private String name; private Integer age; private Boolean happy; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog;&#125; 实战 验证实体类 直接在前面加上@Valid即可(前提:实体类包含校验规则) 123@PostMapping()public JsonResult addToLib(@RequestBody @Valid ImageLibDTO imageLibDTO) &#123;&#125; 验证实体类1中的依赖实体类2 在实体类1中的实体类2上加上@Valid注解(前提:实体类2包含校验规则) 12345678910111213141516171819public class ImageLibDTO &#123; @NotEmpty(message = &quot;projectCode不能为空&quot;) @Size(min = 5,max = 5,message = &quot;projectCode长度错误&quot;) @ApiModelProperty(&quot;项目代码&quot;) private String projectCode; @NotEmpty(message = &quot;lib不能为空&quot;) @ApiModelProperty(&quot;要操作的库名&quot;) private String lib; @ApiModelProperty(&quot;Image实体List&quot;) @Valid //验证实体类1中的依赖实体类2 private List&lt;Image&gt; imageList; public String getKey()&#123; return &quot;face&quot; + &quot;:&quot; + this.getProjectCode() + &quot;:&quot; + this.getLib(); &#125;&#125; 验证get方式的单个参数 参数前加上@NutBlank即可 在该Controller类上面加上@Validated 并且删除该参数前面的@RequestParam 123456789101112@RestController@RequestMapping(&quot;/lib&quot;)@Validatedpublic class FaceLibController &#123; @GetMapping() public JsonResult getFromLib( @NotBlank(message = &quot;projectCode不能为空&quot;) String projectCode, @NotBlank(message = &quot;lib不能为空&quot;) String lib, @NotEmpty(message = &quot;uidList不能为空&quot;) List&lt;String&gt; uidListr ) &#123;&#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"Validation","slug":"Validation","permalink":"http://yiiiqing.github.io/tags/Validation/"}]},{"title":"SpringBoot-yaml配置","slug":"SpringBoot-yaml配置","date":"2020-11-20T03:26:24.000Z","updated":"2020-12-11T03:29:29.000Z","comments":true,"path":"2020/11/20/SpringBoot-yaml配置/","link":"","permalink":"http://yiiiqing.github.io/2020/11/20/SpringBoot-yaml%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Yaml维基百科: YAML是”YAML Ain’t a Markup Language”（YAML不是一种标记语言）的递归缩写。在开发的这种语言时，YAML 的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）[3]，但为了强调这种语言以数据做为中心，而不是以标记语言为重点，而用反向缩略语重命名。 基本语法 冒号后面有一个空格 对空格要求严格 123456789101112131415# 对象student: name: yiqing age: 25 # 行内元素student: &#123;name: John Smith, age: 33&#125;- name: Mary Smith age: 27# 数组men: [John Smith, Bill Jones]women: - Mary Smith - Susan Williams SpringBoot中使用yaml在springboot中,yaml可以注入实体类中 使用@ConfigurationProperties注解 将配置文件的属性值,映射到这个组件中,参数prefix是将配置文件中的person下面的所有属性一一对应 只有是容器中的组件,才可以使用这个注解 示例: 建实体类(使用了lombok) 123456789101112131415161718192021222324@Component@Data@NoArgsConstructor@AllArgsConstructor@ConfigurationProperties(prefix = &quot;person&quot;)public class Person &#123; private String name; private Integer age; private Boolean happy; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog;&#125;@Component@Data@NoArgsConstructor@AllArgsConstructorpublic class Dog &#123; private String name; private Integer age;&#125; 在resources新建application.yaml 12345678910111213person: name: yiqing age: 3 happy: false birth: 2020/11/20 maps: &#123;k1: v1,k2: v2&#125; lists: - code - music - girl dog: name: 旺财 age: 3 测试 1234567891011@SpringBootTestclass Springboot02ConfigApplicationTests &#123; @Autowired private Person person; @Test void contextLoads() &#123; System.out.println(person); &#125;&#125; 也可以使用EL表达式 12345678910111213person: name: yiqing$&#123;random.uuid&#125; age: $&#123;random.int&#125; happy: false birth: 2020/11/20 maps: &#123;k1: v1,k2: v2&#125; lists: - code - music - girl dog: name: $&#123;person.hello:hello&#125; age: 3 总结 yaml和properties都可以取值,但是推荐yaml 如果在业务中,只需要获取配置文件中的某个值,直接@Value 如果专门编写了一个JavaBean来和配置文件进行映射,就直接使用ConfigurationProperties","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"yaml","slug":"yaml","permalink":"http://yiiiqing.github.io/tags/yaml/"}]},{"title":"SpringBoot-主启动类运行","slug":"SpringBoot-主启动类运行","date":"2020-11-20T02:41:46.000Z","updated":"2020-11-20T03:00:49.000Z","comments":true,"path":"2020/11/20/SpringBoot-主启动类运行/","link":"","permalink":"http://yiiiqing.github.io/2020/11/20/SpringBoot-%E4%B8%BB%E5%90%AF%E5%8A%A8%E7%B1%BB%E8%BF%90%E8%A1%8C/","excerpt":"","text":"主启动类原文: https://www.cnblogs.com/hellokuangshen/p/12450327.html 12345678// @SpringBootApplication:标注这个类是一个springboot的应用:@SpringBootApplicationpublic class Springboot01HelloworldApplication &#123; public static void main(String[] args) &#123; // 将spring boot应用启动 SpringApplication.run(Springboot01HelloworldApplication.class, args); &#125;&#125; SpringApplication.run分为两部分,SpringApplication的实例化,run方法的执行 SpringApplication这个类主要做了四件事情 推断应用的类型是普通项目还是web项目 查找并加载所有可用初始化类,设置到initializers属性中 找出所有的应用程序监听器,设置到listeners属性中 判断并设置main方法的定义类,找到运行的主类 run方法运行流程","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"SpringBoot-自动装配","slug":"SpringBoot-自动装配","date":"2020-11-19T06:54:30.000Z","updated":"2020-11-20T02:40:09.000Z","comments":true,"path":"2020/11/19/SpringBoot-自动装配/","link":"","permalink":"http://yiiiqing.github.io/2020/11/19/SpringBoot-%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D/","excerpt":"","text":"自动装配pom.xml spring-boot-dependencies 核心依赖在父工程中 在写或者引入一些SpringBoot依赖的时候,不需要指定版本,因为有版本仓库 启动器1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 就是SpringBoot的启动场景: 比如spring-boot-starter-web就会帮我们导入web环境所有依赖 spring-boot将所有的场景功能,都编程一个个的启动器,需要什么功能,找对应的启动器 主程序123456789// @SpringBootApplication:标注这个类是一个springboot的应用@SpringBootApplicationpublic class Springboot01HelloworldApplication &#123; public static void main(String[] args) &#123; // 将spring boot应用启动 SpringApplication.run(Springboot01HelloworldApplication.class, args ); &#125;&#125; 注解1234567891011@SpringBootConfiguration: springboot的配置 @Configuration: spring配置类 @Component: 说明这也是一个spring的组件@EnableAutoConfiguration: 自动配置 @AutoConfigurationPackage: 自动配置包 @Import(&#123;Registrar.class&#125;): 自动配置包注册 @AutoConfigurationImportSelector: 自动配置导入选择 // 获取所有配置 List&lt;String&gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes); 获取候选的配置12345protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(this.getSpringFactoriesLoaderFactoryClass(), this.getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you are using a custom packaging, make sure that file is correct.&quot;); return configurations;&#125; META-INF/spring.factories SpringFactoriesLoader.java12Properties properties = PropertiesLoaderUtils.loadProperties(resource);// 所有的资源加载到配置类中 原理分析 小结 springboot在启动的时候,从类路径下的/META-INF/spring.factories获取指定的值 将这些自动配置的类导入容器,自动配置就会生效,帮我们自动配置. 整合javaEE,解决方案和自动配置的东西都在spring-boot-autoconfigure-2.4.0.RELEASE.jar包 它会把所有的需要导入的组件,以类名的方式返回,这些组件就会被添加到容器中 容器中会存在非常多的xxxAutoConfiguration的文件,就是这些类给容器导入了这个场景需要的所有组件并自动配置,就是一个个的java config, @Configuration 以前我们需要手动配置的,springboot帮我们做了 结论springboot所有的自动配置都是在启动的时候扫描并加载的: 所有的自动配置类都在spring.factories,但是要导入对应的starter启动器,自动装配就会生效,然后就配置成功了","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"SpringBoot简介","slug":"SpringBoot简介","date":"2020-11-18T02:28:57.000Z","updated":"2020-11-18T06:03:08.000Z","comments":true,"path":"2020/11/18/SpringBoot简介/","link":"","permalink":"http://yiiiqing.github.io/2020/11/18/SpringBoot%E7%AE%80%E4%BB%8B/","excerpt":"","text":"Spring 是一个开源框架,2003年兴起的轻量级Java开发框架 作者: Rod Johnson 是为了解决企业级应用开发的复杂性而创建,为了简化开发 Spring简化开发方法: 基于POJO的轻量级和最小侵入性编程 通过IOC,依赖注入(DI)和面向接口实现松耦合 基于切面(AOP)和惯例进行声明式编程 通过切面和模板Templete减少样式代码 SpringBoot 为了让大家更容易地使用Spring,更容易地集成各种常用的中间件,开源软件 Spring Boot基于Spring开发 Spring Boot本身不提供Spring框架的核心特性以及拓展功能,知识用于快速敏捷地开发新一代基于Spring框架的应用程序 约定大于配置(maven,spring,springmvc,springboot,…docker,k8s都是,java不是) 集成了大量第三方库配置(Redis,MongoDB,Jpa,RabbitMQ,Quartz等等),可以做到几乎零配置开箱即用 生态成熟","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"}]},{"title":"使用Java配置Spring","slug":"使用Java配置Spring","date":"2020-11-17T09:23:50.000Z","updated":"2020-11-17T09:39:23.000Z","comments":true,"path":"2020/11/17/使用Java配置Spring/","link":"","permalink":"http://yiiiqing.github.io/2020/11/17/%E4%BD%BF%E7%94%A8Java%E9%85%8D%E7%BD%AESpring/","excerpt":"","text":"不适用Spring自己的xml配置,使用Java来配置 JavaConfig原本是Spring的一个子项目,在Spring 4之后为核心功能 在SpringBoot中普遍使用 官方示例: 12345678@Configurationpublic class AppConfig &#123; @Bean public MyService myService() &#123; return new MyServiceImpl(); &#125;&#125; The preceding AppConfig class is equivalent to the following Spring &lt;beans/&gt; XML: 123&lt;beans&gt; &lt;bean id=&quot;myService&quot; class=&quot;com.acme.services.MyServiceImpl&quot;/&gt;&lt;/beans&gt; 建一个实体类 1234567891011121314151617181920212223242526272829package zone.yiqing.pojo;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;/** * @Author Yiqing Zhang * @Date 2020-10-26 7:20 p.m. * @Version 1.0 */@Component // 这个注解表明这个类被Spring接管,注册到容器中public class User &#123; private String name; public String getName() &#123; return name; &#125; @Value(&quot;Yiqing&quot;) // 属性注入值 public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 建一个配置类 12345678910111213141516171819202122232425262728package zone.yiqing.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Import;import zone.yiqing.pojo.User;/** * @Author Yiqing Zhang * @Date 2020-10-26 7:21 p.m. * @Version 1.0 */// 这个也会被Spring托管,注册到容器中,因为它也是一个@Component// @Configuration表名这个类是一个配置类,等同于xml@Configuration @ComponentScan(&quot;zone.yiqing.pojo&quot;)@Import(YiqingConfig2.class)public class YiqingConfig &#123; // 注册一个bean,就相当于bean标签 // 方法名为bean中的id,返回值为bean中的class @Bean public User getUser()&#123; return new User(); // 就是返回要注入到bean的对象 &#125;&#125; 测试 123456789101112131415161718import org.springframework.context.ApplicationContext;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import zone.yiqing.config.YiqingConfig;import zone.yiqing.pojo.User;/** * @Author Yiqing Zhang * @Date 2020-10-26 7:24 p.m. * @Version 1.0 */public class MyTest &#123; public static void main(String[] args) &#123; // 完全使用了配置类去做, 需要通过AnnotationConfig上下文来获取容器,通过配置类的class对象加载 ApplicationContext context = new AnnotationConfigApplicationContext(YiqingConfig.class); User user = (User)context.getBean(&quot;getUser&quot;);//方法名 System.out.println(user.getName()); &#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"}]},{"title":"SpringMVC-文件上传","slug":"SpringMVC-文件上传","date":"2020-11-17T07:46:17.000Z","updated":"2020-12-11T03:30:27.000Z","comments":true,"path":"2020/11/17/SpringMVC-文件上传/","link":"","permalink":"http://yiiiqing.github.io/2020/11/17/SpringMVC-%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/","excerpt":"","text":"使用Apache发布的Commons FileUpload Servlet 3.0规范已经提供方法来处理文件上传,但是这种上传需要在Servlet中完成 Spring MVC提供了更简单的封装, 使用即插即用的MultipartResolver实现 Spring MVC使用Apache发布的Commons FileUpload技术实现MultipartResolver类:CommonsMultipartResolver,所以SpringMVC的文件上传依赖Apache的Commons FileUpload 导入jar包: commons-fileupload,以及高版本的servlet 12345678910&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt;&lt;/dependency&gt; 配置bean: multipartResolver 注意这个bean的id必须为multipartResolver,否则上传文件会报400的错误 12345678&lt;!--文件上传配置--&gt;&lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;!--请求的编码格式,必须和jsp的pageEncoding一直,以便正确读取表单内容,默认IOS-8859-1--&gt; &lt;property name=&quot;defaultEncoding&quot; value=&quot;utf-8&quot;/&gt; &lt;!--上传文件大小上限,这里是10M--&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;10485760&quot;/&gt; &lt;property name=&quot;maxInMemorySize&quot; value=&quot;40960&quot;/&gt;&lt;/bean&gt; 写一个简单的页面测试 123456789101112&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;$Title$&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=&quot;$&#123;pageContext.request.contextPath&#125;/upload&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;file&quot;/&gt; &lt;input type=&quot;submit&quot; value=&quot;upload&quot;&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; Controller 上传两种方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package zone.yiqing.controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.multipart.commons.CommonsMultipartFile;import javax.servlet.http.HttpServletRequest;import java.io.*;/** * @Author Yiqing Zhang * @Date 2020-11-17 3:51 p.m. * @Version 1.0 */@RestControllerpublic class FileController &#123; /** * InputStream OutputSteaam * @param file * @param request * @return * @throws IOException */ @RequestMapping(&quot;/upload&quot;) public String upload(@RequestParam(&quot;file&quot;)CommonsMultipartFile file, HttpServletRequest request) throws IOException &#123; // 获取文件名 String originalFilename = file.getOriginalFilename(); // 文件名为空,返回首页 if(&quot;&quot;.equals(originalFilename))&#123; return &quot;redirect:/index.jsp&quot;; &#125; System.out.println(&quot;上传文件名: &quot; + originalFilename); // 上传路径保存设置(可以使用UUID) String path = request.getServletContext().getRealPath(&quot;/upload&quot;); // 如果路径不存在,创建 File realPath = new File(path); if(!realPath.exists())&#123; realPath.mkdir(); &#125; System.out.println(&quot;文件上传保存地址: &quot; + realPath); InputStream inputStream = file.getInputStream();// 文件输入流 OutputStream outputStream = new FileOutputStream(new File(realPath, originalFilename));// 文件输出流 // 读取写出 int len = 0; byte[] buffer = new byte[1024]; while ((len=inputStream.read(buffer))!=-1)&#123; outputStream.write(buffer,0,len); outputStream.flush(); &#125; outputStream.close(); inputStream.close(); return &quot;redirect:/index.jsp&quot;; &#125; /** * 采用file.Transto 来保存 * @param file * @param request * @return * @throws IOException */ @RequestMapping(&quot;/upload2&quot;) public String upload2(@RequestParam(&quot;file&quot;)CommonsMultipartFile file, HttpServletRequest request) throws IOException&#123; // 上传路径保存设置 String path = request.getServletContext().getRealPath(&quot;/upload&quot;); // 如果路径不存在,创建 File realPath = new File(path); if(!realPath.exists())&#123; realPath.mkdir(); &#125; System.out.println(&quot;文件上传保存地址: &quot; + realPath); // 通过CommonsMultipartFile的方法直接写文件 file.transferTo(new File(realPath + &quot;/&quot; + file.getOriginalFilename()));; return &quot;redirect:/index.jsp&quot;; &#125;&#125; 下载12345678910111213141516171819202122232425262728@RequestMapping(&quot;/download&quot;) public String download(HttpServletResponse response, HttpServletRequest request) throws Exception&#123; // 要下载的地址 String path = request.getServletContext().getRealPath(&quot;/upload&quot;); String fileName = &quot;xxx.jpg&quot;; // 1. 设置response响应头 response.reset(); // 设置页面不缓存,清空buffer response.setContentType(&quot;multipart/form-data&quot;); // 二进制传输数据 response.setHeader(&quot;Content-Disposition&quot;,&quot;attachment;fileName=&quot;+ URLEncoder.encode(fileName,&quot;UTF-8&quot;)); File file = new File(path,fileName); // 2. 读取文件---输入流 InputStream inputStream = new FileInputStream(file); // 3. 写入文件---输出流 OutputStream outputStream = response.getOutputStream(); byte[] buffer = new byte[1024]; int index = 0; while ((index=inputStream.read(buffer)) != -1)&#123; outputStream.write(buffer,0,index); outputStream.flush(); &#125; outputStream.close(); inputStream.close(); return null; &#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"upload","slug":"upload","permalink":"http://yiiiqing.github.io/tags/upload/"},{"name":"download","slug":"download","permalink":"http://yiiiqing.github.io/tags/download/"}]},{"title":"SpringMVC-拦截器","slug":"SpringMVC-拦截器","date":"2020-11-16T03:20:25.000Z","updated":"2020-11-17T09:41:45.000Z","comments":true,"path":"2020/11/16/SpringMVC-拦截器/","link":"","permalink":"http://yiiiqing.github.io/2020/11/16/SpringMVC-%E6%8B%A6%E6%88%AA%E5%99%A8/","excerpt":"","text":"简介SpringMVC中,拦截器相当于Servlet中的Filter,用于对处理器进行预处理和后处理 与过滤器的区别: 拦截器是AOP思想的具体应用 过滤器 servlet规范中,任何java web工程都可使用 在url-pattern中配置了/*之后, 可以对所有要访问的资源进行拦截 拦截器 SpringMVC框架自己的 只会拦截访问的控制器方法(效率更高), 静态资源如jsp,html,css,image,js不拦截 实现方法: 实现HandlerInterceptor接口 123456789101112131415161718192021222324252627282930313233package zone.yiqing.config;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @Author Yiqing Zhang * @Date 2020-11-16 11:33 a.m. * @Version 1.0 */public class MyInterceptor implements HandlerInterceptor &#123; // return true; 执行下一个拦截器,放行 // return false; 不执行下一个拦截器 // 在这里写拦截方法 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println(&quot;==========处理前==========&quot;); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println(&quot;==========处理后==========&quot;); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println(&quot;==========清理==========&quot;); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"}]},{"title":"Sequelize findAndCountAll count错误的问题","slug":"Sequelize-findAndCountAll-count错误的问题","date":"2020-11-14T10:40:29.000Z","updated":"2020-11-14T10:49:51.000Z","comments":true,"path":"2020/11/14/Sequelize-findAndCountAll-count错误的问题/","link":"","permalink":"http://yiiiqing.github.io/2020/11/14/Sequelize-findAndCountAll-count%E9%94%99%E8%AF%AF%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"平时做项目常用Sequelize的findAndCountAll方法,因为分页的情况下非常好用 但是今天一加了关联查询include:[xxx]之后,计算出来的count就有问题 文档上并没有说明这一点 解决方法: 需要在options中加入distinct:true 链接: https://github.com/sequelize/sequelize/issues/9481 1234567let options = &#123; offset, limit, include: [projectCustomField], distinct:true&#125;;let comms = await Comm.findAndCountAll(options); 这是源码中对distinct的说明 1234/** * Apply COUNT(DISTINCT(col)) */distinct?: boolean; Sequelize根据这个属性来过滤结果集中的重复值,但是数据库中并没有重复值,所以这应该是一个bug","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"Sequelize","slug":"Sequelize","permalink":"http://yiiiqing.github.io/tags/Sequelize/"},{"name":"ORM","slug":"ORM","permalink":"http://yiiiqing.github.io/tags/ORM/"}]},{"title":"npm script 多命令的运行","slug":"npm-script-多命令的运行","date":"2020-11-14T07:57:32.000Z","updated":"2021-01-11T03:42:42.000Z","comments":true,"path":"2020/11/14/npm-script-多命令的运行/","link":"","permalink":"http://yiiiqing.github.io/2020/11/14/npm-script-%E5%A4%9A%E5%91%BD%E4%BB%A4%E7%9A%84%E8%BF%90%E8%A1%8C/","excerpt":"","text":"项目启动时,需要先运行数据库迁移命令,再运行npm start. npm的运行方式有两种:并行和串行 串行使用 &amp;&amp; 符号 1234&quot;scripts&quot;: &#123; &quot;start&quot;: &quot;npx sequelize-cli db:migrate &amp;&amp; node ./bin/www&quot;, &quot;dev&quot;: &quot;npx sequelize-cli db:migrate &amp;&amp; nodemon ./bin/www&quot;&#125;, 前面的命令失败,后面的会终止 并行123&quot;scripts&quot;: &#123; &quot;start&quot;: &quot;npx sequelize-cli db:migrate &amp;&amp; node ./bin/www&quot;&#125; 并行运行,可以加上&amp; wait如果命令启动长时间运行的进程ctrl+c可以结束进程 工具可以使用npm i npm-run-all来实现更好地处理","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"npm","slug":"npm","permalink":"http://yiiiqing.github.io/tags/npm/"}]},{"title":"Ajax","slug":"Ajax","date":"2020-11-14T03:47:23.000Z","updated":"2021-01-11T03:42:47.000Z","comments":true,"path":"2020/11/14/Ajax/","link":"","permalink":"http://yiiiqing.github.io/2020/11/14/Ajax/","excerpt":"","text":"简介 Ajax: Asynchronous JavaScript and XML(异步js和xml) 是一种无需重新加载整个网页的情况下,能更新部分网页的技术 是web应用程序的技术 实例: google或者baidu的搜索框 示例login.jsp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;%-- Created by IntelliJ IDEA. User: Yiqing Date: 2020-11-16 Time: 10:47 a.m. To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;$&#123;pageContext.request.contextPath&#125;/statics/js/jquery-3.5.1.js&quot;&gt;&lt;/script&gt; &lt;script&gt; function a1() &#123; $.post(&#123; url:&quot;$&#123;pageContext.request.contextPath&#125;/a3&quot;, data: &#123;&quot;name&quot;:$(&quot;#name&quot;).val()&#125;, success:function(data)&#123; if(data.toString() === &#x27;ok&#x27;)&#123; $(&quot;#userInfo&quot;).css(&quot;color&quot;,&quot;green&quot;); &#125;else&#123; $(&quot;#userInfo&quot;).css(&quot;color&quot;,&quot;red&quot;); &#125; $(&quot;#userInfo&quot;).html(data) &#125; &#125;) &#125; function a2() &#123; $.post(&#123; url:&quot;$&#123;pageContext.request.contextPath&#125;/a3&quot;, data: &#123;&quot;pwd&quot;:$(&quot;#pwd&quot;).val()&#125;, success:function(data)&#123; if(data.toString() === &#x27;ok&#x27;)&#123; $(&quot;#pwdInfo&quot;).css(&quot;color&quot;,&quot;green&quot;); &#125;else&#123; $(&quot;#pwdInfo&quot;).css(&quot;color&quot;,&quot;red&quot;); &#125; $(&quot;#pwdInfo&quot;).html(data) &#125; &#125;) &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt; 用户名: &lt;input type=&quot;text&quot; id=&quot;name&quot; onblur=&quot;a1()&quot;&gt; &lt;span id=&quot;userInfo&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt; 密码: &lt;input type=&quot;text&quot; id=&quot;pwd&quot; onblur=&quot;a2()&quot;&gt; &lt;span id=&quot;pwdInfo&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; AjaxController 12345678910111213141516171819@RequestMapping(&quot;/a3&quot;)public String a3(String name,String pwd)&#123; String msg = &quot;&quot;; if(name!=null)&#123; if(&quot;admin&quot;.equals(name))&#123; msg = &quot;ok&quot;; &#125;else&#123; msg = &quot;用户名错误&quot;; &#125; &#125; if(pwd!=null)&#123; if(&quot;123456&quot;.equals(pwd))&#123; msg = &quot;ok&quot;; &#125;else&#123; msg = &quot;密码有误&quot;; &#125; &#125; return msg;&#125;","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"Ajax","slug":"Ajax","permalink":"http://yiiiqing.github.io/tags/Ajax/"}]},{"title":"JavaScript修改对象属性名","slug":"JavaScript修改对象属性名","date":"2020-11-13T08:29:13.000Z","updated":"2020-11-13T08:30:48.000Z","comments":true,"path":"2020/11/13/JavaScript修改对象属性名/","link":"","permalink":"http://yiiiqing.github.io/2020/11/13/JavaScript%E4%BF%AE%E6%94%B9%E5%AF%B9%E8%B1%A1%E5%B1%9E%E6%80%A7%E5%90%8D/","excerpt":"","text":"主要方法就是新增想要的键值对,然后删除旧的 1234if(result[&#x27;count&#x27;] &amp;&amp; result[&#x27;rows&#x27;])&#123; Object.defineProperty(result,&#x27;total&#x27;,Object.getOwnPropertyDescriptor(result,&#x27;count&#x27;)); delete result[&#x27;count&#x27;];&#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/tags/JavaScript/"}]},{"title":"Node.js后台分页功能","slug":"Node-js后台分页功能","date":"2020-11-13T08:07:16.000Z","updated":"2020-11-13T08:14:23.000Z","comments":true,"path":"2020/11/13/Node-js后台分页功能/","link":"","permalink":"http://yiiiqing.github.io/2020/11/13/Node-js%E5%90%8E%E5%8F%B0%E5%88%86%E9%A1%B5%E5%8A%9F%E8%83%BD/","excerpt":"","text":"今天后台接口有一个在本地测试没问题,上传到预发布环境就一直没有返回,也没有报错,排错了半天发现是这个接口没有添加分页功能 正好在这里记录一下分页功能 express和koa我都用的sequelize,代码是通用的 如果没有上传,默认十条数据分页,查询第一页 12345let &#123; per_page, page &#125; = ctx.request.query; // 根据框架略有不同page = page ? parseInt(page) : 1;limit = limit ? parseInt(per_page) : 10;let offset = page ? (page - 1) * limit : 0;// 然后将offset和limit传入sequelize的options中","categories":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/categories/Node-js/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/tags/JavaScript/"},{"name":"koa","slug":"koa","permalink":"http://yiiiqing.github.io/tags/koa/"},{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/tags/Node-js/"},{"name":"Express","slug":"Express","permalink":"http://yiiiqing.github.io/tags/Express/"},{"name":"Sequelize","slug":"Sequelize","permalink":"http://yiiiqing.github.io/tags/Sequelize/"}]},{"title":"Spring中结合AOP实现事务的织入","slug":"Spring中结合AOP实现事务的织入","date":"2020-11-13T04:22:59.000Z","updated":"2020-11-13T04:32:49.000Z","comments":true,"path":"2020/11/13/Spring中结合AOP实现事务的织入/","link":"","permalink":"http://yiiiqing.github.io/2020/11/13/Spring%E4%B8%AD%E7%BB%93%E5%90%88AOP%E5%AE%9E%E7%8E%B0%E4%BA%8B%E5%8A%A1%E7%9A%84%E7%BB%87%E5%85%A5/","excerpt":"","text":"首先引入织入包 pom.xml 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt;&lt;/dependency&gt; 添加切面 在spring的配置文件中 12345678910111213141516171819202122232425&lt;!--配置声明式事务--&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;datasource&quot;/&gt;&lt;/bean&gt;&lt;!--结合AOP实现事务的织入--&gt;&lt;!--配置事务通知--&gt;&lt;tx:advice id=&quot;txADVICE&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;!--给哪些方法配置事务--&gt; &lt;!--配置事务的传播特性--&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;add&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;delete&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;update&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;query&quot; read-only=&quot;true&quot;/&gt; &lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!--配置事务切入--&gt;&lt;aop:config&gt; &lt;!--切入点--&gt; &lt;aop:pointcut id=&quot;txPointCut&quot; expression=&quot;execution(* zone.yiqing.dao.*.*(..))&quot;/&gt; &lt;!--切入方法--&gt; &lt;aop:advisor advice-ref=&quot;txADVICE&quot; pointcut-ref=&quot;txPointCut&quot;/&gt;&lt;/aop:config&gt;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"}]},{"title":"Bootstrap cdn","slug":"Bootstrap-cdn","date":"2020-11-13T02:42:55.000Z","updated":"2021-01-11T03:43:23.000Z","comments":true,"path":"2020/11/13/Bootstrap-cdn/","link":"","permalink":"http://yiiiqing.github.io/2020/11/13/Bootstrap-cdn/","excerpt":"","text":"12345678&lt;!-- 最新版本的 Bootstrap 核心 CSS 文件 --&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css&quot; integrity=&quot;sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;!-- 可选的 Bootstrap 主题文件（一般不用引入） --&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap-theme.min.css&quot; integrity=&quot;sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;!-- 最新的 Bootstrap 核心 JavaScript 文件 --&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js&quot; integrity=&quot;sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;","categories":[{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"}],"tags":[{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://yiiiqing.github.io/tags/Bootstrap/"},{"name":"CDN","slug":"CDN","permalink":"http://yiiiqing.github.io/tags/CDN/"},{"name":"样式","slug":"样式","permalink":"http://yiiiqing.github.io/tags/%E6%A0%B7%E5%BC%8F/"}]},{"title":"sequelize operators","slug":"sequelize-operators","date":"2020-11-12T10:40:39.000Z","updated":"2020-11-12T10:44:04.000Z","comments":true,"path":"2020/11/12/sequelize-operators/","link":"","permalink":"http://yiiiqing.github.io/2020/11/12/sequelize-operators/","excerpt":"","text":"常用的Sequelize symbol operators 操作符 Sequelize 版本: v5 123456789101112131415161718192021222324252627282930313233343536const Op = Sequelize.Op[Op.and]: [&#123;a: 5&#125;, &#123;b: 6&#125;] // (a = 5) AND (b = 6)[Op.or]: [&#123;a: 5&#125;, &#123;a: 6&#125;] // (a = 5 OR a = 6)[Op.gt]: 6, // &gt; 6[Op.gte]: 6, // &gt;= 6[Op.lt]: 10, // &lt; 10[Op.lte]: 10, // &lt;= 10[Op.ne]: 20, // != 20[Op.eq]: 3, // = 3[Op.is]: null // IS NULL[Op.not]: true, // IS NOT TRUE[Op.between]: [6, 10], // BETWEEN 6 AND 10[Op.notBetween]: [11, 15], // NOT BETWEEN 11 AND 15[Op.in]: [1, 2], // IN [1, 2][Op.notIn]: [1, 2], // NOT IN [1, 2][Op.like]: &#x27;%hat&#x27;, // LIKE &#x27;%hat&#x27;[Op.notLike]: &#x27;%hat&#x27; // NOT LIKE &#x27;%hat&#x27;[Op.iLike]: &#x27;%hat&#x27; // ILIKE &#x27;%hat&#x27; (case insensitive) (PG only)[Op.notILike]: &#x27;%hat&#x27; // NOT ILIKE &#x27;%hat&#x27; (PG only)[Op.startsWith]: &#x27;hat&#x27; // LIKE &#x27;hat%&#x27;[Op.endsWith]: &#x27;hat&#x27; // LIKE &#x27;%hat&#x27;[Op.substring]: &#x27;hat&#x27; // LIKE &#x27;%hat%&#x27;[Op.regexp]: &#x27;^[h|a|t]&#x27; // REGEXP/~ &#x27;^[h|a|t]&#x27; (MySQL/PG only)[Op.notRegexp]: &#x27;^[h|a|t]&#x27; // NOT REGEXP/!~ &#x27;^[h|a|t]&#x27; (MySQL/PG only)[Op.iRegexp]: &#x27;^[h|a|t]&#x27; // ~* &#x27;^[h|a|t]&#x27; (PG only)[Op.notIRegexp]: &#x27;^[h|a|t]&#x27; // !~* &#x27;^[h|a|t]&#x27; (PG only)[Op.like]: &#123; [Op.any]: [&#x27;cat&#x27;, &#x27;hat&#x27;]&#125; // LIKE ANY ARRAY[&#x27;cat&#x27;, &#x27;hat&#x27;] - also works for iLike and notLike[Op.overlap]: [1, 2] // &amp;&amp; [1, 2] (PG array overlap operator)[Op.contains]: [1, 2] // @&gt; [1, 2] (PG array contains operator)[Op.contained]: [1, 2] // &lt;@ [1, 2] (PG array contained by operator)[Op.any]: [2,3] // ANY ARRAY[2, 3]::INTEGER (PG only)[Op.col]: &#x27;user.organization_id&#x27; // = &quot;user&quot;.&quot;organization_id&quot;, with dialect specific column identifiers, PG in this example[Op.gt]: &#123; [Op.all]: literal(&#x27;SELECT 1&#x27;) &#125; // &gt; ALL (SELECT 1)","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/tags/Node-js/"},{"name":"Sequelize","slug":"Sequelize","permalink":"http://yiiiqing.github.io/tags/Sequelize/"},{"name":"ORM","slug":"ORM","permalink":"http://yiiiqing.github.io/tags/ORM/"}]},{"title":"pm2使用npm命令","slug":"使用pm2","date":"2020-11-12T05:58:35.000Z","updated":"2020-11-12T06:17:35.000Z","comments":true,"path":"2020/11/12/使用pm2/","link":"","permalink":"http://yiiiqing.github.io/2020/11/12/%E4%BD%BF%E7%94%A8pm2/","excerpt":"","text":"使用pm2托管我的后台服务已经有一段时间了 之前直接就是 1pm2 start app.js --name myapp --watch 后来发现不可避免的需要使用npm命令启动,比如想通过nodemon启动,命令是npm run dev 于是查找了一下pm2通过npm运行的方法: 1pm2 start npm -- start --watch 然后想当然的就 1pm2 start npm -- run dev --name myapp --watch 启动之后发现,项目被命名为了npm? 后来一想应该是参数位置的原因 正确的方法是 1pm2 start npm --name myapp -- run dev --watch 但是发现–watch没有生效 查看了pm2官网,发现官方说明: PM2 can automatically restart your application when a file is modified in the current directory or its subdirectories 所以最终使用了 12pm2 start ./bin/www --name myapp --watchpm2 start npm --name myapp -- run dev 因为其实express也是通过./bin/www来启动的 都是可以监听变化的","categories":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/categories/Node-js/"}],"tags":[{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/tags/Node-js/"},{"name":"express","slug":"express","permalink":"http://yiiiqing.github.io/tags/express/"},{"name":"npm","slug":"npm","permalink":"http://yiiiqing.github.io/tags/npm/"},{"name":"pm2","slug":"pm2","permalink":"http://yiiiqing.github.io/tags/pm2/"}]},{"title":"SSM框架整合项目实战-业务实现","slug":"SSM框架整合项目实战-业务实现","date":"2020-11-12T05:27:50.000Z","updated":"2020-11-13T06:40:14.000Z","comments":true,"path":"2020/11/12/SSM框架整合项目实战-业务实现/","link":"","permalink":"http://yiiiqing.github.io/2020/11/12/SSM%E6%A1%86%E6%9E%B6%E6%95%B4%E5%90%88%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E4%B8%9A%E5%8A%A1%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"SSM框架整合项目实战-业务实现本文延续上篇: SSM框架整合项目实战-框架搭建 1. 查询书籍1. Controller新增一个接口用于查询数据 12345678910111213141516171819202122232425262728293031323334package zone.yiqing.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import zone.yiqing.pojo.Books;import zone.yiqing.service.BookService;import java.util.List;/** * @Author Yiqing Zhang * @Date 2020-11-12 1:28 p.m. * @Version 1.0 */@Controller@RequestMapping(&quot;/book&quot;)public class BookController &#123; // controller调service层 @Autowired @Qualifier(&quot;BookServiceImpl&quot;) private BookService bookService; // 查询全部的书籍, 并且返回到一个书籍展示页面 @RequestMapping(&quot;/allBook&quot;) public String list(Model model)&#123; List&lt;Books&gt; list = bookService.queryAllBook(); model.addAttribute(&quot;list&quot;,list); return &quot;allBook&quot;; &#125;&#125; 2. 创建查询页面123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;书籍展示&lt;/title&gt; &lt;%--bootstrap--%&gt; &lt;!-- 最新版本的 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css&quot; integrity=&quot;sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row clearfix&quot;&gt; &lt;div class=&quot;col-md-12 column&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt; &lt;small&gt;书籍列表 ------ 显示所有书籍&lt;/small&gt; &lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;row clearfix&quot;&gt; &lt;div class=&quot;col-md-12 column&quot;&gt; &lt;table class=&quot;table table-hover table-striped&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;书籍编号&lt;/th&gt; &lt;th&gt;书籍名称&lt;/th&gt; &lt;th&gt;书籍数量&lt;/th&gt; &lt;th&gt;书籍详情&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;%--书籍从数据库中取出,遍历--%&gt; &lt;tbody&gt; &lt;c:forEach var=&quot;book&quot; items=&quot;$&#123;list&#125;&quot;&gt; &lt;tr&gt; &lt;td&gt;$&#123;book.bookID&#125;&lt;/td&gt; &lt;td&gt;$&#123;book.bookName&#125;&lt;/td&gt; &lt;td&gt;$&#123;book.bookCounts&#125;&lt;/td&gt; &lt;td&gt;$&#123;book.detail&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3. 首页首页新增调转 为了项目发布之后也能稳定运行:取绝对地址 123456789101112131415161718192021222324252627&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;首页&lt;/title&gt; &lt;style&gt; a&#123; text-decoration: none; color:black; font-size: 18px; &#125; h3&#123; width:180px; height: 38px; margin: 100px auto; text-align: center; line-height: 38px; background: deepskyblue; border-radius: 5px; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h3&gt; &lt;a href=&quot;$&#123;pageContext.request.contextPath&#125;/book/allBook&quot;&gt;进入书籍页面 &lt;/a&gt; &lt;/h3&gt; &lt;/body&gt;&lt;/html&gt; 页面效果 2. 添加书籍1. Controller12345678910111213// 跳转到增加书籍页面@RequestMapping(&quot;/toAddBook&quot;)public String toAddPage() &#123; return &quot;addBook&quot;;&#125;// 添加书籍的请求@RequestMapping(&quot;/addBook&quot;)public String addBook(Books books) &#123; System.out.println(&quot;add book&quot; + books); bookService.addBook(books); return &quot;redirect:/book/allBook&quot;; //重定向到@RequestMapping(&quot;/allBook&quot;)&#125; 2. 修改书籍展示页面123456&lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-md-4 column&quot;&gt; &lt;%--toAddBook--%&gt; &lt;a class=&quot;btn btn-primary&quot; href=&quot;$&#123;pageContext.request.contextPath&#125;/book/toAddBook&quot;&gt;新增书籍&lt;/a&gt; &lt;/div&gt;&lt;/div&gt; 3. 新建添加书籍页面 addBook.jsp 注意表单的name要和实体类的字段名一致 如果字段为空上传会报错,所以在表单中添加required属性 表单label的for是为了点击label跳转到input框的 表单的action地址注意写绝对地址 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;%-- Created by IntelliJ IDEA. User: Yiqing Date: 2020-11-13 Time: 11:01 a.m. To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;新增书籍&lt;/title&gt; &lt;%--bootstrap--%&gt; &lt;!-- 最新版本的 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css&quot; integrity=&quot;sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row clearfix&quot;&gt; &lt;div class=&quot;col-md-12 column&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt; &lt;small&gt;新增书籍&lt;/small&gt; &lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;form action=&quot;$&#123;pageContext.request.contextPath&#125;/book/addBook&quot; method=&quot;post&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;bkname&quot;&gt;书籍名称:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;bookName&quot; class=&quot;form-control&quot; id=&quot;bkname&quot; required&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;bknumber&quot;&gt;书籍数量:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;bookCounts&quot; class=&quot;form-control&quot; id=&quot;bknumber&quot; required&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;bkdesc&quot;&gt;书籍描述:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;detail&quot; class=&quot;form-control&quot; id=&quot;bkdesc&quot; required&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input type=&quot;submit&quot; class=&quot;form-control&quot; value=&quot;添加&quot;&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3. 修改书籍1. Controller123456789101112131415// 跳转到修改页面@RequestMapping(&quot;/toUpdateBook&quot;)public String toUpdatePage(int id, Model model) &#123; Books books = bookService.queryBookById(id); model.addAttribute(&quot;QBook&quot;,books); return &quot;updatePage&quot;;&#125;// 修改书籍@RequestMapping(&quot;/updateBook&quot;)public String updateBook(Books books)&#123; System.out.println(&quot;updateBook=&gt;&quot;+books); bookService.updateBook(books); return &quot;redirect:/book/allBook&quot;;&#125; 2. 修改书籍展示页面1234567891011121314151617181920212223242526&lt;table class=&quot;table table-hover table-striped&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;书籍编号&lt;/th&gt; &lt;th&gt;书籍名称&lt;/th&gt; &lt;th&gt;书籍数量&lt;/th&gt; &lt;th&gt;书籍详情&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;%--书籍从数据库中取出,遍历--%&gt; &lt;tbody&gt; &lt;c:forEach var=&quot;book&quot; items=&quot;$&#123;list&#125;&quot;&gt; &lt;tr&gt; &lt;td&gt;$&#123;book.bookID&#125;&lt;/td&gt; &lt;td&gt;$&#123;book.bookName&#125;&lt;/td&gt; &lt;td&gt;$&#123;book.bookCounts&#125;&lt;/td&gt; &lt;td&gt;$&#123;book.detail&#125;&lt;/td&gt; &lt;td&gt; &lt;a href=&quot;$&#123;pageContext.request.contextPath&#125;/book/toUpdateBook?id=$&#123;book.bookID&#125;&quot;&gt;修改&lt;/a&gt; &amp;nbsp; &lt;a href=&quot;&quot;&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;/tbody&gt; &lt;/table&gt; 3. 新建修改书籍页面1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;%-- Created by IntelliJ IDEA. User: Yiqing Date: 2020-11-13 Time: 11:37 a.m. To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;修改书籍&lt;/title&gt; &lt;%--bootstrap--%&gt; &lt;!-- 最新版本的 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css&quot; integrity=&quot;sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row clearfix&quot;&gt; &lt;div class=&quot;col-md-12 column&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h1&gt; &lt;small&gt;修改书籍&lt;/small&gt; &lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;form action=&quot;$&#123;pageContext.request.contextPath&#125;/book/updateBook&quot; method=&quot;post&quot;&gt; &lt;%--提交要上传id,否则无法查找修改,前端传递隐藏域--%&gt; &lt;input type=&quot;hidden&quot; name=&quot;bookID&quot; value=&quot;$&#123;QBook.bookID&#125;&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;bkname&quot;&gt;书籍名称:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;bookName&quot; class=&quot;form-control&quot; id=&quot;bkname&quot; value=&quot;$&#123;QBook.bookName&#125;&quot; required&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;bknumber&quot;&gt;书籍数量:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;bookCounts&quot; class=&quot;form-control&quot; id=&quot;bknumber&quot; value=&quot;$&#123;QBook.bookCounts&#125;&quot; required&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;bkdesc&quot;&gt;书籍描述:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;detail&quot; class=&quot;form-control&quot; id=&quot;bkdesc&quot; value=&quot;$&#123;QBook.detail&#125;&quot; required&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input type=&quot;submit&quot; class=&quot;form-control&quot; value=&quot;添加&quot;&gt; &lt;/div&gt; &lt;/form&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 4. 删除书籍1. Controller123456// 删除书籍@RequestMapping(&quot;/deleteBook/&#123;bookID&#125;&quot;)public String deleteBook(@PathVariable(&quot;bookID&quot;) int id) &#123; bookService.deleteBookById(id); return &quot;redirect:/book/allBook&quot;;&#125; 2. 修改书籍展示页面1&lt;a href=&quot;$&#123;pageContext.request.contextPath&#125;/book/deleteBook/$&#123;book.bookID&#125;&quot;&gt;删除&lt;/a&gt; 5. 配置日志和事务1. 开启日志在mybatis的配置中添加setting 123&lt;settings&gt; &lt;setting name=&quot;logImpl&quot; value=&quot;STDOUT_LOGGING&quot;/&gt; &lt;/settings&gt; 2. 配置事务切面织入spring-service.xml 1234567891011121314151617181920&lt;!--结合AOP实现事务的织入--&gt;&lt;!--配置事务通知--&gt;&lt;tx:advice id=&quot;txADVICE&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;!--给哪些方法配置事务--&gt; &lt;!--配置事务的传播特性--&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;add&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;delete&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;update&quot; propagation=&quot;REQUIRED&quot;/&gt; &lt;tx:method name=&quot;query&quot; read-only=&quot;true&quot;/&gt; &lt;!--&lt;tx:method name=&quot;*&quot; propagation=&quot;REQUIRED&quot;/&gt;--&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!--配置事务切入--&gt;&lt;aop:config&gt; &lt;!--切入点--&gt; &lt;aop:pointcut id=&quot;txPointCut&quot; expression=&quot;execution(* zone.yiqing.dao.*.*(..))&quot;/&gt; &lt;!--切入方法--&gt; &lt;aop:advisor advice-ref=&quot;txADVICE&quot; pointcut-ref=&quot;txPointCut&quot;/&gt;&lt;/aop:config&gt; 6. 搜索功能1. Controller123456789101112131415// 查询书籍@RequestMapping(&quot;/queryBook&quot;)public String queryBook(String queryBookName, Model model)&#123; Books books = bookService.queryBookByName(queryBookName); List&lt;Books&gt; list = new ArrayList&lt;&gt;(); if(books == null)&#123; list = bookService.queryAllBook(); model.addAttribute(&quot;error&quot;,&quot;未查到&quot;); &#125;else&#123; list.add(books); &#125; model.addAttribute(&quot;list&quot;,list); return &quot;allBook&quot;;&#125; 2. 页面新增查询表单123456789&lt;div class=&quot;col-md-8 column&quot;&gt; &lt;%--查询书籍--%&gt; &lt;form action=&quot;$&#123;pageContext.request.contextPath&#125;/book/queryBook&quot; method=&quot;post&quot; style=&quot;float: right&quot; class=&quot;form-inline&quot;&gt; &lt;span style=&quot;color: #ff0000; font-weight: bold&quot;&gt;$&#123;error&#125;&lt;/span&gt; &lt;input type=&quot;text&quot; placeholder=&quot;请输入要查询的书籍名称&quot; class=&quot;form-control&quot; name=&quot;queryBookName&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;查询&quot; class=&quot;btn btn-primary&quot;&gt; &lt;/form&gt;&lt;/div&gt; 3. dao层3.1 interface12// 搜索Books queryBookByName(@Param(&quot;bookName&quot;) String bookName); 3.2 mapper.xml123&lt;select id=&quot;queryBookByName&quot; resultType=&quot;Books&quot;&gt; select * from books where bookName=#&#123;bookName&#125;;&lt;/select&gt; 4. service层4.1 interface12// 搜索Books queryBookByName(String bookName); 4.2 实现类impl1234@Overridepublic Books queryBookByName(String bookName) &#123; return bookMapper.queryBookByName(bookName);&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://yiiiqing.github.io/tags/Mybatis/"},{"name":"项目","slug":"项目","permalink":"http://yiiiqing.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"SSM框架整合项目实战-框架搭建","slug":"SSM框架整合项目实战-框架搭建","date":"2020-11-12T02:52:26.000Z","updated":"2020-11-12T06:48:08.000Z","comments":true,"path":"2020/11/12/SSM框架整合项目实战-框架搭建/","link":"","permalink":"http://yiiiqing.github.io/2020/11/12/SSM%E6%A1%86%E6%9E%B6%E6%95%B4%E5%90%88%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA/","excerpt":"","text":"SSM框架整合项目实战-框架搭建好不容易学完了SSM, 不实战一下怎么行? 基础框架1. 新建一个maven项目2. 配置maven: 导入依赖和静态资源过滤问题12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;!--依赖:junit,数据库驱动,连接池,servlet,jsp,mybatis,mybatis-spring,spring--&gt;&lt;dependencies&gt; &lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.mchange&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Servlet--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;jsp-api-2.0&lt;/artifactId&gt; &lt;version&gt;6.1.26&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--Mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--Spring--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--静态资源导出问题--&gt;&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 3. 编写mybatis配置文件1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;&lt;/configuration&gt; 4. 编写Spring的applicationContext.xmlwenjian1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;&lt;/beans&gt; 5. 创建数据库数据123456789101112131415161718CREATE DATABASE `ssmbuild`;USE `ssmbuild`;DROP TABLE IF EXISTS `books`;CREATE TABLE `books` ( `bookID` INT(10) NOT NULL AUTO_INCREMENT COMMENT &#x27;书id&#x27;, `bookName` VARCHAR(100) NOT NULL COMMENT &#x27;书名&#x27;, `bookCounts` INT(11) NOT NULL COMMENT &#x27;数量&#x27;, `detail` VARCHAR(200) NOT NULL COMMENT &#x27;描述&#x27;, KEY `bookID` (`bookID`)) ENGINE=INNODB DEFAULT CHARSET=utf8INSERT INTO `books`(`bookID`,`bookName`,`bookCounts`,`detail`) VALUES(1,&#x27;Java&#x27;,1,&#x27;从入门到放弃&#x27;),(2,&#x27;MySQL&#x27;,10,&#x27;从删库到跑路&#x27;),(3,&#x27;Linux&#x27;,5,&#x27;从进门到进牢&#x27;); Mybatis1. 编写数据库配置文件properties12345jdbc.driver=com.mysql.jdbc.Driver# 如果使用的是MySQL 8.0+,需要添加时区设置 &amp;serverTimezone=Asia/Shanghaijdbc.url=jdbc:mysql://localhost:3306/ssmbuild?useSSL=true&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=Asia/Shanghaijdbc.username=rootjdbc.password=zzz 2. 编写数据库对应的实体类1234567891011121314151617181920package zone.yiqing.pojo;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;/** * @Author Yiqing Zhang * @Date 2020-11-12 10:19 a.m. * @Version 1.0 */@Data@AllArgsConstructor@NoArgsConstructorpublic class Books &#123; private int bookID; private String bookName; private int bookCounts; private String detail;&#125; 3. 编写Mybatis核心配置文件1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;!--配置数据源,交给Spring去做--&gt; &lt;typeAliases&gt; &lt;package name=&quot;zone.yiqing.pojo&quot;/&gt; &lt;/typeAliases&gt; &lt;mappers&gt; &lt;mapper class=&quot;zone.yiqing.dao.BookMapper&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 4. dao层4.1 interface123456789101112131415161718192021222324package zone.yiqing.dao;import org.apache.ibatis.annotations.Param;import zone.yiqing.pojo.Books;import java.util.List;/** * @Author Yiqing Zhang * @Date 2020-11-12 10:22 a.m. * @Version 1.0 */public interface BookMapper &#123; // 增加一本书 int addBook(Books books); // 删除一本书 int deleteBookById(@Param(&quot;bookId&quot;) int id); // 更新一本书 int updateBook(Books books); // 查询一本书 Books queryBookById(int id); // 查询全部书 List&lt;Books&gt; queryAllBook();&#125; 4.2 mapper.xml12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;zone.yiqing.dao.BookMapper&quot;&gt; &lt;insert id=&quot;addBook&quot; parameterType=&quot;Books&quot;&gt; insert into books (bookName,bookCounts,detail) values (#&#123;bookName&#125;,#&#123;bookCounts&#125;,#&#123;detail&#125;); &lt;/insert&gt; &lt;delete id=&quot;deleteBookById&quot; parameterType=&quot;int&quot;&gt; delete from books where bookID = #&#123;bookId&#125; &lt;/delete&gt; &lt;update id=&quot;updateBook&quot; parameterType=&quot;Books&quot;&gt; update books set bookName=#&#123;bookName&#125;,bookCounts=#&#123;bookCounts&#125;,detail=#&#123;detail&#125; where bookID=#&#123;bookID&#125;; &lt;/update&gt; &lt;select id=&quot;queryBookById&quot; resultType=&quot;Books&quot;&gt; select * from books where bookID=#&#123;bookID&#125;; &lt;/select&gt; &lt;select id=&quot;queryAllBook&quot; resultType=&quot;Books&quot;&gt; select * from books; &lt;/select&gt;&lt;/mapper&gt; 5. 将mapper在mabatis中注册(见3)6. service层service层和dao层的区别: dao是操作数据库,service层是处理业务,只是在该项目中,业务基本和dao层重合,所以可以理解为service是dao层的一个代理 6.1 interface1234567891011121314151617181920212223package zone.yiqing.service;import zone.yiqing.pojo.Books;import java.util.List;/** * @Author Yiqing Zhang * @Date 2020-11-12 10:33 a.m. * @Version 1.0 */public interface BookService &#123; // 增加一本书 int addBook(Books books); // 删除一本书 int deleteBookById(int id); // 更新一本书 int updateBook(Books books); // 查询一本书 Books queryBookById(int id); // 查询全部书 List&lt;Books&gt; queryAllBook();&#125; 6.2 编写实现类注意因为是整合Spring,所以要有注入方式 1234567891011121314151617181920212223242526272829303132333435363738394041package zone.yiqing.service;import zone.yiqing.dao.BookMapper;import zone.yiqing.pojo.Books;import java.util.List;/** * @Author Yiqing Zhang * @Date 2020-11-12 10:35 a.m. * @Version 1.0 */public class BookServiceImpl implements BookService &#123; //service层调dao层:组合 private BookMapper bookMapper; //为了spring托管,增加set方法 public void setBookMapper(BookMapper bookMapper) &#123; this.bookMapper = bookMapper; &#125; public int addBook(Books books) &#123; return bookMapper.addBook(books); &#125; public int deleteBookById(int id) &#123; return bookMapper.deleteBookById(id); &#125; public int updateBook(Books books) &#123; return bookMapper.updateBook(books); &#125; public Books queryBookById(int id) &#123; return bookMapper.queryBookById(id); &#125; public List&lt;Books&gt; queryAllBook() &#123; return bookMapper.queryAllBook(); &#125;&#125; Spring层1. 整合dao层在resources下新建文件 spring-dao.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--1.关联数据库配置文件, 不再通过Mybatis去读了,用Spring去读--&gt; &lt;context:property-placeholder location=&quot;classpath:database.properties&quot;/&gt; &lt;!--2.连接池 dbcp: 半自动化,不能自动连接 c3p0: 自动化操作,自动化加载配置文件,并且可以自动设置到对象中! druid hikari --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;/&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt; &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;/&gt; &lt;!--c3p0连接池的自由属性--&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;30&quot;/&gt; &lt;property name=&quot;minPoolSize&quot; value=&quot;10&quot;/&gt; &lt;!--关闭连接后不自动commit--&gt; &lt;property name=&quot;autoCommitOnClose&quot; value=&quot;false&quot;/&gt; &lt;!--获取连接超时时间--&gt; &lt;property name=&quot;checkoutTimeout&quot; value=&quot;10000&quot;/&gt; &lt;!--当获取连接失败,重试次数--&gt; &lt;property name=&quot;acquireRetryAttempts&quot; value=&quot;2&quot;/&gt; &lt;/bean&gt; &lt;!--3.sqlSessionFactory--&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!--绑定Mybatis的配置文件--&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置dao接口扫描包,动态实现了Dao接口可以注入到Spring容器中 实现类impl不用再手动自己写,Spring通过反射做了 --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt; &lt;property name=&quot;basePackage&quot; value=&quot;zone.yiqing.dao&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 2. 整合service层12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--1.扫描service下的包--&gt; &lt;context:component-scan base-package=&quot;zone.yiqing.service&quot;/&gt; &lt;!--2.将我们的所有业务类,注入Spring,可以通过配置,或者注解实现--&gt; &lt;bean id=&quot;BookServiceImpl&quot; class=&quot;zone.yiqing.service.BookServiceImpl&quot;&gt; &lt;property name=&quot;bookMapper&quot; ref=&quot;bookMapper&quot;/&gt; &lt;/bean&gt; &lt;!--3.声明式事务--&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;!--注入数据源--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;!--4.aop事务支持--&gt;&lt;/beans&gt; 3. 在applicationContext.xml中引入12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;import resource=&quot;spring-dao.xml&quot;/&gt; &lt;import resource=&quot;spring-service.xml&quot;/&gt;&lt;/beans&gt; SpringMVC层1. 将项目添加web项目支持2. 配置web.xml1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot; version=&quot;4.0&quot;&gt; &lt;!--DispatherServlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--乱码过滤--&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;!--解决包括jsp的乱码--&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--session--&gt; &lt;session-config&gt; &lt;session-timeout&gt;15&lt;/session-timeout&gt; &lt;/session-config&gt;&lt;/web-app&gt; 3. 配置spring-mvc.xml1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt; &lt;!--注解驱动--&gt; &lt;mvc:annotation-driven/&gt; &lt;!--静态资源过滤--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--扫描包:controller--&gt; &lt;context:component-scan base-package=&quot;zone.yiqing.controller&quot;/&gt; &lt;!--视图解析器--&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 4. 在WEB-INF下创建jsp文件夹用于存放静态页面 以上就是一个SSM框架搭建的Java WEB项目模板,可以用于基础来构建所有项目","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://yiiiqing.github.io/tags/Mybatis/"},{"name":"项目","slug":"项目","permalink":"http://yiiiqing.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"jdbc数据库配置文件","slug":"jdbc数据库配置文件","date":"2020-11-12T02:14:40.000Z","updated":"2020-11-12T03:22:29.000Z","comments":true,"path":"2020/11/12/jdbc数据库配置文件/","link":"","permalink":"http://yiiiqing.github.io/2020/11/12/jdbc%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","excerpt":"","text":"12345jdbc.driver=com.mysql.jdbc.Driver# 如果使用的是MySQL 8.0+,需要添加时区设置 &amp;serverTimezone=Asia/Shanghaijdbc.url=jdbc:mysql://localhost:3306/ssmbuild?useSSL=true&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=Asia/Shanghaijdbc.username=rootjdbc.password=zzz 如果使用的是MySQL 8.0+,需要添加时区设置 &amp;serverTimezone=Asia/Shanghai","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/tags/MySQL/"},{"name":"jdbc","slug":"jdbc","permalink":"http://yiiiqing.github.io/tags/jdbc/"}]},{"title":"Java项目运行乱码处理","slug":"Java项目运行乱码处理","date":"2020-11-09T11:03:30.000Z","updated":"2020-11-16T03:49:20.000Z","comments":true,"path":"2020/11/09/Java项目运行乱码处理/","link":"","permalink":"http://yiiiqing.github.io/2020/11/09/Java%E9%A1%B9%E7%9B%AE%E8%BF%90%E8%A1%8C%E4%B9%B1%E7%A0%81%E5%A4%84%E7%90%86/","excerpt":"","text":"表单提交中文出现的乱码问题的解决方法在web.xml中添加filter配置 注意: 过滤器映射url-pattern用/不是/ */不拦截jsp文件,/*拦截jsp文件 123456789101112&lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 返回的json乱码在applicationContext.xml文件中 123456789101112131415&lt;!--JSON乱码问题配置--&gt;&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;constructor-arg value=&quot;UTF-8&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;objectMapper&quot;&gt; &lt;bean class=&quot;org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean&quot;&gt; &lt;property name=&quot;failOnEmptyBeans&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 控制台乱码问题在tomcat配置中,VM options加入 -Dfile.encoding=UTF-8","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"}]},{"title":"SpringMVC-数据处理","slug":"SpringMVC-数据处理","date":"2020-11-09T10:11:59.000Z","updated":"2020-11-09T10:45:11.000Z","comments":true,"path":"2020/11/09/SpringMVC-数据处理/","link":"","permalink":"http://yiiiqing.github.io/2020/11/09/SpringMVC-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/","excerpt":"","text":"处理提交数据 提交的域名和处理方法的参数名一致 提交: /hello?name=yiqing 处理: 123456789101112131415@Controller@RequestMapping(&quot;/user&quot;)public class UserController &#123; //localhost:8080/user/t1?name=xxx; @GetMapping(&quot;/t1&quot;) public String test1(String name, Model model)&#123; // 1. 接收前端参数 System.out.println(&quot;receive param: &quot; + name); // 2. 将返回结果传递给前端 model.addAttribute(&quot;msg&quot;,name); // 3. 视图跳转 return &quot;test&quot;; &#125;&#125; 提交的域名和处理方法参数不一致 使用@RequestParam规定值的名称 建议全部加上 123456789101112131415@Controller@RequestMapping(&quot;/user&quot;)public class UserController &#123; //localhost:8080/user/t1?username=xxx; @GetMapping(&quot;/t1&quot;) public String test1(@RequestParam(&quot;username&quot;) String name, Model model)&#123; // 1. 接收前端参数 System.out.println(&quot;receive param: &quot; + name); // 2. 将返回结果传递给前端 model.addAttribute(&quot;msg&quot;,name); // 3. 视图跳转 return &quot;test&quot;; &#125;&#125; 提交的对象 提交的表单域和对象的属性名一致 不一致就是null 123456//pojopublic class User &#123; private int id; private String name; private int age;&#125; 123456789101112//controller/** * 接收前端用户传递的参数,判断参数名,如果参数名在方法上,直接使用 * 假设传递的是一个对象User,将会匹配User对象中的字段名,字段要保持一致 * @param user * @return */@GetMapping(&quot;/t2&quot;)public String test2(User user)&#123; System.out.println(user); return &quot;test&quot;;&#125; 返回数据 Model: 如处理的1所示 Model是精简版 大部分情况,我们都是使用Model的 ModelMap: 继承自LinkedHashMap,拥有LinkedHashMap的全部功能 ModelAndView: 在储存数据的同时,进行设置返回的逻辑视图View,进行控制展示层的跳转(在原始的实现Controller接口的方式中有使用,详见https://yiiiqing.github.io/2020/11/06/SpringMVC/)","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"}]},{"title":"SpringMVC中使用RestFul风格","slug":"SpringMVC中使用RestFul风格","date":"2020-11-09T03:22:00.000Z","updated":"2020-11-09T04:47:08.000Z","comments":true,"path":"2020/11/09/SpringMVC中使用RestFul风格/","link":"","permalink":"http://yiiiqing.github.io/2020/11/09/SpringMVC%E4%B8%AD%E4%BD%BF%E7%94%A8RestFul%E9%A3%8E%E6%A0%BC/","excerpt":"","text":"传统风格 1234567//http://localhost:8080/4/add?a=1&amp;b=2@RequestMapping(&quot;/add1&quot;)public String test1(int a, int b, Model model)&#123; int res = a + b; model.addAttribute(&quot;msg&quot;,&quot;结果为&quot;+res); return &quot;test&quot;;&#125; RestFul风格 123456789101112131415// http://localhost:8080/4/add/a/b@RequestMapping(&quot;/add2/&#123;a&#125;/&#123;b&#125;&quot;)public String test2(@PathVariable int a, @PathVariable int b, Model model)&#123; int res = a + b; model.addAttribute(&quot;msg&quot;,&quot;结果为&quot;+res); return &quot;test&quot;;&#125;// 或者@GetMapping(&quot;/add3/&#123;a&#125;/&#123;b&#125;&quot;)public String test3(@PathVariable int a, @PathVariable int b, Model model)&#123; int res = a + b; model.addAttribute(&quot;msg&quot;,&quot;结果为&quot;+res); return &quot;test&quot;;&#125; 使用好处: 简洁: 使路径变得更加简洁 高效: 获得参数更加方便,框架会自动进行类型转换 安全: 不会暴露变量名 通过路径变量的类型可以约束访问参数,如果类型不一样,则访问不到对应的请求方法,而不会是参数转换失败","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"},{"name":"RestFul","slug":"RestFul","permalink":"http://yiiiqing.github.io/tags/RestFul/"}]},{"title":"Tomcat重新部署项目基本规则","slug":"Tomcat重新部署项目基本规则","date":"2020-11-09T02:16:46.000Z","updated":"2020-11-09T03:08:04.000Z","comments":true,"path":"2020/11/09/Tomcat重新部署项目基本规则/","link":"","permalink":"http://yiiiqing.github.io/2020/11/09/Tomcat%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE%E5%9F%BA%E6%9C%AC%E8%A7%84%E5%88%99/","excerpt":"","text":"启动选项 每次项目修改后,为了省事都是选Restart.但是这样会部署速度会非常慢 今天了解了一下这几个选项 重启Restart: 重启 重新部署Redeploy: 将java目录下的文件和xml配置都重新部署到Tomcat.更新class文件,更新web.xml等配置文件,不重启Tomcat,只是删掉原来的,重新发布 热部署Update classes and resources: 修改jsp,java,静态资源 java修改后会被编译成为class,IDE调试模式立即生效,运行模式需要重新部署Redeploy才能生效 jsp文件不论什么模式,立即生效 更新静态资源 Update resources: html,js,css等,直接生效 Configuration在Configuration的Server配置中,有以下两项配置也与资源更新相关 On frame deactivation: 是IDE在失去焦点的时候会自动触发,开发过程中会因为很多原因随时触发,会消耗CPU,建议使用Do nothing,同官方默认 On Update action: 建议使用update classes and resources,运行模式下（jsp 立即生效，java 需要redeploy才可生效） Reference: http://www.mamicode.com/info-detail-1699044.html","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"idea","slug":"idea","permalink":"http://yiiiqing.github.io/tags/idea/"},{"name":"Tomcat","slug":"Tomcat","permalink":"http://yiiiqing.github.io/tags/Tomcat/"}]},{"title":"SpringMVC","slug":"SpringMVC","date":"2020-11-06T02:27:02.000Z","updated":"2020-11-16T03:04:55.000Z","comments":true,"path":"2020/11/06/SpringMVC/","link":"","permalink":"http://yiiiqing.github.io/2020/11/06/SpringMVC/","excerpt":"","text":"原理首先需要了解MVC结构和servlet相关基础,SpringMVC是基于servlet的 实线: SpringMVC框架提供的技术,无需开发者实践 虚线: 需要开发者实现 controller调用service层 view的设置 DispatcherServlet 前置控制器: SpringMVC的控制中心,接收用户的请求并拦截 HandlerMapping 处理器映射: 被DispatcherServlet调用,根据请求的url查找Handler HandlerExecution 具体Handler, 主要作用:根据url查找控制器 将解析后的信息返回给控制器 HandlerAdapter 处理器适配器,找到对应的适配类 调用具体的Controller执行 将执行结果返回 将结果返回控制器 ViewResolver 调用视图解析器来解析HandlerAdapter传递的ModelAndView名(加入前缀后缀等) 将解析后的视图名返回控制器 根据视图结果,调用具体的视图 返回用户 依赖12345678910111213141516171819202122232425262728&lt;!--依赖--&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt; &lt;artifactId&gt;jsp-api-2.0&lt;/artifactId&gt; &lt;version&gt;6.1.26&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置方法一: 配置方式 配置web/WEB-INF下的web.xml 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot; version=&quot;4.0&quot;&gt; &lt;!--配置DispatcherServlet: 这个是SpringMVC的核心; 请求分发器,前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--DispatvcherServlet要绑定Spring的配置文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--启动级别:1 数字越小,启动越早--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- 在SpringMVC中, / /*区别 /: 只匹配所有的请求,不会去匹配jsp /*: 匹配所有的请求,包括jsp --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--过滤器,解决乱码问题--&gt; &lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; resources下新建springmvc-servlet.xml文件 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!--处理器映射器--&gt; &lt;bean class=&quot;org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping&quot;/&gt; &lt;!--处理器适配器--&gt; &lt;bean class=&quot;org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter&quot;/&gt; &lt;!--视图解析器 模板引擎 Thymeleaf Freemarker...--&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; id=&quot;internalResourceViewResolver&quot;&gt; &lt;!--前缀后缀--&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt; &lt;!--BeanNameUrlHandlerMapping:bean--&gt; &lt;!-- id是url --&gt; &lt;bean id=&quot;/hello&quot; class=&quot;zone.yiqing.controller.HelloController&quot;/&gt;&lt;/beans&gt; 处理器映射器和处理器适配器框架已经提供,视图解析器可以使用框架的,也可以使用第三方 配置Controller 123456789101112131415161718192021222324252627282930package zone.yiqing.controller;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.mvc.Controller;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @Author Yiqing Zhang * @Date 2020-11-06 10:13 a.m. * @Version 1.0 */public class HelloController implements Controller &#123; @Override public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; ModelAndView modelAndView = new ModelAndView(); // 业务代码 String result = &quot;HelloSpringMVC!&quot;; modelAndView.addObject(&quot;msg&quot;,result); // 视图跳转 modelAndView.setViewName(&quot;test&quot;); return modelAndView; &#125;&#125; controller调用业务层代码,这里忽略,返回一个ModelAndView,携带信息msg,视图名为test 编写视图 在 web/WEB-INF/jsp/test.jsp 12345678910111213141516&lt;%-- Created by IntelliJ IDEA. User: Yiqing Date: 2020-11-06 Time: 9:58 a.m. To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;$&#123;msg&#125;&lt;/body&gt;&lt;/html&gt; 接收msg并返回 启动tomcat服务器,查看结果,2/2是我自己配置的项目路径,可以看到/hello的请求,已经正确处理 方法二: 注解方式 第一步同上 resources下新建springmvc-servlet.xml文件 核心的三行 123&lt;context:component-scan base-package=&quot;zone.yiqing.controller&quot;/&gt;&lt;mvc:default-servlet-handler/&gt;&lt;mvc:annotation-driven/&gt; 全部 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt; &lt;!--自动扫描包,让指定包下的注解生效, 由IOC容器统一管理--&gt; &lt;context:component-scan base-package=&quot;zone.yiqing.controller&quot;/&gt; &lt;!--让SpringMVC不处理静态资源--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 支持mvc注解驱动 在spring中一般使用@RequestMapping注解来完成映射关系 要想使@RequestMapping生效 必须在上下文中注册DefaultAnnotationHandlerMapping和一个AnnotationMethodHandlerAdapter实例 这两个类分别在类级别和方法级别处理 annotation-driven配置帮助我们自动完成上述两个实例的注入 --&gt; &lt;mvc:annotation-driven&gt; &lt;!--JSON乱码问题配置--&gt; &lt;mvc:message-converters&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;constructor-arg value=&quot;UTF-8&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;objectMapper&quot;&gt; &lt;bean class=&quot;org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean&quot;&gt; &lt;property name=&quot;failOnEmptyBeans&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;!--视图解析器 模板引擎 Thymeleaf Freemarker...--&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; id=&quot;internalResourceViewResolver&quot;&gt; &lt;!--前缀后缀--&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 编写视图 将所有东西都放到WEB-INF目录下,可以保证视图的安全,因为这个目录下的文件客户端不能直接访问 12345678910&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt; &lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;/body&gt;&lt;/html&gt; 编写Controller 添加@Controller注解, 将会自动扫描(第二步配置),不需要再手动配置bean @RequestMapping映射请求路径 声明Model类型的参数是为了把Action中的数据带到视图中 方法返回的结果是视图名 123456789101112131415161718192021 package zone.yiqing.controller; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.RequestMapping; /** * @Author Yiqing Zhang * @Date 2020-11-06 1:44 p.m. * @Version 1.0 */@Controller public class HelloController &#123; @RequestMapping(&quot;/hello&quot;) public String hello(Model model)&#123; // 封装数据 model.addAttribute(&quot;msg&quot;,&quot;Hello, SpringMVC annotation!&quot;); return &quot;hello&quot;; // 这里return的是视图名,会被视图解析器处理找到hello.jsp &#125; &#125; @RequestMapping注解用于映射url到控制器类或者一个特定的处理程序方法. 可用于类或方法上 用于类上,表示类中的所有的响应请求的方法都是以该地址为父路径 同上","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"}]},{"title":"js 常用方法","slug":"js-常用方法","date":"2020-11-05T05:20:49.000Z","updated":"2020-11-24T07:09:32.000Z","comments":true,"path":"2020/11/05/js-常用方法/","link":"","permalink":"http://yiiiqing.github.io/2020/11/05/js-%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"一些有用的方法数组去除数组中的空值,假值123var u=[undefined,undefined,1,&#x27;&#x27;,&#x27;false&#x27;,false,true,null,&#x27;null&#x27;];u.filter(d=&gt;d);// 结果是1,&#x27;false&#x27;,true,&#x27;null&#x27; 更改object属性名1json = JSON.parse(JSON.stringify(json).replace(/CourseName/g,&quot;title&quot;)); 获取时间 toLocaleDateString()方法可根据本地时间把 Date 对象的日期部分转换为字符串，并返回结果。 12let startTime1 = new Date(new Date(new Date().toLocaleDateString()).getTime()); // 当天0点 let endTime1 = new Date(new Date(new Date().toLocaleDateString()).getTime() +24 * 60 * 60 * 1000 -1);// 当天23:59 setHours()方法用于设置指定的时间的小时字段 12let startTime2 = new Date(new Date(new Date().getTime()-24*60*60*1000).setHours(0,0,0,0));// 当天0点 let endTime2 = new Date(new Date(new Date().getTime()-24*60*60*1000).setHours(23,59,59,999)) 前十二个月 1234567891011var dateArr = []; var date = new Date(); var year = date.getFullYear(); date.setMonth(date.getMonth()+1, 1)//获取到当前月份,设置月份 for (var i = 0; i &lt; 12; i++) &#123; date.setMonth(date.getMonth() - 1);//每次循环一次 月份值减1 var m = date.getMonth() + 1; m = m &lt; 10 ? &quot;0&quot; + m : m; dateArr.push(date.getFullYear() + &quot;-&quot; + (m))&#125;console.log(dateArr); 获取当前域名,url,相对路径,参数 获取当前域名 12var domain = document.domain;var domain = window.location.host; 获取当前url 1234var url = window.location.href;var url = self.location.href;var url = document.URL;var url = document.location; 获取当前相对路径 1234567891011function GetUrlRelativePath()&#123; var url = document.location.toString(); var arrUrl = url.split(&quot;//&quot;); var start = arrUrl[1].indexOf(&quot;/&quot;); var relUrl = arrUrl[1].substring(start);//stop省略，截取从start开始到结尾的所有字符 if(relUrl.indexOf(&quot;?&quot;) != -1)&#123; relUrl = relUrl.split(&quot;?&quot;)[0]; &#125; return relUrl;&#125; 获取当前url参数 1234567function GetUrlPara()&#123; var url = document.location.toString(); var arrUrl = url.split(&quot;?&quot;); var para = arrUrl[1]; return para;&#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/tags/JavaScript/"}]},{"title":"Spring配置","slug":"Spring配置","date":"2020-11-05T01:46:58.000Z","updated":"2020-11-12T05:41:45.000Z","comments":true,"path":"2020/11/05/Spring配置/","link":"","permalink":"http://yiiiqing.github.io/2020/11/05/Spring%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Spring配置applicationContext.xml1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;&lt;/beans&gt; 注解要使用注解: 导入约束 配置注解的支持context:annotation-config/ 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:annotation-config/&gt;&lt;/beans&gt; 在属性中标记@Autowired,也可以在set方式上使用,是用Autowired我们可以不用编写Set方法,前提是这个自动装配的属性咋IOC(Spring) 容器中存在,且符合名字byName 科普: 123@Nullable可以设置属性为空Autowired(required = false) 如果显式定义了该属性为false,说明这个对象可以为null,否则不允许为空@Qualifire(value=&quot;xxx&quot;) 指定唯一bean对象 @Resource 和 @Autowired 的区别: 都是用来自动装配的,都可以放在属性字段上 @Autowired通过byType,必须要求对象存在 @Resource默认通过byName方式,如果找不到名字,则通过byType实现,如果都找不到报错 Mybatis整合123456789101112131415161718192021222324252627282930313233343536373839&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.49&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Spring操作数据库的话,还需要一个spring-jdbc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Mybatis配置123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/mybatis?useSSL=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;zzz&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--每一个Mapper.XML都需要在Mybatis核心配置文件中注册!--&gt; &lt;mappers&gt; &lt;mapper resource=&quot;zone/yiqing/dao/UserMapper.xml&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; Maven静态资源过滤问题添加到pom.xml 1234567891011121314151617181920&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 编译版本问题编译时候出现了 Version 5 not supportted 的错误,经google发现是需要在配置文件中指定maven的编译 1234&lt;properties&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt;&lt;/properties&gt;","categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://yiiiqing.github.io/tags/Mybatis/"},{"name":"Maven","slug":"Maven","permalink":"http://yiiiqing.github.io/tags/Maven/"}]}],"categories":[{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/categories/Java/"},{"name":"Kafka","slug":"Kafka","permalink":"http://yiiiqing.github.io/categories/Kafka/"},{"name":"设计模式","slug":"设计模式","permalink":"http://yiiiqing.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"网络","slug":"网络","permalink":"http://yiiiqing.github.io/categories/%E7%BD%91%E7%BB%9C/"},{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/categories/Docker/"},{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/categories/Linux/"},{"name":"笔记","slug":"笔记","permalink":"http://yiiiqing.github.io/categories/%E7%AC%94%E8%AE%B0/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/categories/MySQL/"},{"name":"算法","slug":"算法","permalink":"http://yiiiqing.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"中间件","slug":"中间件","permalink":"http://yiiiqing.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Design","slug":"Design","permalink":"http://yiiiqing.github.io/categories/Design/"},{"name":"Web","slug":"Web","permalink":"http://yiiiqing.github.io/categories/Web/"},{"name":"DB","slug":"DB","permalink":"http://yiiiqing.github.io/categories/DB/"},{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/categories/JavaScript/"},{"name":"Redis","slug":"Redis","permalink":"http://yiiiqing.github.io/categories/Redis/"},{"name":"Markdown","slug":"Markdown","permalink":"http://yiiiqing.github.io/categories/Markdown/"},{"name":"中间件","slug":"Java/中间件","permalink":"http://yiiiqing.github.io/categories/Java/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/categories/Node-js/"},{"name":"Redis","slug":"Java/Redis","permalink":"http://yiiiqing.github.io/categories/Java/Redis/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://yiiiqing.github.io/tags/Spring/"},{"name":"WEB","slug":"WEB","permalink":"http://yiiiqing.github.io/tags/WEB/"},{"name":"Kafka","slug":"Kafka","permalink":"http://yiiiqing.github.io/tags/Kafka/"},{"name":"单例模式","slug":"单例模式","permalink":"http://yiiiqing.github.io/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"http","slug":"http","permalink":"http://yiiiqing.github.io/tags/http/"},{"name":"tcp","slug":"tcp","permalink":"http://yiiiqing.github.io/tags/tcp/"},{"name":"Docker","slug":"Docker","permalink":"http://yiiiqing.github.io/tags/Docker/"},{"name":"Java","slug":"Java","permalink":"http://yiiiqing.github.io/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"http://yiiiqing.github.io/tags/Linux/"},{"name":"计算机组成原理","slug":"计算机组成原理","permalink":"http://yiiiqing.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yiiiqing.github.io/tags/MySQL/"},{"name":"排序","slug":"排序","permalink":"http://yiiiqing.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"name":"Thread","slug":"Thread","permalink":"http://yiiiqing.github.io/tags/Thread/"},{"name":"配置","slug":"配置","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"bash","slug":"bash","permalink":"http://yiiiqing.github.io/tags/bash/"},{"name":"Java8","slug":"Java8","permalink":"http://yiiiqing.github.io/tags/Java8/"},{"name":"jOOQ","slug":"jOOQ","permalink":"http://yiiiqing.github.io/tags/jOOQ/"},{"name":"gRPC","slug":"gRPC","permalink":"http://yiiiqing.github.io/tags/gRPC/"},{"name":"RPC","slug":"RPC","permalink":"http://yiiiqing.github.io/tags/RPC/"},{"name":"DI","slug":"DI","permalink":"http://yiiiqing.github.io/tags/DI/"},{"name":"IoC","slug":"IoC","permalink":"http://yiiiqing.github.io/tags/IoC/"},{"name":"Guice","slug":"Guice","permalink":"http://yiiiqing.github.io/tags/Guice/"},{"name":"数据结构","slug":"数据结构","permalink":"http://yiiiqing.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"Mysql","slug":"Mysql","permalink":"http://yiiiqing.github.io/tags/Mysql/"},{"name":"Database","slug":"Database","permalink":"http://yiiiqing.github.io/tags/Database/"},{"name":"ACID","slug":"ACID","permalink":"http://yiiiqing.github.io/tags/ACID/"},{"name":"Isolation","slug":"Isolation","permalink":"http://yiiiqing.github.io/tags/Isolation/"},{"name":"Shell","slug":"Shell","permalink":"http://yiiiqing.github.io/tags/Shell/"},{"name":"JavaScript","slug":"JavaScript","permalink":"http://yiiiqing.github.io/tags/JavaScript/"},{"name":"Nginx","slug":"Nginx","permalink":"http://yiiiqing.github.io/tags/Nginx/"},{"name":"CAP","slug":"CAP","permalink":"http://yiiiqing.github.io/tags/CAP/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://yiiiqing.github.io/tags/Zookeeper/"},{"name":"CentOS","slug":"CentOS","permalink":"http://yiiiqing.github.io/tags/CentOS/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yiiiqing.github.io/tags/SpringBoot/"},{"name":"Devtools","slug":"Devtools","permalink":"http://yiiiqing.github.io/tags/Devtools/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://yiiiqing.github.io/tags/SpringCloud/"},{"name":"Redis","slug":"Redis","permalink":"http://yiiiqing.github.io/tags/Redis/"},{"name":"curl","slug":"curl","permalink":"http://yiiiqing.github.io/tags/curl/"},{"name":"报错","slug":"报错","permalink":"http://yiiiqing.github.io/tags/%E6%8A%A5%E9%94%99/"},{"name":"字符串","slug":"字符串","permalink":"http://yiiiqing.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"配置 - Java","slug":"配置-Java","permalink":"http://yiiiqing.github.io/tags/%E9%85%8D%E7%BD%AE-Java/"},{"name":"Markdown","slug":"Markdown","permalink":"http://yiiiqing.github.io/tags/Markdown/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yiiiqing.github.io/tags/RabbitMQ/"},{"name":"Ant","slug":"Ant","permalink":"http://yiiiqing.github.io/tags/Ant/"},{"name":"Actuator","slug":"Actuator","permalink":"http://yiiiqing.github.io/tags/Actuator/"},{"name":"Interceptor","slug":"Interceptor","permalink":"http://yiiiqing.github.io/tags/Interceptor/"},{"name":"Node.js","slug":"Node-js","permalink":"http://yiiiqing.github.io/tags/Node-js/"},{"name":"express","slug":"express","permalink":"http://yiiiqing.github.io/tags/express/"},{"name":"git","slug":"git","permalink":"http://yiiiqing.github.io/tags/git/"},{"name":"RestFul","slug":"RestFul","permalink":"http://yiiiqing.github.io/tags/RestFul/"},{"name":"maven","slug":"maven","permalink":"http://yiiiqing.github.io/tags/maven/"},{"name":"String","slug":"String","permalink":"http://yiiiqing.github.io/tags/String/"},{"name":"byte[]","slug":"byte","permalink":"http://yiiiqing.github.io/tags/byte/"},{"name":"TypeScript","slug":"TypeScript","permalink":"http://yiiiqing.github.io/tags/TypeScript/"},{"name":"base64","slug":"base64","permalink":"http://yiiiqing.github.io/tags/base64/"},{"name":"file","slug":"file","permalink":"http://yiiiqing.github.io/tags/file/"},{"name":"镜像源","slug":"镜像源","permalink":"http://yiiiqing.github.io/tags/%E9%95%9C%E5%83%8F%E6%BA%90/"},{"name":"import","slug":"import","permalink":"http://yiiiqing.github.io/tags/import/"},{"name":"koa","slug":"koa","permalink":"http://yiiiqing.github.io/tags/koa/"},{"name":"vi","slug":"vi","permalink":"http://yiiiqing.github.io/tags/vi/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://yiiiqing.github.io/tags/Mybatis/"},{"name":"Error","slug":"Error","permalink":"http://yiiiqing.github.io/tags/Error/"},{"name":"CROS","slug":"CROS","permalink":"http://yiiiqing.github.io/tags/CROS/"},{"name":"Swagger","slug":"Swagger","permalink":"http://yiiiqing.github.io/tags/Swagger/"},{"name":"bug","slug":"bug","permalink":"http://yiiiqing.github.io/tags/bug/"},{"name":"utils","slug":"utils","permalink":"http://yiiiqing.github.io/tags/utils/"},{"name":"schedule","slug":"schedule","permalink":"http://yiiiqing.github.io/tags/schedule/"},{"name":"cron","slug":"cron","permalink":"http://yiiiqing.github.io/tags/cron/"},{"name":"async","slug":"async","permalink":"http://yiiiqing.github.io/tags/async/"},{"name":"heartbeat","slug":"heartbeat","permalink":"http://yiiiqing.github.io/tags/heartbeat/"},{"name":"websocket","slug":"websocket","permalink":"http://yiiiqing.github.io/tags/websocket/"},{"name":"Druid","slug":"Druid","permalink":"http://yiiiqing.github.io/tags/Druid/"},{"name":"Thymeleaf","slug":"Thymeleaf","permalink":"http://yiiiqing.github.io/tags/Thymeleaf/"},{"name":"upload","slug":"upload","permalink":"http://yiiiqing.github.io/tags/upload/"},{"name":"download","slug":"download","permalink":"http://yiiiqing.github.io/tags/download/"},{"name":"Validation","slug":"Validation","permalink":"http://yiiiqing.github.io/tags/Validation/"},{"name":"yaml","slug":"yaml","permalink":"http://yiiiqing.github.io/tags/yaml/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiiiqing.github.io/tags/SpringMVC/"},{"name":"Sequelize","slug":"Sequelize","permalink":"http://yiiiqing.github.io/tags/Sequelize/"},{"name":"ORM","slug":"ORM","permalink":"http://yiiiqing.github.io/tags/ORM/"},{"name":"npm","slug":"npm","permalink":"http://yiiiqing.github.io/tags/npm/"},{"name":"Ajax","slug":"Ajax","permalink":"http://yiiiqing.github.io/tags/Ajax/"},{"name":"Express","slug":"Express","permalink":"http://yiiiqing.github.io/tags/Express/"},{"name":"Bootstrap","slug":"Bootstrap","permalink":"http://yiiiqing.github.io/tags/Bootstrap/"},{"name":"CDN","slug":"CDN","permalink":"http://yiiiqing.github.io/tags/CDN/"},{"name":"样式","slug":"样式","permalink":"http://yiiiqing.github.io/tags/%E6%A0%B7%E5%BC%8F/"},{"name":"pm2","slug":"pm2","permalink":"http://yiiiqing.github.io/tags/pm2/"},{"name":"项目","slug":"项目","permalink":"http://yiiiqing.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"jdbc","slug":"jdbc","permalink":"http://yiiiqing.github.io/tags/jdbc/"},{"name":"idea","slug":"idea","permalink":"http://yiiiqing.github.io/tags/idea/"},{"name":"Tomcat","slug":"Tomcat","permalink":"http://yiiiqing.github.io/tags/Tomcat/"},{"name":"Maven","slug":"Maven","permalink":"http://yiiiqing.github.io/tags/Maven/"}]}